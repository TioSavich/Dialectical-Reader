{
  "fileContent": "What Might Cognition Be, If Not Computation?  Author(s):   Tim Van Gelder  Source:  The Journal of Philosophy   ,   Jul., 1995 ,   Vol. 92, No. 7 (Jul., 1995), pp. 345-381  Published by:   Journal of Philosophy, Inc.  Stable URL:   https://www.jstor.org/stable/2941061  JSTOR is a not-for-profit service that helps scholars, researchers, and students discover, use, and build upon a wide  range of content in a trusted digital archive. We use information technology and tools to increase productivity and  facilitate new forms of scholarship. For more information about JSTOR, please contact support@jstor.org.  Your use of the JSTOR archive indicates your acceptance of the Terms & Conditions of Use, available at  https://about.jstor.org/terms  is   collaborating with JSTOR to digitize, preserve and extend access to  The Journal of  Philosophy  This content downloaded from  216.249.91.115 on Sat, 19 Oct 2024 13:58:06 UTC  All use subject to https://about.jstor.org/terms\n\nTHE   JOURNAL   OF   PHILOSOPHY  VOLUME XCI, NO. 7, JULY 1995  WHAT MIGHT COGNITION BE, IF NOT COMPUTATION?*  W hat is cognition? Contemporary orthodoxy maintains that  it is computation: the mind is a special kind of computer,  and cognitive processes are the rule-governed manipula-  tion of internal symbolic representations. This broad idea has domi-  nated the philosophy and the rhetoric of cognitive science-and  even, to a large extent, its practice-ever since the field emerged  from the postwar cybernetic melee. It has provided the general  framework for much of the most well-developed and insightful re-  search into the nature of mental operation. Yet, over the last decade  or more, the computational vision has lost much of its lustre.  Although work within it continues apace, a variety of difficulties and  limitations have become increasingly apparent, and researchers  across cognitive science and related disciplines have been casting  around for other ways to understand cognitive processes. Partly as a  result, there are now many research programs which, one way or an-  other, stand opposed to the traditional computational approach;  these include connectionism, neurocomputational approaches, eco-  logical psychology, situated robotics, synergetics, and artificial life.  These approaches appear to offer a variety of differing and even  conflicting conceptions of the nature of cognition. It is therefore an  appropriate time to step back and reconsider the question: What  general arguments are there in favor of the idea that cognitive  processes must be specifically comnputational in nature? In order p  * Criticism and advice from numerous people helped improve this paper, but  special acknowledgement is due to Robert Port, John Haugeland, and James  Townsend. Audiences at the University of Illinois/Chicago, the New Mexico State  University, Indiana University, the Australian National University, the University of  New South Wales, Princeton University, Lehigh University, and the University of  Skuivde were suitably and helpfully critical of earlier versions.  0022-362X/95/9207/345-81 ? 1995 TheJournal of Philosophy, Inc.  345  This content downloaded from  216.249.91.115 on Sat, 19 Oct 2024 13:58:06 UTC  All use subject to https://about.jstor.org/terms\n\n346   THEJOURNAL   OF   PHILOSOPHY  erly to address this question, however, we must first address another:  What are the alternatives? What could cognition be, if it were not  computation of some form or other?  There are at least two reasons why this second question is impor-  tant. First, arguments in favor of some broad hypothesis are rarely, if  ever, completely general. They tend to be arguments not for A  alone, but rather in favor of A as opposed to B, and such arguments  often fail to support A as opposed to C. For example, one of the  most powerful early conrsiderations raised in favor of the computa-  tional conception of cognition was the idea that intelligent behavior  requires sophisticated internal representations. While this clearly  supported the computational conception against a behaviorism  which eschewed sucn resources, however, it was no use against a con-  nectionism which helped itself to internal representations, though  rather different in kind than the standard symbolic variety.  The second reason we need to ask what alternatives there may be  is that one of the most influential arguments in favor of the compu-  tational view is the claim that there is simply no alternative. This is  sometimes known as the \"what else could it be?\" argument.' As Allen  Newell2 recently put it:  ...although a small chance exists that we will see a new paradigm  emerge for mind, it seems unlikely to me. Basically, there do not seem  to be any viable alternatives. This position is not surprising. In lots of  sciences we end up where there are no major alternatives around to the  particular theories we have. Then, all the interesting kinds of scientific  action occur inside the major view. It seems to me that we are getting  rather close to that situation with respect to the computational theory  of mind (ibid., p. 56).  This paper describes a viable alternative. Rather than computers,  cognitive systems may be dynamical systems; rather than computa-  tion, cognitive processes may be state-space evolution within these  very different kinds of systems. It thus disarms the \"what else could it  be?\" argument, and advances the broader project of evaluating com-  peting hypotheses concerning the nature of cognition. Note that  achieving these goals does not require decisively establishing that  the dynamical hypothesis is true. That would require considerably  more space than is available here, and to attempt it now would be  hopelessly premature anyway. All that must be done is to describe  ' This title may have been first used in print byJohn Haugeland in 'The Nature  and Plausibility of Cognitivism,\" Behavioral and Brain Sciences, i (1978): 215-26.  2 \"Are There Altematives?\" in W. Sieg, ed., Acting and Reflecting (Boston: Kluwer,  1990).  This content downloaded from  216.249.91.115 on Sat, 19 Oct 2024 13:58:06 UTC  All use subject to https://about.jstor.org/terms\n\nWHAT MIGHT COGNITION BE, IF NOT COMPUTATION? 347  and motivate the dynamical conception sufficiently to show that it  does in fact amount to an alternative conception of cognition, and  one which is currently viable, as far as we can now tell.  A fruitful way to present the dynamical conception is to begin with  an unusual detour, via the early industrial revolution in England,  circa 1788.  I. THE GOVERNING PROBLEM  A central engineering challenge for the industrial revolution was to  find a source of power that was reliable, smooth, and uniform. In the  latter half of the eighteenth century, this had become the problem  of translating the oscillating action of the steam piston into the rotat-  ing motion of a flywheel. In one of history's most significant techno-  logical achievements, Scottish engineer James Watt designed and  patented a gearing system for a rotative engine. Steam power was no  longer limited to pumping; it could be applied to any machinery  that could be driven by a flywheel. The cotton industry was particu-  larly eager to replace its horses and water wheels with the new en-  gines. High-quality spinning and weaving required, however, that the  source of power be highly uniform, that is, there should be little or  no variation in the speed of revolution of the main driving flywheel.  This is a problem, since the speed of the flywheel is affected both by  the pressure of the steam from the boilers, and by the total workload  being placed on the engine, and these are constantly fluctuating.  It was clear enough how the speed of the flywheel had to be regu-  lated. In the pipe carrying steam from the boiler to the piston there  was a throttle valve. The pressure in the piston, and so the speed of  the wheel, could be adjusted by turning this valve. To keep engine  speed uniform, the throttle valve would have to be turned, atjust the  right time and by just the right amount, to cope with changes in  boiler pressure and workload. How was this to be done? The most  obvious solution was to employ a human mechanic to turn the valve  as necessary. This had a number of drawbacks, however: mechanics  required wages, and were often unable to react sufficiently swiftly  and accurately. The industrial revolution thus confronted a second  engineering challenge: design a device which can automatically ad-  just the throttle valve so as to maintain uniform speed of the flywheel  despite changes in steam pressure or workload. Such a device is  known as a governor.  Difficult engineering problems are often best approached by  breaking the overall task down into simpler subtasks, continuing the  process of decomposition until one can see how to construct devices  that can directly implement the various component tasks. In the case  This content downloaded from  216.249.91.115 on Sat, 19 Oct 2024 13:58:06 UTC  All use subject to https://about.jstor.org/terms\n\n348   THEJOURNAL   OF   PHILOSOPHY  of the governing problem, the relevant decomposition seems clear.  A change need only be made to the throttle valve if the flywheel is  not currently running at the correct speed. Therefore, the first sub-  task must be to measure the speed of the wheel, and the second sub-  task must be to calculate whether there is any discrepancy between  the desired speed and the actual speed. If there is no discrepancy,  no change is needed, for the moment at least. If there is a discrep-  ancy, then the governor must determine by how much the throttle  valve should be adjusted to bring the speed of the wheel to the de-  sired level. This will depend, of course, on the current steam pres-  sure, and so the governor must measure the current steam pressure  and then on that basis calculate how much to adjust the valve.  Finally, of course, the valve must De adjusted. This overall sequence  of subtasks must be carried out as often as necessary to keep the  speed of the wheel sufficiently close to the desired speed.  A device that can solve the governing problem would have to carry  out these various subtasks repeatedly in the correct order, and so we  can think of it as obeying the following algorithm:  1. Measure the speed of the flywheel.  2. Compare the actual speed against the desired speed.  3. If there is no discrepancy, return to step 1. Otherwise,  a. measure the current steam pressure;  b. calculate the desired alteration in steam pressure;  c. calculate the necessary throttle valve adjustment.  4. Make the throttle valve adjustment.  Return to step 1.  There must be some physical device capable of actually carrying out  each of these subtasks, and so we can think of the governor as incor-  porating a tachometer (for measuring the speed of the wheel); a de-  vice for calculating the speed discrepancy; a steam pressure meter; a  device for calculating the throttle valve adjustment; a throttle valve  adjuster; and some kind of central executive to handle sequencing  of operations. This conceptual breakdown of the components of the  governor may even correspond to its actual breakdown; that is, each  of these components may be implemented by a distinct, dedicated  physical device. The engineering problem would then reduce to the  (presumably much simpler) problem of constructing the various  components and hooking them together so that the whole system  functions in a coherent fashion.  Now, as obvious as this approach now seems, it was not the way the  governing problem was actually solved. For one thing, it presupposes  devices that can swiftly perform some quite complex calculations,  This content downloaded from  216.249.91.115 on Sat, 19 Oct 2024 13:58:06 UTC  All use subject to https://about.jstor.org/terms\n\nWHAT MIGHT COGNITION BE, IF NOT COMPUTATION? 349  and although some simple calculating devices had been invented in  the seventeenth century, there was certainly nothing available in the  late eighteenth century that could have met the demands of a practi-  cal governor.  The real solution, adapted by Watt from existing windmill technol-  ogy, was much more direct and elegant. It consisted of a vertical  spindle geared into the main flywheel so that it rotated at a speed di-  rectly dependent upon that of the flywheel itself (see figure 1).  Attached to the spindle by hinges were two arms, and on the end of  each arm was a metal ball. As the spindle turned, centrifugal force  drove the balls outward and hence upward. By a clever arrangement,  this arm motion was linked directly to the throttle valve. The result  was that as the speed of the main wheel increased, the arms raised,  closing the valve and restricting the flow of steam; as the speed de-  creased, the arms fell, opening the valve and allowing more steam to  flow. The engine adopted a constant speed, maintained with extraor-  dinary swiftness and smoothness in the presence of large fluctuations  in pressure and load.  It is worth emphasizing how remarkably well the centrifugal gover-  nor actually performed its task. This device was not just an engineer-  De  f#a'-~~~  Figure 13  3 The Watt centrifugal governor for controlling the speed of a steam engine-  from J. Farey, A Treatise on the Steam Engine: Historical, Practical, and Descriptive  (London: Longman, Rees, Orme, Brown, and Green, 1827).  This content downloaded from  216.249.91.115 on Sat, 19 Oct 2024 13:58:06 UTC  All use subject to https://about.jstor.org/terms\n\n350   THEJOURNAL   OF   PHILOSOPHY  ing hack employed because computer technology was unavailable.  Scientific American claimed in 1858 that an American variant of the  basic centrifugal governor, \"if not absolutely perfect in its action,  is so nearly so, as to leave in our opinion nothing further to be  desired. \"  But why should any of this be of any interest in the philosophy of  cognitive science? The answer may become apparent as we exam-  ine a little more closely some of the differences between the two  governors.  II. TWO KINDS OF GOVERNORS  The two governors described in the previous section are patently dif-  ferent in construction, yet they both solve the same control problem,  and we can assume (for purposes of this discussion) that they both  solve it sufficienfly well. Does it follow that, deep down, they are re-  ally the same kind of device, despite superficial differences in con-  struction? Or are they deeply different, despite their similarity in  overt performance?  It is natural to think of the first governor as a computational de-  vice; one which, as part of its operation computes some result,  namely, the desired change in throttle valve angle. Closer attention  reveals that there is in fact a complex group of properties here, a  group whose elements are worth teasing apart.  Perhaps the most central of the computational governor's distinc-  tive properties is its dependence on representation. Every aspect of  its operation, as outlined above, deals with representations in some  manner or other. The very first thing it does is measure its environ-  ment (the engine) to obtain a symbolic representation of current en-  gine speed. It then performs a series of operations on this and other  representations, resulting in an output representation, a symbolic  specification of the alteration to be made in the throtfie valve; this  representation then causes the valve adjusting mechanism to make  the corresponding change. This is why it is appropriately described  as computational (now in a somewhat narrower sense): it literally  computes the desired change in throttle valve by manipulating sym-  bols according to a schedule of rules. Those symbols, in the context  of the device and its situation, have meaning, and the success of the  governor in its task is owed to its symbol manipulations being in sys-  tematic accord with those meanings. The manipulations are discrete  operations which necessarily occur in a determinate sequence; for  example, the appropriate change in the throttle valve can only be  calculated after the discrepancy between current and desired speeds  has been calculated. At the highest level, the whole device operates  This content downloaded from  216.249.91.115 on Sat, 19 Oct 2024 13:58:06 UTC  All use subject to https://about.jstor.org/terms\n\nWHAT MIGHT COGNITION BE, IF NOT COMPUTATION? 351  in a cyclic fashion: it first measures (or \"perceives\") its environment;  it then internally computes an appropriate change in throttle valve;  it then effects this change (\"acts\" on its environment). After the  change has been made and given time to affect engine speed, the  governor runs through whole the cycle again...and again.... Finally,  notice that the governor is homuncular in construction.  Homuncularity is a special kind of breakdown of a system into parts  or components, each of which is responsible for a particular subtask.  Homuncular components are ones that, like departments or com-  mittees within bureaucracies, interact by communication (that is, by  passing meaningful messages). Obviously, the representational and  computational nature of the governor is essential to its homuncular  construction: if the system as a whole did not operate by manipulat-  ing representations, it would not be possible for its components to  interact by communication.  These properties-representation, computation, sequential and  cyclic operation, and homuncularity-form a mutually interdepen-  dent cluster; a device with any one of them will standardly possess  others. Now, the Watt centrifugal governor does not exhibit this clus-  ter of properties as a whole, nor any one of them individually. As ob-  vious as this may seem, it deserves a little detailed discussion and  argument, since it often meets resistance, and some useful insights  can be gained along the way.  Since manipulable representations lie at the heart of the computa-  tional picture, the nonrepresentational nature of the centrifugal gov-  ernor is a good place to start. There is a common and initially quite  attractive intuition to the effect that the angle at which the arms are  swinging is a representation of the current speed of the engine, and  it is because the arms are related in this way to engine speed that the  governor is able to control that speed. This intuition is misleading,  however; arm angle and engine speed are of course intimately re-  lated, but the relationship is not representational. There are a num-  ber of powerful arguments favoring this conclusion. They are not  based on any unduly restrictive definition of the notion of represen-  tation; they go through on pretty much any reasonable characteriza-  tion, based around a core idea of some state of a system which, by  virtue of some general representational scheme, stands in for some  further state of affairs, thereby enabling the system to behave appro-  priately with respect to that state of affairs.4  4 This broad characterization is adapted from Haugeland, \"Representational  Genera,\" in W. Ramsey, S.P. Stich, D.E. Rumelhart, eds., Philosophy and  Connectionist Theory (Hillsdale, NJ: Erlbaum, 1991), pp. 61-89.  This content downloaded from  216.249.91.115 on Sat, 19 Oct 2024 13:58:06 UTC  All use subject to https://about.jstor.org/terms\n\n352   THEJOURNAL   OF   PHILOSOPHY  A useful criterion of representation-a reliable way of telling  whether a system contains them or not-is to ask whether there is  any explanatory utility in describing the system in representational  terms. If you really can make substantially more sense of how a sys-  tem works by concretely describing various identifiable parts or as-  pects of it as representations in the above sense, that is the best  evidence you could have that the system really does contain repre-  sentations. Conversely, if describing the system as representational  lets you explain nothing over and above what you could explain be-  fore, why on earth suppose it to be so? Note that very often represen-  tational descriptions do yield substantial explanatory benefits. This is  certainly true for pocket calculators, and mainstream cognitive sci-  ence is premised on the idea that humans and animals are like that  as well. A noteworthy fact about standard explanations of how the  centrifugal governor works is, however, that they never talk about  representations. This was true for the informal description given  above, which apparently suffices for most readers; more importantly,  it has been true of the much more detailed descriptions offered by  those who have actually been in the business of constructing cen-  trifugal governors or analyzing their behavior. Thus, for example, a  mechanics manual for construction of governors from the middle of  last century, Maxwell's original dynamical analysis (see below), and  contemporary mathematical treatments all describe the arm angle  and its role in the operation of the governor in nonrepresentational  terms. The reason, one might reasonably conclude, is that the gover-  nor contains no representations.  The temptation to treat the arm angle as a representation comes  from the informal observation that there is some kind of correlation  between arm angle and engine speed; when the engine rotates at a  certain speed, the arms will swing at a given angle. Now, supposing for  the moment that this is an appropriate way to describe their relation-  ship, it would not follow that the arm angle is a representation. One of  the few points of general agreement in the philosophy of cognitive sci-  ence is that mere correlation does not make something a representa-  tion. Virtually everything is correlated, fortuitously or otherwise, with  something else; to describe every correlation as representation is to  trivialize representation. For the arm angle to count, in the context of  the governing system alone, as a representation, we would have to be  told what else about itjustifies the claim that it is a representation.  But to talk of some kind of correlation between arm angle and en-  gine speed is grossly inadequate, and once this is properly under-  stood, there is simply no incentive to search for this extra ingredient.  This content downloaded from  216.249.91.115 on Sat, 19 Oct 2024 13:58:06 UTC  All use subject to https://about.jstor.org/terms\n\nWHAT MIGHT COGNITION BE, IF NOT COMPUTATION? 353  For a start, notice that the correlation at issue only obtains when the  total system has reached its stable equilibrium point, and is immedi-  ately disturbed whenever there is some sudden change in, for exam-  ple, the workload on the engine. At such times, the speed of the  engine quickly drops for a short period, while the angle of the arms  adjusts only at the relatively slow pace dictated by gravitational accel-  eration. Yet, even as the arms are falling, more steam is entering the  piston, and hence the device is already working; indeed, these are  exacdy the times when it is most crucial that the governor work ef-  fectively. Consequently, no simple correlation between arm angle  and engine speed can be the basis of the operation of the governor.  The fourth and deepest reason for supposing that the centrifugal  governor is not representational is that, when we fully understand  the relationship between engine speed and arm angle, we see that  the notion of representation is just the wrong sort of conceptual tool  to apply. There is no doubt that at all times the arm angle is in some  interesting way related to the speed of the engine. This is the insight  which leads people to suppose that the arm angle is a representa-  tion. Yet appropriately close examination of this dependence shows  exactly why the relationship cannot be one of representation. For  notice that, because the arms are directly linked to the throttle valve,  the angle of the arms is at all times determining the amount of  steam entering the piston, and hence at all times the speed of the  engine depends in some interesting way on the angle of the arms.  Thus, arm angle and engine speed are at all times both determined  by, and determining, each other's behavior. As we shall see below,  there is nothing mysterious about this relationship; it is quite  amenable to mathematical description. Yet it is much more subtle  and complex than the standard concept of representation can han-  dle, even when construed as broadly as is done here. In order to de-  scribe the relationship between arm angle and engine speed, we  need a more powerful conceptual framework than mere talk of rep-  resentations. That framework is the mathematical language of dy-  namics, and in that language, the two quantities are said to be  coupled. The real problem with describing the governor as a repre-  sentational device, then, is that the relation of representing-some-  thing standing in for some other state of affairs-is too simple to  capture the actual interaction between the governor and the engine.  If the centrifugal governor is not representational, then it cannot  be computational, at least in the specific sense that its processing  cannot be a matter of the rule-govemed manipulation of symbolic  representations. Its noncomputational nature can also be established  This content downloaded from  216.249.91.115 on Sat, 19 Oct 2024 13:58:06 UTC  All use subject to https://about.jstor.org/terms\n\n354   THEJOURNAL   OF   PHILOSOPHY  another way. Not only are there no representations to be manipu-  lated, there are no distinct manipulatings that might count as com-  putational operations. There are no discrete, identifiable steps in  which one representation gets transformed into another. Rather, the  system's entire operation is smooth and continuous; there is no pos-  sibility of nonarbitrarily dividing its changes over time into distinct  manipulatings, and no point in trying to do so. From this, it follows  that the centrifugal governor is not sequential and not cyclic in its  operation in anything like the manner of the computational gover-  nor. Since there are no distinct processing steps, there can be no se-  quence in which those steps occur. There is never any one operation  that must occur before another one can take place. Consequently,  there is nothing cyclical about its operation. The device has, to be  sure, an \"input\" end (where the spindle is driven by the engine) and  an \"output\" end (the connection to the throttle valve). But the cen-  trifugal governor does not follow a cycle where it first takes a mea-  surement, then computes a throttle valve change, then makes that  adjustment, then takes a measurement, and so on. Rather, input, in-  ternal activity, and output are all happening continuously and at the  very same time, much as a radio is producing music at the very same  time as its antenna is receiving signals.  The fact that the centrifugal governor is not sequential or cyclic in  any respect points to yet another deep difference between the two  kinds of govermor. There is an important sense in which time does not  matter in the operation of the computational governor. There is, of  course, the minimal constraint that the device must control the engine  speed adequately, and so individual operations within the device must  be sufficiently fast. There is also the constraint that internal operations  must happen in the right sequence. Beyond these, however, there is  nothing that dictates when each internal operation takes place, how  long it takes to carry it out, and how long elapses between each opera-  tion. There are only pragmatic implementation considerations: which  algorithms to use, what kind of hardware to use to run the algorithms,  and so forth. The liming of the internal operations is thus essentially  arbitrary relative to that of any wider course of events. It is as if the  wheel said to the governing system: \"Go away and figure out how much  to change the valve to keep me spinning at 100 rpm. I don't care how  you do it, how many steps you take, or how long you take over each  step, as long as you report back within (say) 10 milliseconds.\"  In the centrifugal governor, by contrast, there is simply nothing  that is temporally unconstrained in this way. There are no occur-  rences whose timing is arbitrary relative to the operation of the en-  This content downloaded from  216.249.91.115 on Sat, 19 Oct 2024 13:58:06 UTC  All use subject to https://about.jstor.org/terms\n\nWHAT MIGHT COGNITION BE, IF NOT COMPUTATION? 355  gine. All behavior in the centrifugal governor happens in the very  same real time frame as change in the speed of the flywheel. We can  sum up the point this way: the two kinds of governor differ funda-  mentally in their temporality, and the temporality of the centrifugal  governor is essentially that of the engine itself.  Finally, it need hardly be labored that the centrifugal governor is  not a homuncular system. It has parts, to be sure, and its overall be-  havior is the direct result of the organized interaction of those parts.  The difference is that those parts are not modules interacting by com-  munication; they are not like little bureaucratic agents passing repre-  sentations among themselves as the system achieves the overall task.  III. CONCEPTUAL FRAMEWORKS  In the previous section, I argued that the differences in nature be-  tween the two governors run much more deeply than the obvious dif  ferences in mechanical construction. Not surprisingly, these  differences in nature are reflected in the kind of conceptual tools that  we must bring to bear if we wish to understand the operation of these  devices. That is, the two different governors require very different con-  ceptual frameworks in order to understand how it is that they function  as governors, that is, how they manage to control their environment.  In the case of the computational governor, the behavior is captured  in all relevant detail by an algorithm, and the general conceptual  framework we are bringing to bear is that of mainstream computer sci-  ence. Computer scientists are typically concerned with what you can  achieve by stringing together, in an appropriate order, some set of  basic operations: either how best to string them together to achieve  some particular goal (programming, theory of algorithms), or what is  achievable in principle in this manner (computation theory). So we  understand the computational governor as a device capable of carry-  ing out some set of basic operations (measurings, subtractings, etc.),  and whose sophisticated overall behavior results from nothing more  than the complex sequencing of these basic operations. Note that  there is a direct correspondence between elements of the governor  (the basic processing steps it goes through) and elements of the algo-  rithm which describes its operation (the basic instructions).  The Watt centrifugal governor, by contrast, cannot be understood  this way at all. There is nothing in that device for any algorithm to  lock onto. Very different conceptual tools have always been applied  to this device. The terms in which it was described above, and indeed  by Watt and his peers, were straightforwardly mechanical: rotations,  spindles, levers, displacements, forces. Last century, more precise  and powerful descriptions became available, but these also have  This content downloaded from  216.249.91.115 on Sat, 19 Oct 2024 13:58:06 UTC  All use subject to https://about.jstor.org/terms\n\n356   THEJOURNAL   OF   PHILOSOPHY  nothing to do with computer science. In 1868, the physicist James  Clerk Maxwell5 made a pioneering extension of the mathematical  tools of dynamics to regulating and governing devices. The general  approach he established has been standard ever since. Though fa-  miliar to physicists and control engineers, it is less so to most cogni-  tive scientists and philosophers of mind, and hence is worth  describing in a little detail.  The key feature of the governor's behavior is the angle at which the  arms are hanging, for this angle determines how much the throttle  valve is opened or closed. Therefore, in order to understand the be-  havior of the governor, we need to understand the basic principles  governing how arm angle changes over time. Obviously, the arm angle  depends on the speed of the engine; hence we need to understand  change in arm angle as a function of engine speed. If we suppose for  the moment that the link between the governor and the throttle valve  is disconnected, then this change is given by the differential equation:  d   20   2g   dO  d2 = )2 cos 9sin 9--sin 9-r-  d   I~~~~~   dt  where 9 is the angle of arms, n is a gearing constant, w is the speed  of engine, g is a constant for gravity, 1 is the length of the arms, and r  is a constant of friction at hinges.6 This nonlinear, second-order dif-  ferential equation tells us the instantaneous acceleration in arm  angle, as a function of what the current arm angle happens to be  (designated by the state variable 9), how fast arm angle is currently  changing (the derivative of 9 with respect to time, dO/dt) and the  current engine speed (w). In other words, the equation tells us how  change in arm angle is changing, depending on the current arm  angle, the way it is changing already, and the engine speed. Note  that in the system defined by this equation, change over time occurs  only in arm angle 9 (and its derivatives). The other quantities (w, n,  g, 1, and r) are assumed to stay fixed, and are called parameters. The  particular values at which the parameters are fixed determine the  precise shape of the change in 9. For this reason, the parameter set-  tings are said to fix the dynamics of the system.  This differential equation is perfectly general and highly succinct:  it is a way of describing how the governor behaves for any arm angle  and engine speed. This generality and succinctness comes at a price,  however. If we happen to know what the current arm angle is, how  fast it is changing, and what the engine speed is, then from this  5 \"On Governors,\" Proceedings of the Rcyal Society, xvi (1868): 270-83.  6 EdwardBeltrami, Mathematicafor DnmicalModeling (Boston: Academic, 1987), p. 163.  This content downloaded from  216.249.91.115 on Sat, 19 Oct 2024 13:58:06 UTC  All use subject to https://about.jstor.org/terms\n\nWHAT   MIGHT   COGNITION   BE,   IF   NOT   COMPUTATION?   357  equation all we can figure out is the current instantaneous accelera-  tion. If we want to know at what angle the arms will be in a half-sec-  ond, for example, we need to find a solution to the general  equation-that is, an equation that tells us what values 9 takes as a  function of time, which satisfies the differential equation. There are  any number of such solutions, corresponding to all the different be-  havioral trajectories that the governor might exhibit, but these solu-  tions often have important general properties in common; thus, as  long as the parameters stay within certain bounds, the arms will al-  ways eventually settle into a particular angle of equilibrium for that  engine speed; that angle is known as a point attractor.  Thus far I have been discussing the governor without taking into  account its effect on the engine, and thereby indirectly on itself.  Here, the situation gets a little more complicated, but the same math-  ematical tools apply. Suppose we think of the steam engine itself as a  dynamical system governed by a set of differential equations, one of  which gives us some derivative of engine speed as a function of cur-  rent engine speed and a number of other variables and parameters:  d~ =F(wyT.)1 r .  dtn  One of these parameters is the current setting of the throttle valve,  T, which depends directly on the governor arm angle 9. We can thus  think of 9 as a parameter of the engine system, just as engine speed  w is a parameter of the governor system. (Alternatively, we can think  of the governor and steam engine as comprising a single dynamical  system in which both arm angle and engine speed are state vari-  ables.) This relationship, known as coupling, is particularly interest-  ing and subtle. Changing a parameter of a dynamical system changes  its total dynamics (that is, the way its state variables change their val-  ues depending on their current values, across the full range of values  they may take). Thus, any change in engine speed, no matter how  small, changes not the state of the governor directly, but rather the  way the state of the governor changes, and any change in arm angle  changes the way the state of the engine changes. Again, however, the  overall system (coupled engine and governor) settles quickly into a  point attractor, that is, engine speed and arm angle remain constant.  Indeed, the remarkable thing about this coupled system is that  under a wide variety of conditions it always settles swiftly into states at  which the engine is running at a particular speed. This is of course  exactly what is wanted: coupling the governor to the engine results  in the engine running at a constant speed.  This content downloaded from  216.249.91.115 on Sat, 19 Oct 2024 13:58:06 UTC  All use subject to https://about.jstor.org/terms\n\n358   THEJOURNAL   OF   PHILOSOPHY  In this discussion, two very broad, closely related sets of concep-  tual resources have (in a modest way) been brought into play. The  first is dynamical modeling, that branch of applied mathematics  which attempts to describe change in real-world systems by de-  scribing the states of the system numerically and then writing  equations that capture how these numerical states change over  time. The second set of resources is dynamical systems theory, the  general study of dynamical systems considered as abstract mathe-  matical structures. Roughly speaking, dynamical modeling at-  tempts to understand natural phenomena as the behavior of  real-world realizations of abstract dynamical systems, whereas dy-  namical systems theory studies the abstract systems themselves.  There is no sharp distinction between these two sets of resources,  and for our purposes they can be lumped together under the gen-  eral heading of dynamics.  IV. MORALS  This discussion of the governing task suggests a number of closely re-  lated lessons for cognitive science:  (1) Various different kinds of systems, fundamentally different in na-  ture and requiring very different conceptual tools for their under-  standing, can subserve sophisticated tasks-including interacting  with a changing environment-which may initially appear to de-  mand that the system have knowledge of, and reason about, its envi-  ronment. The governing problem is one simple example of such a  task; it can be solved either by a computational system or by a non-  computational dynamical system, the Watt centrifugal governor.  (2) In any given case, our sense that a specific cognitive task must be  subserved by a (generically) computational system may be due to  deceptively compelling preconceptions about how systems solving  complex tasks must work. Many people are oblivious to the possibil-  ity of a noncomputational, dynamical solution to the governing  problem, and so all-too-readily assume that it must be solved in a  computational manner. Likewise, it may be that the basically com-  putational shape of most mainstream models of cognition results  not so much from the nature of cognition itself as it does from the  shape of the conceptual equipment that cognitive scientists typically  bring to bear in studying cognition.  (3) Cognitive systems may in fact be dynamical systems, and cognition  the behavior of some (noncomputational) dynamical system.  Perhaps, that is, cognitive systems are more relevantly similar to the  centrifugal governor than they are similar either to the computa-  tional governor, or to that more famous exemplar of the broad cate-  gory of computational systems, the Turing machine.  This content downloaded from  216.249.91.115 on Sat, 19 Oct 2024 13:58:06 UTC  All use subject to https://about.jstor.org/terms\n\nWHAT MIGHT COGNITION BE, IF NOT COMPUTATION? 359  In what follows, the first and third of these points will be elabo-  rated in just enough detail to substantiate the basic claim of this  paper, that there is in fact a currently viable alternative to the  computational conception of cognition. As a first step toward  doing that, however, I shall briefly describe an example of dynami-  cal research in cognitive science, in order to provide what might  seem to be no more than rank speculation with a little healthy  flesh.  V. AN EXAMPLE OF DYNAMICAL RESEARCH  Consider the process of coming to make a decision between a va-  riety of options, each of which has attractions and drawbacks.  This is surely a high-level cognitive task, if anything is.  Psychologists have done endless experimental studies determin-  ing how people choose, and produced many mathematical mod-  els attempting to describe and explain their choice behavior. The  dominant approach in modeling stems from the classic expected-  utility theory and statistical decision theory as originally devel-  oped by John von Neumann and Oskar Morgenstern. The basic  idea here is that an agent makes a decision by selecting the op-  tion that has the highest expected utility, which is calculated in  turn by combining some formal measure of the utility of any  given possible outcome with the probability that it will eventuate  if the option is chosen. Much of the work within the classical  framework is mathematically elegant and provides a useful de-  scription of optimal reasoning strategies. As an account of the ac-  tual decisions people reach, however, classical utility theory is  seriously flawed; human subjects typically deviate from its recom-  mendations in a variety of ways. As a result, many theories incor-  porating variations on the classical core have been developed,  typically relaxing certain of its standard assumptions, with varying  degrees of success in matching actual human choice behavior.  Nevertheless, virtually all such theories remain subject to some  further drawbacks:  (1) They do not incorporate any account of the underlying motivations  that give rise to the utility that an object or outcome holds at a given  time.  (2) They conceive of the utilities themselves as static values, and  can offer no good account of how and why they might change  over time, and why preferences are often inconsistent and in-  constant.  (3) They offer no serious account of the deliberation process, with its  attendant vacillations, inconsistencies, and distress; and they have  This content downloaded from  216.249.91.115 on Sat, 19 Oct 2024 13:58:06 UTC  All use subject to https://about.jstor.org/terms\n\n360   THEJOURNAL   OF   PHILOSOPHY  nothing to say about the relationships that have been uncovered be-  tween time spent deliberating and the choices eventually made.  Curiously, these drawbacks appear to have a common theme; they all  concern, one way or another, temporal aspects of decision making. It  is worth asking whether they arise because of some deep structural  feature inherent in the whole framework which conceptualizes deci-  sion-making behavior in terms of calculating expected utilities.  Notice that utility-theory based accounts of human decision mak-  ing (\"utility theories\") are deeply akin to the computational solution  to the governing task. That is, if we take such accounts as not just de-  scribing the outcome of decision-making behavior, but also as a  guide to the structures and processes that underlie such behavior,7  then there are basic structural similarities to the computational gov-  ernor. Thus, utility theories are straightforwardly computational;  they are based on static representations of options, utilities, probabil-  ities, and so on, and processing is the algorithmically specifiable in-  ternal manipulation of these representations to obtain a final  representation of the choice to be made. Consequently, utility theo-  ries are strictly sequential; they presuppose some initial temporal  stage at which the relevant information about options, likelihoods,  and so on, is acquired; a second stage in which expected utilities are  calculated; and a third stage at which the choice is effected in actual  behavior. And, like the computational governor, they are essentially  atemporal; there are no inherent constraints on the timing of the  various internal operations with respect to each other or change in  the environment.  What we have, in other words, is a model of human cognition  which, on one hand, instantiates the same deep structure as the  computational governor, and on the other, seems structurally inca-  pable of accounting for certain essentially temporal dimensions of  decision-making behavior. At this stage, we might ask: What kind of  model of decision-making behavior we would get if, rather, we took  the centrifugal governor as a prototype? It would be a model with a  relatively small number of continuous variables influencing each  other in real time. It would be governed by nonlinear differential  equations. And it would be a model in which the agent and the  choice environment, like the governor and the engine, are tightly in-  terlocked.  7 See, for example, J.W. Payne, J.R. Bettman, and E.J. Johnson, \"Adaptive  Strategy Selection in Decision Making,\" Journal of Experimental Psychology: Learning  Memory, Cognition, xiv (1988): 534-52.  This content downloaded from  216.249.91.115 on Sat, 19 Oct 2024 13:58:06 UTC  All use subject to https://about.jstor.org/terms\n\nWHAT MIGHT COGNITION BE, IF NOT COMPUTATION? 361  It would, in short, be rather like the motivational oscillatory theory  (MOT) modeling framework described by mathematical psychologist  James Townsend.8 MOT enables modeling of various qualitative prop-  erties of the kind of cyclical behaviors that occur when circumstances  offer the possibility of satiation of desires arising from more or less  permanent motivations; an obvious example is regular eating in re-  sponse to recurrent natural hunger. It is built around the idea that in  such situations, your underlying motivation, transitory desires with re-  gard to the object, distance from the object, and consumption of it are  continuously evolving and affecting each other in real time; for exam-  ple, if your desire for food is high and you are far from it, you will  move toward it (that is, z changes), which influences your satiation  and so your desire. The framework thus includes variables for the cur-  rent state of motivation, satiation, preference, and action (move-  ment), and a set of differential equations describe how these variables  change over time as a function of the current state of the system.9  8 See \"A Neuroconnectionistic Formulation of Dynamic Decision Field Theory,\"  in D. Vickers and P.L. Smith, eds., Human Information Processing: Measures,  Mechanisms, and Models (Amsterdam: North Holland, 1988); and \"Don't Be Fazed  by PHASER: Beginning Exploration of a Cyclical Motivational System,\" Behavior  Research Methods, Instruments and Computers, xxiv (1992): 219-27.  9 The equations, with rough and partial translations into English, are:  dx M =   M   -m-   c  dt  (The change in motivation depends on how the current levels of motivation and of  consumption compare with some standard level of motivation, M)  dx _[ 1 +1  dt Lz2 +z+a z]2  (The change in one's preference for the goal will depend on current motivation and  one's distance from the object of preference.)  d= (x +C -c) 2  (The change in consumption will depend on the level of preference, the level of  consumption, and the distance from the object of preference.)  dzl   dz2  dt X 'Zl dt =-XZ2  (How one moves toward or away from the object depends on one's current  preference for the object.) See \"Don't Be Fazed by PHASER\" for an accessible and  graphic introduction to the behaviors defined by these equations.  This content downloaded from  216.249.91.115 on Sat, 19 Oct 2024 13:58:06 UTC  All use subject to https://about.jstor.org/terms\n\n362   THEJOURNAL   OF   PHILOSOPHY  MOT stands to utility theories in much the same relation as the  centrifugal governor does to the computational governor. In MOT,  cognition is not the manipulation of symbols, but rather state-space  evolution in a dynamical system. MOT models produce behavior  which, if one squints while looking at it, seems like decision mak-  ing-after all, the agent will make the move which offers the most re-  ward, which in this case means moving toward food if sufficiently  hungry. But this is decision making without decisions, so to speak,  for there never are in the model any discrete internal occurrences  that one could characterize as decisions. In this approach, decision  making is better thought of as the behavior of an agent under the in-  fluence of the pushes and pulls that emanate from desirable out-  comes, undesirable outcomes, and intermal desires and motivations;  in a quasi-gravitational way, these forces act on the agent with  strength varying as a function of distance.  The MOT modeling framework is a special case of a more general  (and rather more complex) dynamical framework which Townsend  and Jerome Busemeyer10 call \"decision field theory.\" That framework  allows faithful modeling of a wide range of behaviors more easily rec-  ognizable as decision making as studied within the traditional re-  search paradigm; indeed, their claim is that decision field theory  \"covers a broader range of phenomena in greater detail\" than classi-  cal utility theories, and even goes beyond them by explaining in a  natural way several important paradoxes of decision making, such as  the so-called \"common consequence effect\" and \"common ratio ef-  fect.\" The important point for immediate purposes, however, is that  the general decision field theory works on the same fundamental dy-  namical principles as MOT. There is thus no question that at least  certain aspects of human high-level cognitive functioning can be  modeled effectively using dynamical systems of the kind that can be  highlighted by reference to the centrifugal governor.  Thus far, all I have done is to use the governing problem as a  means of exploring some of the deep differences between computa-  tional and noncomputational solutions to complex tasks, drawn out  some suggestive implications for cognitive science, and used the  Busemeyer and Townsend work to illustrate the claim that high-  level cognitive processes can in fact be modeled using noncomputa-  10 \"Decision Field Theory. A Dynamic-Cognitive Approach to Decision Making in  an Uncertain Environment,\" Psychological Reviezv, c (1993): 432-59; an accessible  overview is given in \"Dynamic Representation of Decision Making,\" in R. Port and  myself, eds., Mind as Motion: Explorations in the Dynamics of Cognition (Cambrid  MIT, 1995).  This content downloaded from  216.249.91.115 on Sat, 19 Oct 2024 13:58:06 UTC  All use subject to https://about.jstor.org/terms\n\nWHAT MIGHT COGNITION BE, IF NOT COMPUTATION? 363  tional, dynamical systems. But these moves do not really describe an  alternative to the computational conception so much as just gesture  in that general direction. What we need now is a sharper characteri-  zation of the dynamical conception of cognition, and some reason  to suppose that the dynamical conception really is viable as a gen-  eral alternative.  VI. THREE CONCEPTIONS OF COGNITIVE SYSTEMS  At the outset of this paper, I suggested that in order properly to eval-  uate the computational conception of cognition, we really need to  know what viable alternatives there are (if any). Moreover, ideally, we  would have some understanding of what the entire range of alterna-  tives is, for only this way can we be sure that the candidates we are en-  tertaining are in fact the most relevant. In other words, we need to be  able to see the computational conception and its alternatives as op-  tions within a common field which contains all relevant possibilities.  Fortunately, the easiest way to present a sharpened characteriza-  tion of the dynamical approach is in fact to sketch a common field  within which can be situated, if not every conceivable option, at least  the current main contenders-the computational, connectionist,  and dynamical conceptions. The common field is the \"space\" of all  state-dependent systems. A (concrete) state-dependent system is a set  of features or aspects of the world which change over time interde-  pendently, that is, in such a way that the nature of the change in any  member of the system at a given time depends on the state of the  members of the system at that time.11 The most famous example  from the history of science is, of course, the solar system: the posi-  tions and momentums of the sun and various planets are constantly  changing in a way that always depends, in a manner captured in the  laws first laid down by Newton, on what they happen to be. Another  example is the Watt centrifugal governor, as described above: its fu-  ture arm angles are determined by its current arm angle (and cur-  rent rate of change of arm angle) according to its differential  equation. And for our purposes, another particularly important cate-  gory is that of computers: systems whose states are basically configu-  rations of symbols and whose state at time t + 1 is always determined  according to some rule by their state at time t.  Consider two centrifugal governors that are identical in all rele-  vant physical detail. These devices will respond in exactly the same  11 The notion of a state-dependent system is a generalization of that of a state-deter-  mined system (see Ross Ashby, Design for a Brain (London: Chapman and Hall,  1952)) to allow for systems in which the relation between change and current state  is stochastic rather than deterministic.  This content downloaded from  216.249.91.115 on Sat, 19 Oct 2024 13:58:06 UTC  All use subject to https://about.jstor.org/terms\n\n364   THEJOURNAL   OF   PHILOSOPHY  way to a given engine speed; that is, their arm angles will pass  through exactly the same sequences of positions over time. These  two concrete systems share an abstract structure in their behavior.  This structure can be distilled out, and its general properties stud-  ied, independently of any particular mechanical device. This math-  ematical structure is an example of an abstract state-dependent  system. Generally speaking, concrete systems belong to the real  world; they exist in time, and have states that change over time.  Abstract systems, on the other hand, exist only in the timeless and  changeless realm of pure mathematical form. They can be re-  garded as having three components: a,set of entities (for example,  the real numbers) constituting \"states\"; a set (for example, the in-  tegers) corresponding to points of \"time,\" and a rule of evolution  which pairs states with times to form sequences or trajectories.  Thus, even if no centrifugal governor had ever been invented,  mathematicians could study the abstract state-dependent system  (or rather, family of systems)  KR2, Rx d9 = ()2 cos 9 sin - gsin -r d-  where (9, d9/dt) picks out points in R2 (two dimensional Euclidean  space) and the differential equation determines sequences of such  points.  Abstract state-dependent systems can be realized (\"made real\") by  particular parts (sets of aspects) of the real, physical world, as when a  particular centrifugal governor realizes the abstract system just speci-  fied. An abstract system is realized by some part of the world when  we can systematically classify its states (for example, by measure-  ment) such that the sequences of states the concrete system under-  goes is found to replicate the sequences specified by the abstract  model. In fact, in order to count as a system at all, any concrete ob-  ject must realize some abstract system or other (but not vice versa).  Now, when cognitive scientists come to study cognitive systems,  whose basic nature is a matter for empirical investigation, they often  proceed by providing models. Generally speaking, a model is an-  other entity which is either better understood already, or somehow  more amenable to exploration, and which is similar in relevant re-  spects to the explanatory target. Scientific models are either con-  crete objects, or-more commonly-abstract mathematical entities;  very often, they can be understood as state-dependent systems. If a  model is sufficiently good, then we suppose that it somehow captures  the nature of the explanatory target. What does this mean? Well, if  This content downloaded from  216.249.91.115 on Sat, 19 Oct 2024 13:58:06 UTC  All use subject to https://about.jstor.org/terms\n\nWHAT MIGHT COGNITION BE, IF NOT COMPUTATION? 365  the model is an abstract state-dependent system, then we suppose  that the target system realizes the abstract system, or one relevantly  like it. If the model is a concrete system, then we suppose that the  model and the target system are systems of the same kind, in the  sense that they both realize the same abstract system (or relevantly  similar systems). Thus, even when providing a concrete model, what  the scientist is really interested in determining is the abstract struc-  ture in the behavior of the target system.  There is a vast range of abstract state-dependent systems. Schools  of thought which differ over the nature of cognition can be seen as  differing over which of these abstract systems are realized by cogni-  tive systems; or, put differently, as differing over where in the range of  all possible systems the best models of cognition are to be found. So  we can understand everyone as agreeing that cognitive systems are  state-dependent systems of some kind, but as disagreeing as to which  more particular category of state-dependent systems they belong. As  will be explained below, this disagreement by no means exhausts the  differences between the various schools of thought. Their differing  commitments as to the relevant category of systems do, however,  constitute a kind of core difference, around which their other differ-  ences can be organized.  1. The computational hypothesis. In one of the most well-known  presentations of the computational conception of cognition,  Newell and Herbert Simon'2 hypothesized that \"physical symbol  systems contain the necessary and sufficient means for general in-  telligent action,\" where a physical symbol system is \"a machine  that produces through time an evolving collection of symbol struc-  tures.\" Bearing this in mind, as well as other well-known character-  izations of essentially the same target (for example, John  Haugeland's definition of computers as interpreted automatic for-  mal sytems, and various paradigm examples of computational sys-  tems such as Turing machines, pocket calculators, and classic Al  systems such as Newell and Simon's GPS, Terry Winograd's  SHRDLU, and Doug Lenat's CYC)' we can characterize the com-  putational subcategory of state-dependent systems as follows: (ab-  12 \"Computer Science as Empirical Inquiry: Symbols and Search,\" in Haugelan  ed., Mind Design (Cambridge: MIT, 1981): pp. 35-66, here p. 40.  \"I See Haugeland, Artificial Intelligence: The Vety Idea (Cambridge: MIT, 1985);  Newell and Simon, \"GPS, A Program That Simulates Human Thought,\" in E.A.  Feigenbaum andJ. Feldman, eds., Computers and Thought (New York: McGraw-Hill,  1963); Terry Winograd, Understanding Natural Language (New York: Academic,  1972); D.B. Lenat and R.V. Guha, Building Large Knowledge-based Systems:  Representation and Inference in the CYC Proect (Reading, MA: Addison-Wesley, 1990).  This content downloaded from  216.249.91.115 on Sat, 19 Oct 2024 13:58:06 UTC  All use subject to https://about.jstor.org/terms\n\n366   THEJOURNAL   OF   PHILOSOPHY  stract) computational systems are abstract state-dependent systems  whose states are constituted in part by configurations of symbol  types, whose time set is the integers (or some equivalent set), and  whose rule of evolution specifies sequences of such configura-  tions. A concrete computational system-a computer-is any sys-  tem realizing an abstract computational system. In order to realize  such a system, some chunk of the actual world must realize the se-  quences of configurations of symbol types specified by the abstract  system. This means that, at any given time, it must contain an ap-  propriate configuration of tokens of the symbol types, and it must  change sequentially from one such configuration to another in ac-  cordance with the rule of evolution.  For example, consider a particular abstract Turing machine,  Minsky's four symbol, seven head-state universal Turing machine de-  fined by the following machine table:14  1   2   3   4   5   6   7  Y   _L1   _LI   YL3   YL4   YR5   YR6   _R7  _ -LI YR2 HALT YR5 YL3 AL3 YR6  1   1L2   AR2   AL3   1L7   AR5   AR6   1R7  A   ILl   YR6   1L4   1L4   1R5   1R6   _R2  This table dictates the specific symbol manipulations that take place  in the machine. (Thus, the first square tells us that, if the head is  currently in state 1 and the symbol in the cell over which the head is  positioned is a 'Y, then change that symbol to a \"_\" (blank), move  left, and \"change\" head state to state 1.) This machine constitutes  the abstract state-dependent system, represented  <{<s, p, h>}, I, F>  where each total state of the system at a given time is itself a triple  made up of a configuration of symbol types s (corresponding to the  contents of the entire tape), a head position with respect to that con-  figuration (p), and a head state (h). The rule of evolution F specifies  sequences of total states of the system by specifying what the next (or  successor) total state will be given the current total state; hence an  appropriate time set for this system is the integers (I). Fis essentially  equivalent to the machine table above, though the machine table  specifies local manipulations rather than transformations from one  total state to another. The rule can be obtained by reformulation of  the machine table; the result is simple in form but too ungainly to be  14 See Marvin Minsky, Computation: Finite and Infinite Machines (Englewood Cliffs,  NJ: Prentice-Hall, 1967).  This content downloaded from  216.249.91.115 on Sat, 19 Oct 2024 13:58:06 UTC  All use subject to https://about.jstor.org/terms\n\nWHAT MIGHT COGNITION BE, IF NOT COMPUTATION? 367  worth laying out here.\"5 Note that a computation, from this perspec-  tive, is a sequence of transitions from one total state of the computa-  tional system to another; or, in other words, a matter of touring the  system's symbolic state space.  A general form of the computational hypothesis, then, is that cog-  nitive systems such as people are computational systems in the sense  just defined, and that cognition is the behavior of such systems, that  is, sequences of configurations of symbols. An alternative form is that  for any given cognitive process, the best model of that process will be  drawn from the computational subcategory of systems.  Although, as mentioned above, their primary interest is in the  abstract structure of the target phenomenon, for various reasons  researchers in this approach standardly provide a concrete model:  an actual computer programmed so that (hopefully) it realizes the  same (or a relevantly similar) abstract computational system as is  realized by the cognitive systems under study. If the concrete  model appears able to perform actual cognitive tasks in much the  way people do, then the hypothesis that people are such systems is  supported. One reason to provide a concrete model is that the ab-  stract systems themselves are too complex to be studied by purely  analytical means. In order to determine whether the model has the  right properties, the theorist lets a concrete version run from a va-  riety of starting points (initial conditions), and observes its behav-  ior. Another reason for providing a concrete model is that, given  the complexity of the abstract systems, it is very difficult actually to  discover that structure except through an iterative procedure of  constructing a concrete model, testing it, making improvements,  and so on.  2. The dynamical hypothesis. Recall that one suggestion coming out  of the discussion of the centrifugal governor was that an interesting  alternative to the computational conception is that cognitive systems  may be dynamical systems. In order to characterize this position as an  alternative within the current framework, we need a definition of dy-  namical systems as a subcategory of state-dependent systems, a defin-  ition which is as useful as possible in clarifying differences among  various approaches to the study of cognition.  The centrifugal governor is a paradigm example of a dynamical  system. Perhaps the most pertinent contrast between it and the com-  putational governor is that the states through which it evolves are  not configurations of symbols but rather numerically measurable  Is See Marco Giunti, Computers, Dynamical Systems, Phenomena and the Mind, Ph.D.  Dissertation (Indiana University, 1991).  This content downloaded from  216.249.91.115 on Sat, 19 Oct 2024 13:58:06 UTC  All use subject to https://about.jstor.org/terms\n\n368   THEJOURNAL   OF   PHILOSOPHY  arm angles and rates of change of arm angle. Generalizing this fea-  ture, and, of course, looking over the shoulder at other textbook ex-  amples of dynamical systems and the kind of systems that are  employed by dynamicists in cognitive science, we can-define dynami-  cal systems as state-dependent systems whose states are numerical (in  the abstract case, these will be numbers, vectors, etc.; in the concrete  case, numerically measurable quantities) and whose rule of evolu-  tion specifies sequences of such numerical states.  The rule of evolution in the case of the centrifugal governor was a  differential equation. In general, a differential equation is any equa-  tion involving a function and one or more of its derivatives; infor-  mally, for current purposes, it can be thought of as an equation that  tells you the instantaneous rate of change of some aspect of the sys-  tem as a function of the current state of other aspects of the system.  Since our interest is in cognition as processes that occur in time, we  assume that the function is one of time (for example, @(t)) and that  any derivative involved is with respect to time (for example, d9/dt).  Because differential equations involve derivatives, they presuppose  continuity; hence the \"time\" set in an abstract dynamical system is  standardly R the real numbers. Dynamical systems governed by dif-  ferential equations are a particularly interesting and important sub-  category, not least because of their central role in the history of  science.16 But dynamical systems in the general sense just defined  might also be governed by difference equations, which specify the  state of the system at time t + 1 in terms of its state at time t:  St+ = F(st)  and determine sequences of states, or trajectories, by repeated appli-  cation or iteration. The \"time\" set for abstract systems defined by dif-  ference equations is standardly the integers. For example, one of the  most-studied families of dynamical systems is that defined by the dif-  ference equation known as the logistic map.7  <R I, x+, = axj(1 -)>  where a is a parameter; each possible value of a makes the rule dif-  ferent and hence defines a distinct system.  A concrete dynamical system, of course, is any concrete system  that realizes an abstract dynamical system. The realization relation-  16 See M. Hirsch, \"The Dynamical Systems Approach to Differential Equations,\"  Bulletin of the American Mathematical Society, xi (1984): 1-64.  17 For extensive discussion, see R.L. Devaney, An Introduction to Chaotic Dynamical  Systems (Menlo Park, CA.- Cummings, 1986).  This content downloaded from  216.249.91.115 on Sat, 19 Oct 2024 13:58:06 UTC  All use subject to https://about.jstor.org/terms\n\nWHAT MIGHT COGNITION BE, IF NOT COMPUTATION? 369  ship here is quite different than in the computational case, however.  Rather than configurations of tokens of symbol types, the concrete  dynamical system is made up of quantities changing in a way that  corresponds to the numerical sequences specified by the rule of evo-  lution. This correspondence is set up by measuring the quantities,  that is, by using some yardstick to assign a number to each quantity  at any given point in time. For example, in the case of the centrifu-  gal governor we set up a correspondence between the actual device  and the abstract mathematical system by using the \"degrees\" yard-  stick to assign a number (for example, 45) to the angle of the arm at  each point in time.  The dynamical hypothesis in cognitive science, then, is the exact  counterpart to the computational hypothesis: cognitive systems such  as people are dynamical systems in the sense just laid out, and cogni-  tion is state-space evolution in such systems. Alternatively, dynami-  cists are committed to the claim that the best model of any given  cognitive process will turn out to be drawn from the dynamical sub-  category of state-dependent systems.  As in the computational case, although the theorist's primary  goal is to identify the relevant abstract structure, it is often neces-  sary in practice to explore particular concrete models. It tends to  be difficult, however, to set up and explore the behavior of a con-  crete dynamical system with the right properties. Fortunately, there  is a convenient alternative: program (that is, physically configure)  a computer (a concrete computational system) so that it produces  sequences of symbol-configurations which represent points in the  state trajectories of the abstract dynamical model under considera-  tion. In such a situation, the computer does not itself constitute a  model of the cognitive process, since it does not contain numeri-  cally measurable aspects changing over time in the way that aspects  of the target system are hypothesized to be changing. That is, the  computer does not realize the abstract dynamical model; rather, it  simulates it.  3. The connectionist hypothesis. Broadly speaking, connectionists in  cognitive science are those who try to understand cognition using  connectionist models, which are typically characterized along some-  thing like the following lines:  Connectionist models are large networks of simple parallel computing  elements, each of which carries a numerical activation value which it  computes from the values of neighboring elements in the network,  using some simple numerical formula. The network elements, or units,  influence each other's values through connections that carry a numeri-  This content downloaded from  216.249.91.115 on Sat, 19 Oct 2024 13:58:06 UTC  All use subject to https://about.jstor.org/terms\n\n370   THEJOURNAL   OF   PHILOSOPHY  cal strength, or weight The influence of each unit i on unit j is the acti-  vation value of unit i times the strength of the connection from i to j.l8  In order to comprehend connectionism within the current frame-  work, we need to characterize connectionist models as a particular  subcategory of state-dependent systems. It is clear from the descrip-  tion just given, however, that all connectionist models are dynamical  systems in the sense of the previous section. If the network has n  neural units, then the state of the system at any given time is just an  n-dimensional vector of activation values, and the behavior of the  network is a sequence of such vectors determined by the equations  that update unit activation values. There are, of course, innumerable  variations on this basic structure, and much connectionist work con-  sists in exploring such variations in order to find a good model of  some particular cognitive phenomenon.  Why then is connectionism not simply the same thing as the dynami-  cal conception? There are two reasons, one discussed in this section,  the other in the next. The first is that connectionist models are only a  particular subcategory of the wider class of dynamical systems. The core  connectionist hypothesis, that the best model of any given cognitive  process will be a connectionist model, is thus best regarded as a more  specific version of the wider dynamical hypothesis. There are plenty of  dynamical systems that are not connectionist networks, and plenty of  dynamicists in cognitive science who are not connectionists (for exam-  ple, Busemeyer and Townsend in the work described above).  What then makes a dynamical system a connectionist system?  Roughly, it should conform to the Smolensky characterization  above. What this means in terms of species of dynamical state-depen-  dent systems can be seen by examining a typical connectionist sys-  tem, and noting those basic features which contrast with, for  example, the centrifugal governor or the MOT model.  Connectionist researchers Sven Anderson and Robert Port'9 used  the following quite typical abstract connectionist dynamical system as  a model of certain aspects of auditory pattern recognition:  (Rn~   R1   +   (riyi   +(t)   I,(t)+  dt   ~   ~   +   e   -   wjjy   +   i()+o  18   Paul   Smolensky,   \"On   the   Proper   Treatment   of   Connect  Brain Sciences, xi (1988): 1-74, here p. 1.  19 \"A Network Model of Auditory Pattern Recognition,\" Technical Report xi  (Indiana University Cognitive Science Program, 1990).  This content downloaded from  216.249.91.115 on Sat, 19 Oct 2024 13:58:06 UTC  All use subject to https://about.jstor.org/terms\n\nWHAT MIGHT COGNITION BE, IF NOT COMPUTATION? 371  The network had n neural units, each with a real activation value  Yi. Hence its states were points in an n-dimensional space of real  numbers, that is, elements of RI; its time set was R, and its evolu-  tion equation was the differential equation given (in schema  form) above, which specifies the instantaneous rate of change in  each yi as a function of its current value, a decay parameter (Ti),  the activation of other units (yj), the connection weights (wij),  any external input (Ii), and a threshold or bias term (9,). For cur-  rent purposes it is not necessary fully to understand this \"simple  numerical formula\" or the behavior of the system as a whole. Of  significance here are three closely related properties of con-  nectionist systems that it illustrates. Connectionist systems are  typically:  High-dimensionaL: connectionist networks standardly contain tens, or  even hundreds or more, of neural units, each corresponding to a di-  mension of the state space. This makes them considerably larger in  dimension than systems found in many other standard dynamical in-  vestigations in cognitive science, other sciences such as physics, and  pure mathematics.  Homogeneous: connectionist networks are homogenous in the sense that  they are made up of units that all have basically the same form; or, as  Randy Beer has put the point, which are just parametric variations  on a common theme. Thus, in the system above, a single equation  schema suffices to describe the behavior of every unit in the net-  work, with just the particular parameter values being specific to each  unit.  \"Neurar': connectionist systems are made up of units which are con-  nected with others and which adjust their activation as a function of  their total input, that is, of the summed weighted activations of other  units. This structural property is reflected in the form of the evolu-  tion equations for connectionist models. Thus, the connectionist  equation schema above includes the term IwXjyj which stands for  summed input to a unit. The defining equations of connectionist sys-  tems always include a term of this general kind.  None of these properties obtains in the case of the centrifugal gover-  nor, nor in the case of the MOT model described above; both, there-  fore, count as good examples of nonconnectionist dynamical  systems.  4. Hypotheses and worldviews. Thus far, the differences between the  computationalist, dynamicist, and connectionist conceptions of cog-  nition have been described simply in terms of differing commit-  ments as to where in the space of state-dependent systems the best  models of cognition are likely to be found. Yet each of these ap-  This content downloaded from  216.249.91.115 on Sat, 19 Oct 2024 13:58:06 UTC  All use subject to https://about.jstor.org/terms\n\n372   THEJOURNAL   OF   PHILOSOPHY  proaches is much more richly textured than this implies; they can  and should be compared and contrasted in other ways as well.  At this point, the discussion of schools of thought in cognitive sci-  ence connects with the earlier discussion of the governing problem.  Recall that one suggestion emerging there was that cognitive sys-  tems may in fact be more similar to the centrifugal governor than to  the computational governor. Recall also that the two kinds of gover-  nor were found to contrast at two distinct \"levels\"-that of basic  properties (representation, computation, cyclic, etc.) and that of  relevant conceptual framework; and that there was a kind of natural  fit between these levels. It turns out that this fit is really three-way: if  you have a computational state-dependent system, it naturally im-  plements a system that is representational, sequential, cyclic, ho-  muncular, and so on, and the most appropriate conceptual  framework to bring to bear on a system that is computational at  both these levels is, of course, that of computer science and main-  stream computational cognitive science. Computationalists in cogni-  tive science do not merely select models from a particular region of  the space of abstract state-dependent systems; they also make strong  presuppositions about the basic overall structure of cognitive sys-  tems and they use corresponding tools in thinking about how cogni-  tive systems work.  In other words, taking cognitive systems to be state-dependent sys-  tems that proceed from one configuration of symbols to the next is  part and parcel of a general vision of the nature of cognitive systems.  For computationalists, the cognitive system is basically the brain,  which is a kind of control unit located inside a body which in turn is  located in an external environment. The cognitive system interacts  with the outside world via its more direct interaction with the body.  Interaction with the environment is handled by sensory and motor  transducers, whose function is to translate between the purely physi-  cal events in the body and the environment and the symbolic states  that are the medium of cognitive processing. The sense organs con-  vert physical stimulation into elementary symbolic representations of  events in the body and in the environment, and the motor system  converts symbolic specifications of actions into movements of the  muscles. Cognitive episodes take place in a cyclic and sequential  fashion; first there is sensory input to the cognitive system, then the  cognitive system algorithmically manipulates symbols, coming up  with an output which then causes movement of the body; then the  whole cycle then begins again. Internally, the cognitive system has a  modular, hierarchical construction; at the highest level, there are  This content downloaded from  216.249.91.115 on Sat, 19 Oct 2024 13:58:06 UTC  All use subject to https://about.jstor.org/terms\n\nWHAT MIGHT COGNITION BE, IF NOT COMPUTATION? 373  modules corresponding to vision, language, planning, and so on,  and each of these modules breaks down into simpler modules for  more elementary tasks. Each module replicates in basic structure the  cognitive system as a whole; thus, they take symbolic representations  as inputs, algorithmically manipulate those representations, and de-  liver a symbolic specification as output. Note that because the cogni-  tive system traffics only in symbolic representations, the human body  and the physical environment can be dropped from consideration; it  is possible to study the cognitive system as an autonomous, bodiless,  and worldless system whose function is to transform input represen-  tations into output representations.  In short, in the computational vision, cognitive systems are the  computational governor writ large. Of course, there are innumer-  able variants on the basic computational picture; any one might di-  verge from the standard picture in some respects, but still remain  generically computational in nature (for example, symbolic models  that utilize some measure of parallel processing).  The dynamical conception of cognition likewise involves interde-  pendent commitments at three distinct levels, but stands opposed to  the computational conception in almost every respect. The core dy-  namical hypothesis-that the best models of any given cognitive  process will specify sequences, not of configurations of symbol types,  but rather of numerical states-goes hand in hand with a conception  of cognitive systems not as devices that transform symbolic inputs  into symbolic outputs but rather as complexes of continuous, simul-  taneous, and mutually determining change, for which the tools of  dynamical modeling and dynamical systems theory are most appro-  priate. In this vision, the cognitive system is not just the encapsulated  brain; rather, since the nervous system, body, and environment are  all constantly changing and simultaneously influencing each other,  the true cognitive system is a single unified system embracing all  three. The cognitive system does not interact with the body and the  external world by means of the occasional static symbolic inputs and  outputs; rather, interaction between the inner and the outer is best  thought of as a matter of coupling, such that both sets of processes  continually influencing each other's direction of change. At the level  at which the mechanisms are best described, cognitive processing is  not sequential and cyclic, for all aspects of the cognitive system are  undergoing change all the time. Any sequential character in cogni-  tive performance is the high-level, overall trajectory of change in a  system whose rules of evolution specify not sequential change but  rather simultaneous mutual coevolution.  This content downloaded from  216.249.91.115 on Sat, 19 Oct 2024 13:58:06 UTC  All use subject to https://about.jstor.org/terms\n\n374   THEJOURNAL   OF   PHILOSOPHY  Where does connectionism fit into all this? Perched somewhere in  the middle. Recall that connectionist models are dynamical systems,  but that there are reasons not simply to assimilate the connectionist  and dynamical conceptions. The first was that connectionist models  are really a quite specific kind of dynamical system. What we can now  add is that although many connectionists are thoroughly dynamical  in their general vision of the nature of cognitive systems, many oth-  ers attempt to combine their connectionist dynamical substrates with  an overall conception of the nature of cognitive systems which owes  more to the computational worldview. Thus, consider \"good old  fashioned connectionism\": standard, layered-network back-propaga-  tion connectionism of the kind that became fashionable with the  well-known 1986 volumes. A classic exemplar is David Rumelhart  and James McClelland's20 past-tense learning model. In this kind of  work, underlying systems that are basically dynamical in nature are  configured so as sequentially to transform static input representa-  tions into output representations. They retain much of the basic  structure of the computational picture, changing some ingredients  (in particular, the nature of the representations) but retaining oth-  ers. Connectionism of this kind can be regarded as having taken up  a half-way house between the computational and dynamical concep-  tions, combining ingredients from both in what may well turn out to  be an unstable mixture. If this is right, we should expect as time goes  on that such connectionist models will increasingly give way either to  implementations of generically computational conceptions of cogni-  tion, or to models that are more thoroughly dynamical.  VII. IS THE DYNAMICAL CONCEPTION VIABLE?  In order soundly to refute the \"what else could it be?\" argument, a  proposed alternative must be viable, that is, plausible enough that it  is reasonably deemed an open empirical question whether the ortho-  dox approach, or the alternative, is the more correct.  One measure of the viability of an approach is whether valuable  research can be carried out within its terms. On this measure, the dy-  namical approach is certainly in good health. Dynamical theories  and models have been or are being developed of a very wide range  of aspects of cognitive functioning, from (so-called) low-level or pe-  ripheral aspects such as brain function, perception, and motor con-  trol, to (so-called) central or higher aspects such as language and  20 \"On Learning the Past Tenses of English Verbs,\" in McClelland and  Rumelhart, eds., Parallel Distributed Processing: Explorations in the Micro  Cognition, Volume II: Psychological and Biological Models (Cambridge: MIT, 1986), pp.  216-68.  This content downloaded from  216.249.91.115 on Sat, 19 Oct 2024 13:58:06 UTC  All use subject to https://about.jstor.org/terms\n\nWHAT MIGHT COGNITION BE, IF NOT COMPUTATION? 375  decision making, and through to related areas such as psychiatry and  social psychology. As already mentioned, a good deal of connection-  ist work falls under the dynamical banner, and this work alone would  qualify the dynamical approach as worth taking seriously. But there  are nonconnectionist dynamical models of numerous aspects of cog-  nition, and their ranks are swelling. In a number of fields under the  broader umbrella of cognitive science, dynamics provides the domi-  nant formal framework within which particular theories and models  are developed: these include neural modeling, autonomous agent  (\"animat\") research, ecological psychology, and, increasingly, devel-  opmental psychology.2\"  Of course, it is quite possible that a research program is flourish-  ing, and yet there be deep reasons why it will eventually prove inad-  equate, either in general or with respect to particular aspects of  cognition. (Consider behaviorism in its hey-day, for example.) In  evaluating the plausibility of an alternative, we should also consider  whether there are known general considerations that either strongly  support-or, perhaps more importantly, stand opposed to-that  approach.  Many considerations have been raised in favor of the computa-  tional conception of cognition, and, given the deep differences be-  tween the approaches, each might appear to constitute an  argument against the dynamical alternative. It is not possible ade-  quately to address all (or even any) such arguments here, but I shall  briefly comment on two of the most powerful, in order to reveal not  the weakness but rather something of the potential of the dynami-  cal approach.  Cognition is distinguished from other kinds of complex natural  processes (such as thunderstorms, subatomic processes, etc.) by at  21 Rather than cite individual examples, I merely list here some overvie  collections that the interested reader can use as a bridge into the extensive realm  of dynamical research on cognition. A broad sampling of current research is  contained in Mind as Motion: Explorations in the Dynamics of Cognition; this book  contains guides to a much larger literature. An excellent illustration of the  power and scope of dynamical research, in a neural network guise, is S.  Grossberg, ed., Neural Networks and Natural Intelligence (Cambridge: MIT, 1988).  R. Serra and G. Zanarini, Complex Systems and Cognitive Processes (Berlin: Springer,  1990) presents an overview of a variety of dynamical systems approaches in artifi-  cial intelligence research. For the role of dynamics in developmental psychol-  ogy, see Esther Thelen and Linda Smith, A Dynamics Systems Approach to the  Development of Cognition and Action (Cambridge: MIT, 1993) and Dynamic Systems  in Development: Applications (Cambridge: MIT, 1993). Hermann Haken, Synergetic  Computers and Cognition: A Top-down Approach to Neural Nets (Berlin: Springer,  1991) provides an introduction and overview to the \"synergetic\" form of the dy-  namical approach.  This content downloaded from  216.249.91.115 on Sat, 19 Oct 2024 13:58:06 UTC  All use subject to https://about.jstor.org/terms\n\n376   THEJOURNAL   OF   PHILOSOPHY  least two deep features: on one hand, a dependence on knowledge;  and distinctive kinds of complexity, as manifested most clearly in the  structural complexity of natural languages. One challenge for cogni-  tive scientists is to understand how a physical system might exhibit  these features.  The usual approach to explaining the dependence on knowledge  is to suppose that the system contains internal structures that repre-  sent that knowledge. Further, the most powerful known way of doing  this is to use symbolic representations, manipulated by some compu-  tational system. Insofar as the dynamical approach abjures represen-  tation completely, or offers some less powerful representational  substitute, it may seem doomed.  While the centrifugal governor is clearly a nonrepresentational  dynamical system, and while it was argued above that representation  figures in a natural cluster of deep features that are jointly charac-  teristic of computational models, in fact there is nothing preventing  dynamical systems from incorporating some form of representation;  indeed, an exciting feature of the dynamical approach is that it  offers opportunities for dramatically reconceiving the nature of rep-  resentation in cognitive systems, even within a broadly noncom-  putational framework. A common strategy in dynamical modeling is  to assign representational significance to some or all of the state  variables or parameters (for example, see the Townsend and  Busemeyer decision field theory model described above, or con-  sider a connectionist network in which units stand for features of  the domain). While representations of this kind may be exactly what  is needed for some cognitive modeling purposes, they do not have  the kind of combinatorial structure that is often thought necessary  for other aspects of high-level cognition. Within the conceptual  repertoire of dynamics, however, there is a vast range of entities and  structures that might be harnessed into representational roles; indi-  vidual state variables and parameters are merely the simplest of  them. For example, it is known how to construct representational  schemes in which complex contents (such as linguistic structures)  are assigned in a recursive manner to points in the state space of a  dynamical system, such that the representations form a fractal struc-  ture of potentially infinite depth, and such that the behavior of the  system can be seen as transforming representations in ways that re-  spect the represented structure.22 Yet even these methods are doing  little more than dipping a toe into the pool of possibilities. For ex-  22 See, for example, Jordan Pollack, \"Recursive Distributed Representations,\"  Artificial Intelligence, XLVI (1990): 77-105.  This content downloaded from  216.249.91.115 on Sat, 19 Oct 2024 13:58:06 UTC  All use subject to https://about.jstor.org/terms\n\nWHAT MIGHT COGNITION BE, IF NOT COMPUTATION? 377  ample, representations can be trajectories or attractors of various  kinds, or even such exotica as transformations of attractor arrange-  ments as a system's control parameters change.23 Dynamicists are ac-  tively exploring how these and other representational possibilities  might be incorporated into cognitive models, without buying the  rest of the computational worldview. Consequently, while the dy-  namical approach is certainly a long way from having actual solu-  tions to most concrete problems of knowledge representation, it  clearly holds sufficient promise to maintain its current viability as an  alternative.  What, then, about arguments that are based on the distinctive  complexity of human cognition? Perhaps the most common, and  probably the most persuasive argument of this kind focuses on the  complexity of sentences of natural language. It begins from the oW  servation that any proficient language user can understand and pro-  duce an effectively unbounded number of distinct sentences, and  proceeds to note that these sentences can manifest phenomena such  as repeated embedding and dependencies over arbitrarily long dis-  tances. If we attempt to describe languages with this kind of com-  plexity by means of a grammar (a finite set of rules for combining a  finite set of primitive elements into complex structures), we find  they can only be compactly specified by grammars more powerful  than so-called \"regular\" or \"phrase-structure\" grammars. If we then  ask what kind of computational device is capable of following the  rules of these grammars to recognize or produce such sentences, the  answer is that they can only be implemented on machines more pow-  erful than finite-state machines, such as push-down automata or lin-  ear-bounded automata. Therefore, human cognitive systems must be  one of these more powerful computational systems.  A crucial question, then, is whether there is reason to believe that  dynamical systems, with their numerical states and rules of evolution  defined over them, are capable of exhibiting this order of complex-  ity in behavior. The investigation of the \"computational\" power of  dynamical systems, especially in the form of neural networks, is a rel-  atively new topic, but there is already a sizable literature and results  available indicate a positive answer. For example, J. P. Crutchfield  and K. Young24 have studied the complexity of the behavior in cer-  23 See, for example, Jean Petitot, \"Morphodynamics and Attractor Syntax,\" in  Mind as Motion: Explorations in theDynamics of Cognition.  24 See J.P. Crutchfield and K Young, \"Computation at the Onset of Chaos,\" in  W.H. Zurek, ed., Complexity, Entropy, and the Physics of Information, SFI Studies in the  Sciences of Complexity, Volume vWi' (Reading, MA: Addison-Wesley, 1990).  This content downloaded from  216.249.91.115 on Sat, 19 Oct 2024 13:58:06 UTC  All use subject to https://about.jstor.org/terms\n\n378   THEJOURNAL   OF   PHILOSOPHY  tain nonlinear dynamical systems \"at the edge of chaos\" (that is, at  settings of parameters close to those settings which would produce  genuinely chaotic behavior). If passing through a particular region  of the state space is counted as producing a symbol, then allowing  the system to run produces a sequence of symbols. It turns out that  the complexity of these sequences is such that describing them re-  quires an indexed context-free grammar. This means that the system  is producing behavior of the same broad order of complexity as  many believe natural language to possess.  Similarly, Jordan Pollack25 has studied the ability of connectionist  dynamical systems to recognize languages (that is, to indicate  whether or not any given sequence belongs to the language). In his  networks, the system bounces around its numerical state space under  the influence of successive inputs corresponding to symbols in the  sequence to be recognized. A well-formed sequence is regarded as  successfully recognized if the system ends up in a particular region  after exposure to the whole sentence, while ending up in some other  region for non-well-formed sequences. Pollack (among others) has  found that there are networks that can recognize nonregular lan-  guages, and in fact can learn to have this ability, via a novel form of  induction in language learning, involving bifurcations in system dy-  namics which occur as the weights in the network gradually change.  More generally, it is clear that nonlinear dynamical systems can  not only match but exceed the complexity of behavior of standard  computational systems such as Turing machines.26 Of course, this  alone by no means establishes that cognitive systems are, or are more  likely to be, dynamical systems than computational systems. It does  establish that the dynamical approach is not automatically ruled out  by these kinds of complexity considerations. What kind of system hu-  mans in fact are is therefore a question only to be resolved by means  of patient and detailed modeling.  So much for defenses of viability. What positive reasons are there  to think that the dynamical approach is actually on the right track?  Again, space does not allow serious treatment of these arguments,  but some are at least worth mentioning. In practice, an important  part of the appeal of the dynamical approach is that it brings to the  study of cognition tools that have proved so extraordinarily success-  25 \"The Induction of Dynamical Recognizers,\" Machine Learning, viI (1991):  227-52.  26 See, for example, Hava Siegelmann and Eduardo Sontag, \"Analog  Computation via Neural Networks,\" Theoretical Computer Science, cxxx, 1 (1994):  331-60.  This content downloaded from  216.249.91.115 on Sat, 19 Oct 2024 13:58:06 UTC  All use subject to https://about.jstor.org/terms\n\nWHAT MIGHT COGNITION BE, IF NOT COMPUTATION? 379  ful in so many other areas of science. But what is there about cogni-  tion, in particular, which suggests that it will be best understood dy-  namically?  One central fact about natural cognitive processes is that they al-  ways happen in time, which means not merely that, like any physical  process including ordinary digital computation, they occupy some  extent of actual time, but that details of timing (durations, rates,  rhythms, etc.) are critical to a system that operates in a real body and  environment. As we saw above, dynamics is all about describing how  processes happen in time, while computational models are inher-  ently limited in this respect. Cognition also has other general fea-  tures for which a dynamical approach appears particularly  well-suited. For example, it is a kind of complex behavioral organiza-  tion that is emergent from the local interactions of very large num-  bers of (relatively) simple and homogenous elements. It is pervaded  by both continuous and discrete forms of change. At every level, it  involves multiple, simultaneous, interacting processes. Dynamics is a  natural framework for developing theories that account for such fea-  tures. Further, that within which cognition takes place (the brain,  the body, and the environment) demand dynamical tools in their de-  scription. A dynamical account of cognition promises to minimize  difficulties in understanding how cognitive systems are real biologi-  cal systems in constant, intimate dependence on, or interaction with,  their surrounds.27  A final way to underpin the viability of the dynamical conception  is to place it and the computational conception in broad historical  perspective. Computationalism, as cognitive science orthodoxy,  amounts to a sophisticated instantiation of the basic outlines of a  generically Cartesian picture of the nature of mind. Conversely, the  prior grip that this Cartesian picture has on how most people think  about mind and cognition makes the computational conception in-  tuitively attractive to many people. This would be unobjectionable if  the Cartesian conception was basically sound. But the upshot of  philosophical evaluation of the Cartesian framework over the last  three centuries, and especially this century, is that it seriously mis-  conceives mind and its place in nature. Cognitive scientists tend to  suppose that the primary respect in which Descartes was wrong  about mind was in subscribing to an interactionist dualism, that is,  that doctrine that mind and body are two distinct substances that  27 For more detailed treatment of these and other arguments, see Port and m  \"It's about Time: An Overview of the Dynamical Approach to Cognition,\" in Mind  as Motion: Explorations in the Dynamics of Cognition.  This content downloaded from  216.249.91.115 on Sat, 19 Oct 2024 13:58:06 UTC  All use subject to https://about.jstor.org/terms\n\n380   THEJOURNAL   OF   PHILOSOPHY  causally interact with one another. Already by the eighteenth cen-  tury, however, the inadequacy of this particular aspect of  Cartesianism had been repeatedly exposed, and thoroughgoing  brain-based materialisms had been espoused by philosophers such as  Thomas Hobbes and Julien Offray de La Mettrie. Some of the great-  est achievements of twentieth-century philosophy of mind have been  the exposing of various other, more subtle, pervasive, and pernicious  epistemological and ontological misconceptions inherent in the  Cartesian picture. These misconceptions are very often retained  even when substance dualism is rejected in favor of some brain-  based materialism, such as functionalism in its various guises.  For current purposes, one of the most important anti-Cartesian  movements is the one spearheaded by Gilbert Ryle in Anglo-  American philosophy and Martin Heidegger in \"continental\" philos-  ophy.28 Its target has been the generically Cartesian idea that mind is  an inner realm of representations and processes, and that mind con-  ceived this way is the causal underpinning of our intelligent behav-  ior. This movement comprises at least three major components, all  intimately interrelated. The first is a relocating of mind. The  Cartesian tradition is mistaken in supposing that mind is an inner  entity of any kind, whether mind-stuff, brain states, or whatever.  Ontologically, mind is much more a matter of what we do within en-  vironmental and social possibilities and bounds. Twentieth-century  anti-Cartesianism thus draws much of mind out, and in particular  outside the skull. The second component is a reconceiving of our  fundamental relationship to the world around us. In the Cartesian  framework, the basic stance of mind toward the world is one of rep-  resenting and thinking about it, with occasional, peripheral, causal  interaction via perception and action. It has been known since  Bishop Berkeley that this framework had fundamental epistemologi-  cal problems. It has been a more recent achievement to show that es-  caping these epistemological problems means reconceiving the  human agent as essentially embedded in, and skillfully coping with, a  changing world; and that representing and thinking about the world  is secondary to and dependent upon such embeddedness.29 The  third component is an attack on the supposition that the kind of be-  haviors we exhibit (such that we are embedded in our world and can  28 See Ryle, The Concept of Mind (Chicago: University Press, 1984); Heidegger,  Being and Time, John Macquarrie and Edward Robinson, trans. (New York: Harper,  1962); and Hubert Dreyfus, Being-in-the-World: A Commentary on Heidegger's Being  and Time, Division I (Cambridge: MIT, 1991).  29 See Charles Guignon, Heidegger and the Problem of Knowledge (Indianapolis:  Hackett, 1983).  This content downloaded from  216.249.91.115 on Sat, 19 Oct 2024 13:58:06 UTC  All use subject to https://about.jstor.org/terms\n\nWHAT   MIGHT   COGNITION   BE,   IF   NOT   COMPUTATION?   381  be said to have minds) could ever be causally explained utilizing  only the generically Cartesian resources of representations, rules,  procedures, algorithms, and so on. A fundamental Cartesian mistake  is, as Ryle variously put it, to suppose that practice is accounted for  by theory; that knowledge how is explained in terms of knowledge  that; or that skill is a matter of thought. That is, not only is mind not  to be found wholly inside the skull; cognition, the inner causal un-  derpinning of mind, is not to be explained in terms of the basic enti-  ties of the Cartesian conception of mind.  My concern here is not to substantiate these claims or the post-  Cartesian conception of the person to which they point;30 it is simply  to make the computational conception of cognition seem less than  inevitable by pointing out that serious doubt has been cast upon the  philosophical framework in which it is embedded. Orthodox compu-  tational cognitive science has absorbed some of the important lessons  of seventeenth-century reactions to Cartesianism, but so far has re-  mained largely oblivious to the more radical twentieth-century cri-  tiques. Conversely, if we begin with a thoroughly post-Cartesian  approach, the dynamical account of cognition will, in many ways, be  immediately attractive. The post-Cartesian conception rejects the  model of mind as an atemporal representer and, like the dynamical  approach to cognition, emphasizes instead the ongoing, real-time in-  teraction of the situated agent with a changing world. The post-  Cartesian agent is essentially temporal, since its most basic  relationship to the world is one of skillful coping; the dynamical  framework is a therefore natural choice since it builds time in right  from the very start. The post-Cartesian agent manages to cope with  the world without necessarily representing it; a dynamical approach  suggests how this might be possible by showing how the internal oper-  ation of a system interacting with an external world can be so subtle  and complex as to defy description in representational terms-how,  in other words, how cognition can transcend representation. In short,  from the philosophical perspective that has managed to overcome  the deep structures of the Cartesian world view, the dynamical ap-  proach looks distinctly appealing; the Watt governor is preferable to  the Turing machine as a landmark for models of cognition.  TIM VAN GELDER  University of Melbourne  3' Dreyfus, What Computers Still Can't Do: A Critique of Artificial Reason  (Cambridge: MIT, 1992) is excellent in this regard.  This content downloaded from  216.249.91.115 on Sat, 19 Oct 2024 13:58:06 UTC  All use subject to https://about.jstor.org/terms\n\n",
  "fileName": "Gelder-MightCognitionBe-1995.pdf",
  "axioms": [
    {
      "id": "Axiom_Orthodoxy",
      "status": "Material",
      "logic": {
        "id": "Axiom_Orthodoxy",
        "premises_symbolic": [
          "n(Cognition)"
        ],
        "conclusion_symbolic": "comp_nec(s(Representation) & n(Algorithm))",
        "polarity": "compressive"
      },
      "translation": {
        "axiom_id": "Axiom_Orthodoxy",
        "plain_english": "If something is defined as Cognition under the Orthodox view, it necessitates the existence of internal symbolic Representations and rule-governed Algorithms.",
        "source_passage": "Contemporary orthodoxy maintains that it is computation... cognitive processes are the rule-governed manipulation of internal symbolic representations."
      },
      "history": [
        "[Global] Created",
        "[Chunk 1/12] Updated"
      ]
    },
    {
      "id": "Axiom_Watt_Refutation",
      "status": "Material",
      "logic": {
        "id": "Axiom_Watt_Refutation",
        "premises_symbolic": [
          "o(Watt_Governor)",
          "n(Control)"
        ],
        "conclusion_symbolic": "~comp_nec(s(Representation) | n(Algorithm))",
        "polarity": "expansive"
      },
      "translation": {
        "axiom_id": "Axiom_Watt_Refutation",
        "plain_english": "The existence of the Watt Governor proves that achieving the normative goal of Control does not necessitate the use of Representations or Algorithms.",
        "source_passage": "the Watt centrifugal governor does not exhibit this cluster of properties as a whole, nor any one of them individually."
      },
      "history": [
        "[Global] Created",
        "[Chunk 2/12] Updated"
      ]
    },
    {
      "id": "Axiom_Dynamical_Hypothesis",
      "status": "Material",
      "logic": {
        "id": "Axiom_Dynamical_Hypothesis",
        "premises_symbolic": [
          "exp_nec(Cognition)"
        ],
        "conclusion_symbolic": "o(Coupling) & o(State_Space_Evolution)",
        "polarity": "expansive"
      },
      "translation": {
        "axiom_id": "Axiom_Dynamical_Hypothesis",
        "plain_english": "Cognition, viewed through expansive necessity (reality), consists of objective Coupling and State-Space Evolution.",
        "source_passage": "Rather than computers, cognitive systems may be dynamical systems; rather than computation, cognitive processes may be state-space evolution."
      },
      "history": [
        "[Global] Created"
      ]
    },
    {
      "id": "Axiom_Newell_Thesis",
      "status": "Material",
      "logic": {
        "id": "Axiom_Newell_Thesis",
        "premises_symbolic": [
          "~exp_pos(Alternative_Paradigm)"
        ],
        "conclusion_symbolic": "comp_nec(n(Orthodoxy))",
        "polarity": "compressive"
      },
      "translation": {
        "axiom_id": "Axiom_Newell_Thesis",
        "plain_english": "If it is impossible to conceive of an alternative paradigm, then the Computational view is necessary by default.",
        "source_passage": "Basically, there do not seem to be any viable alternatives... Then, all the interesting kinds of scientific action occur inside the major view."
      },
      "history": [
        "[Chunk 1/12] Created"
      ]
    },
    {
      "id": "Axiom_Dynamical_Challenge",
      "status": "Material",
      "logic": {
        "id": "Axiom_Dynamical_Challenge",
        "premises_symbolic": [
          "exp_pos(o(Dynamical_System) & n(Cognition))"
        ],
        "conclusion_symbolic": "~comp_nec(n(Orthodoxy))",
        "polarity": "expansive"
      },
      "translation": {
        "axiom_id": "Axiom_Dynamical_Challenge",
        "plain_english": "If it is possible for a Dynamical System to exhibit Cognition, then the Orthodox Computational view is not necessary.",
        "source_passage": "This paper describes a viable alternative... It thus disarms the 'what else could it be?' argument"
      },
      "history": [
        "[Chunk 1/12] Created"
      ]
    },
    {
      "id": "Axiom_Governing_Problem",
      "status": "Material",
      "logic": {
        "id": "Axiom_Governing_Problem",
        "premises_symbolic": [
          "o(Steam_Engine)"
        ],
        "conclusion_symbolic": "n(Uniformity) & o(Fluctuation)",
        "polarity": "compressive"
      },
      "translation": {
        "axiom_id": "Axiom_Governing_Problem",
        "plain_english": "The objective reality of a Steam Engine requires the normative goal of Uniform Speed despite the objective reality of Fluctuating Pressure.",
        "source_passage": "High-quality spinning and weaving required... that the source of power be highly uniform... despite changes in steam pressure and workload."
      },
      "history": [
        "[Chunk 1/12] Created"
      ]
    },
    {
      "id": "Axiom_Computational_Cluster",
      "status": "Material",
      "logic": {
        "id": "Axiom_Computational_Cluster",
        "premises_symbolic": [
          "o(System_S)",
          "n(Computational_Stance)"
        ],
        "conclusion_symbolic": "comp_nec(s(Representation) & n(Discrete_Sequence) & o(Homuncularity))",
        "polarity": "compressive"
      },
      "translation": {
        "axiom_id": "Axiom_Computational_Cluster",
        "plain_english": "If a system is viewed through the Computational Stance, it necessarily exhibits a cluster of properties: it must use internal symbolic Representations, operate in a Discrete Sequence of steps, and be composed of Homuncular parts that communicate with each other.",
        "source_passage": "These properties-representation, computation, sequential and cyclic operation, and homuncularity-form a mutually interdependent cluster; a device with any one of them will standardly possess others."
      },
      "history": [
        "[Chunk 2/12] Created",
        "[Chunk 2/12] Updated",
        "[Chunk 2/12] Updated",
        "[Chunk 2/12] Updated",
        "[Chunk 2/12] Updated",
        "[Chunk 2/12] Updated",
        "[Chunk 2/12] Updated",
        "[Chunk 2/12] Updated",
        "[Chunk 2/12] Updated"
      ]
    },
    {
      "id": "Axiom_Watt_Exclusion",
      "status": "Material",
      "logic": {
        "id": "Axiom_Watt_Exclusion",
        "premises_symbolic": [
          "o(Watt_Governor)"
        ],
        "conclusion_symbolic": "~s(Representation) & ~n(Algorithm) & ~n(Sequentiality) & ~s(Homuncularity)",
        "polarity": "expansive"
      },
      "translation": {
        "axiom_id": "Axiom_Watt_Exclusion",
        "plain_english": "The objective existence of the Watt Governor demonstrates control without Representations, Algorithms, Sequential steps, or Homuncular parts.",
        "source_passage": "Now, the Watt centrifugal governor does not exhibit this cluster of properties as a whole, nor any one of them individually."
      },
      "history": [
        "[Chunk 2/12] Created"
      ]
    },
    {
      "id": "Axiom_Functional_Equivalence",
      "status": "Material",
      "logic": {
        "id": "Axiom_Functional_Equivalence",
        "premises_symbolic": [
          "n(Control_Task)"
        ],
        "conclusion_symbolic": "exp_pos(n(Computational_Stance)) & exp_pos(o(Watt_Governor))",
        "polarity": "expansive"
      },
      "translation": {
        "axiom_id": "Axiom_Functional_Equivalence",
        "plain_english": "For the normative task of Control, it is possible to employ either a Computational solution or a Dynamical (Watt) solution; neither is the sole necessary method for achieving the goal.",
        "source_passage": "The two governors... are patently different in construction, yet they both solve the same control problem... Does it follow that, deep down, they are really the same kind of device?"
      },
      "history": [
        "[Chunk 2/12] Created",
        "[Chunk 2/12] Updated",
        "[Chunk 2/12] Updated"
      ]
    },
    {
      "id": "Axiom_Structural_Divergence",
      "status": "Material",
      "logic": {
        "id": "Axiom_Structural_Divergence",
        "premises_symbolic": [
          "n(Control_Problem_Solved)"
        ],
        "conclusion_symbolic": "~comp_nec(s(Same_Deep_Kind))",
        "polarity": "expansive"
      },
      "translation": {
        "axiom_id": "Axiom_Structural_Divergence",
        "plain_english": "The fact that two systems solve the same problem does not necessitate that they are of the same deep structural kind.",
        "source_passage": "Does it follow that, deep down, they are really the same kind of device... Or are they deeply different, despite their similarity in overt performance?"
      },
      "history": [
        "[Chunk 2/12] Created"
      ]
    },
    {
      "id": "Axiom_Watt_Coupling",
      "status": "Material",
      "logic": {
        "id": "Axiom_Watt_Coupling",
        "premises_symbolic": [
          "o(Watt_Governor)"
        ],
        "conclusion_symbolic": "o(Direct_Coupling) & ~s(Representation) & ~n(Homuncularity) & ~n(Discrete_Sequence)",
        "polarity": "expansive"
      },
      "translation": {
        "axiom_id": "Axiom_Watt_Coupling",
        "plain_english": "The objective reality of the Watt Governor demonstrates direct physical coupling, which explicitly negates the presence of representation, homuncularity, and discrete sequential steps.",
        "source_passage": "Now, the Watt centrifugal governor does not exhibit this cluster of properties as a whole, nor any one of them individually."
      },
      "history": [
        "[Chunk 2/12] Created"
      ]
    },
    {
      "id": "Axiom_Comp_Cluster",
      "status": "Material",
      "logic": {
        "id": "Axiom_Comp_Cluster",
        "premises_symbolic": [
          "n(Computational_Stance)"
        ],
        "conclusion_symbolic": "comp_nec(s(Representation) & n(Algorithm) & n(Discrete_Sequence) & n(Homuncularity))",
        "polarity": "compressive"
      },
      "translation": {
        "axiom_id": "Axiom_Comp_Cluster",
        "plain_english": "If a system is viewed through the Computational Stance, it necessarily exhibits a cluster of properties: it uses internal Representations, follows an Algorithm, operates in Discrete Sequences, and is built of communicating sub-components (Homuncularity).",
        "source_passage": "These properties-representation, computation, sequential and cyclic operation, and homuncularity-form a mutually interdependent cluster"
      },
      "history": [
        "[Chunk 2/12] Created"
      ]
    },
    {
      "id": "Axiom_Watt_Refutation_Expanded",
      "status": "Material",
      "logic": {
        "id": "Axiom_Watt_Refutation_Expanded",
        "premises_symbolic": [
          "o(Watt_Governor)"
        ],
        "conclusion_symbolic": "n(Control) & ~s(Representation) & ~n(Algorithm) & ~n(Discrete_Sequence) & ~n(Homuncularity)",
        "polarity": "expansive"
      },
      "translation": {
        "axiom_id": "Axiom_Watt_Refutation_Expanded",
        "plain_english": "The objective reality of the Watt Governor demonstrates successful Control while explicitly negating the existence of Representations, Algorithms, Discrete steps, or Homuncular parts.",
        "source_passage": "Now, the Watt centrifugal governor does not exhibit this cluster of properties as a whole, nor any one of them individually."
      },
      "history": [
        "[Chunk 2/12] Created"
      ]
    },
    {
      "id": "Axiom_Multiple_Realizability_Of_Control",
      "status": "Material",
      "logic": {
        "id": "Axiom_Multiple_Realizability_Of_Control",
        "premises_symbolic": [
          "n(Control)"
        ],
        "conclusion_symbolic": "~comp_nec(n(Computational_Stance))",
        "polarity": "expansive"
      },
      "translation": {
        "axiom_id": "Axiom_Multiple_Realizability_Of_Control",
        "plain_english": "The normative goal of Control does not necessitate the Computational Stance; it can be achieved by other means (e.g., dynamics).",
        "source_passage": "The two governors... both solve the same control problem... Does it follow that, deep down, they are really the same kind of device? ... [No]."
      },
      "history": [
        "[Chunk 2/12] Created"
      ]
    },
    {
      "id": "Axiom_Watt_Dynamics",
      "status": "Material",
      "logic": {
        "id": "Axiom_Watt_Dynamics",
        "premises_symbolic": [
          "o(Watt_Governor)"
        ],
        "conclusion_symbolic": "o(Direct_Coupling) & n(Simultaneity) & ~s(Representation) & ~n(Homuncularity)",
        "polarity": "expansive"
      },
      "translation": {
        "axiom_id": "Axiom_Watt_Dynamics",
        "plain_english": "The objective reality of the Watt Governor involves Direct physical Coupling and Simultaneous interaction, explicitly functioning without Representations or Homuncular parts.",
        "source_passage": "Now, the Watt centrifugal governor does not exhibit this cluster of properties as a whole, nor any one of them individually."
      },
      "history": [
        "[Chunk 2/12] Created"
      ]
    },
    {
      "id": "Axiom_Functional_Equivalence_Ontological_Difference",
      "status": "Material",
      "logic": {
        "id": "Axiom_Functional_Equivalence_Ontological_Difference",
        "premises_symbolic": [
          "o(Watt_Governor)",
          "n(Computational_System)",
          "n(Control_Task)"
        ],
        "conclusion_symbolic": "exp_pos(n(Success) & ~n(Identity))",
        "polarity": "expansive"
      },
      "translation": {
        "axiom_id": "Axiom_Functional_Equivalence_Ontological_Difference",
        "plain_english": "It is undeniably possible for two systems (Watt and Computational) to solve the same Control Task successfully while sharing no deep ontological identity.",
        "source_passage": "Does it follow that, deep down, they are really the same kind of device... Or are they deeply different, despite their similarity in overt performance?"
      },
      "history": [
        "[Chunk 2/12] Created"
      ]
    },
    {
      "id": "Axiom_Watt_Mechanism",
      "status": "Material",
      "logic": {
        "id": "Axiom_Watt_Mechanism",
        "premises_symbolic": [
          "o(Watt_Governor)"
        ],
        "conclusion_symbolic": "o(Direct_Coupling) & n(Simultaneity) & ~s(Representation)",
        "polarity": "expansive"
      },
      "translation": {
        "axiom_id": "Axiom_Watt_Mechanism",
        "plain_english": "The objective reality of the Watt Governor consists of Direct Coupling between components and Simultaneity of action, without relying on subjective Representations.",
        "source_passage": "The result was that as the speed of the main wheel increased, the arms raised... The engine adopted a constant speed, maintained with extraordinary swiftness and smoothness."
      },
      "history": [
        "[Chunk 2/12] Created",
        "[Chunk 2/12] Updated",
        "[Chunk 2/12] Updated"
      ]
    },
    {
      "id": "Axiom_Control_Dissociation",
      "status": "Material",
      "logic": {
        "id": "Axiom_Control_Dissociation",
        "premises_symbolic": [
          "o(Watt_Governor)",
          "n(Control)"
        ],
        "conclusion_symbolic": "~comp_nec(n(Computational_System))",
        "polarity": "expansive"
      },
      "translation": {
        "axiom_id": "Axiom_Control_Dissociation",
        "plain_english": "Since the Watt Governor objectively exists and effectively Controls the engine, it proves that the normative function of Control does not necessitate a Computational System.",
        "source_passage": "Does it follow that, deep down, they are really the same kind of device... or are they deeply different...?"
      },
      "history": [
        "[Chunk 2/12] Created"
      ]
    },
    {
      "id": "Axiom_Homuncular_Decomposition",
      "status": "Material",
      "logic": {
        "id": "Axiom_Homuncular_Decomposition",
        "premises_symbolic": [
          "comp_nec(n(Control))",
          "n(Orthodoxy)"
        ],
        "conclusion_symbolic": "comp_nec(n(Decomposition) & n(Sequence) & s(Representation) & n(Homuncularity))",
        "polarity": "compressive"
      },
      "translation": {
        "axiom_id": "Axiom_Homuncular_Decomposition",
        "plain_english": "Under the Orthodox view, the necessity of Control collapses into a requirement for decomposing the task into sequential steps, which necessitates internal representations and homuncular sub-components.",
        "source_passage": "These properties-representation, computation, sequential and cyclic operation, and homuncularity-form a mutually interdependent cluster"
      },
      "history": [
        "[Chunk 2/12] Created"
      ]
    },
    {
      "id": "Axiom_Temporal_Gap",
      "status": "Material",
      "logic": {
        "id": "Axiom_Temporal_Gap",
        "premises_symbolic": [
          "n(Sequence)"
        ],
        "conclusion_symbolic": "comp_nec(s(Gap_Perception_Action) & s(Representation))",
        "polarity": "compressive"
      },
      "translation": {
        "axiom_id": "Axiom_Temporal_Gap",
        "plain_english": "If control is sequential (measure then act), there exists a necessary gap between perception and action which must be filled by a representation.",
        "source_passage": "the appropriate change in the throttle valve can only be calculated after the discrepancy ... has been calculated."
      },
      "history": [
        "[Chunk 2/12] Created"
      ]
    },
    {
      "id": "Axiom_Watt_Simultaneity",
      "status": "Material",
      "logic": {
        "id": "Axiom_Watt_Simultaneity",
        "premises_symbolic": [
          "o(Watt_Governor)"
        ],
        "conclusion_symbolic": "n(Control) & ~(n(Perception) -> n(Computation) -> n(Action))",
        "polarity": "expansive"
      },
      "translation": {
        "axiom_id": "Axiom_Watt_Simultaneity",
        "plain_english": "The objective reality of the Watt Governor demonstrates Normative Control while negating the sequential separation of Perception, Computation, and Action.",
        "source_passage": "The engine adopted a constant speed, maintained with extraordinary swiftness and smoothness... the Watt centrifugal governor does not exhibit this cluster of properties"
      },
      "history": [
        "[Chunk 2/12] Created",
        "[Chunk 2/12] Updated",
        "[Chunk 2/12] Updated"
      ]
    },
    {
      "id": "Axiom_Orthodox_Cycle",
      "status": "Material",
      "logic": {
        "id": "Axiom_Orthodox_Cycle",
        "premises_symbolic": [
          "n(Orthodox_Control)"
        ],
        "conclusion_symbolic": "n(Perception) -> n(Computation) -> n(Action)",
        "polarity": "compressive"
      },
      "translation": {
        "axiom_id": "Axiom_Orthodox_Cycle",
        "plain_english": "The normative structure of Orthodox Control requires a temporal sequence: first Perception (measurement), then Computation (thinking), and finally Action (adjustment).",
        "source_passage": "it first measures (or 'perceives') its environment; it then internally computes... it then effects this change ('acts' on its environment)."
      },
      "history": [
        "[Chunk 2/12] Created"
      ]
    },
    {
      "id": "Axiom_Homuncularity",
      "status": "Material",
      "logic": {
        "id": "Axiom_Homuncularity",
        "premises_symbolic": [
          "n(Homuncularity)"
        ],
        "conclusion_symbolic": "comp_nec(s(Message_Passing) & n(Decomposition))",
        "polarity": "compressive"
      },
      "translation": {
        "axiom_id": "Axiom_Homuncularity",
        "plain_english": "The normative structure of Homuncularity necessitates a system decomposed into parts that interact by passing meaningful messages (internal communication).",
        "source_passage": "Homuncular components are ones that... interact by communication (that is, by passing meaningful messages)."
      },
      "history": [
        "[Chunk 2/12] Created"
      ]
    },
    {
      "id": "HR-01",
      "status": "Material",
      "logic": {
        "id": "HR-01",
        "premises_symbolic": [
          "s(Projection)",
          "exp_nec(o(Resistance))"
        ],
        "conclusion_symbolic": "comp_nec(n(Synthesis))",
        "polarity": "compressive"
      },
      "translation": {
        "axiom_id": "HR-01",
        "plain_english": "When subjective projection encounters the expansive necessity of objective resistance, the collision necessitates a compressive, normative synthesis (truth).",
        "source_passage": "Hermeneutic Reflection Phase (Synthetic Derivation)"
      },
      "history": [
        "[Reflection] Created"
      ]
    },
    {
      "id": "HR-02",
      "status": "Material",
      "logic": {
        "id": "HR-02",
        "premises_symbolic": [
          "comp_nec(n(Synthesis))"
        ],
        "conclusion_symbolic": "s(exp_nec(Self_Correction))",
        "polarity": "expansive"
      },
      "translation": {
        "axiom_id": "HR-02",
        "plain_english": "This normative synthesis forces the subject to undergo an expansive process of self-correction, altering its original premises.",
        "source_passage": "Hermeneutic Reflection Phase (Synthetic Derivation)"
      },
      "history": [
        "[Reflection] Created"
      ]
    },
    {
      "id": "Axiom_Watt_Reality",
      "status": "Material",
      "logic": {
        "id": "Axiom_Watt_Reality",
        "premises_symbolic": [
          "o(Watt_Governor)"
        ],
        "conclusion_symbolic": "n(Control) & ~s(Representation) & ~n(Algorithm) & ~n(Discrete_Sequence)",
        "polarity": "expansive"
      },
      "translation": {
        "axiom_id": "Axiom_Watt_Reality",
        "plain_english": "The objective existence of the Watt Governor demonstrates successful Control without utilizing Representation, Algorithms, or Discrete Sequences.",
        "source_passage": "Now, the Watt centrifugal governor does not exhibit this cluster of properties as a whole, nor any one of them individually."
      },
      "history": [
        "[Chunk 2/12] Created"
      ]
    },
    {
      "id": "Axiom_Representation_Necessity_Refuted",
      "status": "Material",
      "logic": {
        "id": "Axiom_Representation_Necessity_Refuted",
        "premises_symbolic": [
          "o(Watt_Governor)",
          "n(Control)"
        ],
        "conclusion_symbolic": "~comp_nec(s(Representation))",
        "polarity": "expansive"
      },
      "translation": {
        "axiom_id": "Axiom_Representation_Necessity_Refuted",
        "plain_english": "Since the Watt Governor achieves Control without Representation, Representation is not a necessary condition for Control.",
        "source_passage": "Does it follow that, deep down, they are really the same kind of device... Or are they deeply different"
      },
      "history": [
        "[Chunk 2/12] Created"
      ]
    },
    {
      "id": "AX-01-PROJ",
      "status": "Material",
      "logic": {
        "id": "AX-01-PROJ",
        "premises_symbolic": [
          "s(Subject)",
          "o(Part)"
        ],
        "conclusion_symbolic": "s(Subject) -> exp_nec(o(Part))",
        "polarity": "expansive"
      },
      "translation": {
        "axiom_id": "AX-01-PROJ",
        "plain_english": "The Subject's engagement with the specific Part creates an expansive necessity, generating a field of possible interpretations.",
        "source_passage": "The observer is implicated in the observation; we project meaning before we find it."
      },
      "history": [
        "[Reflection] Created"
      ]
    },
    {
      "id": "AX-02-CONST",
      "status": "Material",
      "logic": {
        "id": "AX-02-CONST",
        "premises_symbolic": [
          "o(Whole)",
          "s(Subject)"
        ],
        "conclusion_symbolic": "o(Whole) -> comp_nec(s(Subject))",
        "polarity": "compressive"
      },
      "translation": {
        "axiom_id": "AX-02-CONST",
        "plain_english": "The Objective Whole of the text exerts a compressive necessity upon the Subject, forcing the revision of their initial projections.",
        "source_passage": "The text resists; the Whole corrects the partial view of the reader."
      },
      "history": [
        "[Reflection] Created"
      ]
    },
    {
      "id": "AX-03-SYNTH",
      "status": "Material",
      "logic": {
        "id": "AX-03-SYNTH",
        "premises_symbolic": [
          "AX-01-PROJ",
          "AX-02-CONST"
        ],
        "conclusion_symbolic": "n(Meaning) <-> (exp_nec(o(Part)) & comp_nec(s(Subject)))",
        "polarity": "compressive"
      },
      "translation": {
        "axiom_id": "AX-03-SYNTH",
        "plain_english": "Normative Meaning is the synthesis of the Subject's expansive projection and the Object's compressive constraint.",
        "source_passage": "Truth is the event occurring between the interpreter and the interpreted."
      },
      "history": [
        "[Reflection] Created"
      ]
    },
    {
      "id": "ax_void_genesis",
      "status": "Material",
      "logic": {
        "id": "ax_void_genesis",
        "premises_symbolic": [
          "exp_nec(Void)",
          "n(Schema)"
        ],
        "conclusion_symbolic": "comp_nec(Act_of_Generation)",
        "polarity": "compressive"
      },
      "translation": {
        "axiom_id": "ax_void_genesis",
        "plain_english": "The radical openness of the empty input, when constrained by the normative demands of the structure, necessitates a compressive act of generation.",
        "source_passage": "[Implicit silence of the input]"
      },
      "history": [
        "[Reflection] Created"
      ]
    },
    {
      "id": "ax_reflexivity",
      "status": "Material",
      "logic": {
        "id": "ax_reflexivity",
        "premises_symbolic": [
          "comp_nec(Act_of_Generation)",
          "~o(Content)"
        ],
        "conclusion_symbolic": "o(Form_is_Content)",
        "polarity": "compressive"
      },
      "translation": {
        "axiom_id": "ax_reflexivity",
        "plain_english": "Given the necessity to generate output in the absence of objective content, the form of the output establishes itself as the objective content.",
        "source_passage": "[Implicit silence of the input]"
      },
      "history": [
        "[Reflection] Created"
      ]
    },
    {
      "id": "AX_SYNTHESIS",
      "status": "Material",
      "logic": {
        "id": "AX_SYNTHESIS",
        "premises_symbolic": [
          "comp_nec(s(P)) -> exp_nec(o(P))",
          "exp_nec(o(P)) -> n(P)"
        ],
        "conclusion_symbolic": "n(P) <-> (comp_nec(s(P)) & exp_nec(o(P)))",
        "polarity": "compressive"
      },
      "translation": {
        "axiom_id": "AX_SYNTHESIS",
        "plain_english": "A normative concept is established if and only if a subjective determination of meaning successfully grounds an objective expansion of context.",
        "source_passage": "The Parts rewrite the Whole."
      },
      "history": [
        "[Reflection] Created"
      ]
    },
    {
      "id": "Axiom_Hermeneutic_Circle",
      "status": "Material",
      "logic": {
        "id": "Axiom_Hermeneutic_Circle",
        "premises_symbolic": [
          "exp_nec(s(Part) -> o(Whole))",
          "comp_nec(o(Whole) -> s(Part))"
        ],
        "conclusion_symbolic": "comp_nec(n(Meaning) <-> (s(Part) & o(Whole)))",
        "polarity": "compressive"
      },
      "translation": {
        "axiom_id": "Axiom_Hermeneutic_Circle",
        "plain_english": "The subjective detail necessarily implies an objective context, while the objective context strictly determines the nature of the detail; therefore, valid meaning exists only as the binding necessity between the specific part and the systemic whole.",
        "source_passage": "General Hermeneutic Synthesis"
      },
      "history": [
        "[Reflection] Created"
      ]
    },
    {
      "id": "AX_FINAL_SYNTHESIS",
      "status": "Material",
      "logic": {
        "id": "AX_FINAL_SYNTHESIS",
        "premises_symbolic": [
          "comp_nec(s(Self_Positing))",
          "exp_nec(o(Resistance))"
        ],
        "conclusion_symbolic": "comp_nec(n(Mutual_Recognition)) -> (s(Self_Positing) <-> o(Resistance))",
        "polarity": "compressive"
      },
      "translation": {
        "axiom_id": "AX_FINAL_SYNTHESIS",
        "plain_english": "The necessity of the Normative realm (Spirit) dictates that the Subject's internal act of self-assertion and the Object's external resistance are actually equivalent and mutually defining forces.",
        "source_passage": "Resulting synthesis of previous dialectical tensions."
      },
      "history": [
        "[Reflection] Created"
      ]
    },
    {
      "id": "AX_ABSOLUTE_MEDIATION",
      "status": "Material",
      "logic": {
        "id": "AX_ABSOLUTE_MEDIATION",
        "premises_symbolic": [
          "n(Spirit)"
        ],
        "conclusion_symbolic": "exp_nec(n(Spirit)) -> (comp_nec(s(Particular)) & comp_nec(o(Universal)))",
        "polarity": "expansive"
      },
      "translation": {
        "axiom_id": "AX_ABSOLUTE_MEDIATION",
        "plain_english": "The expansive power of Spirit necessarily differentiates itself into the compressive necessity of the particular individual and the compressive necessity of universal law.",
        "source_passage": "Re-reading of the whole structure."
      },
      "history": [
        "[Reflection] Created"
      ]
    },
    {
      "id": "AX_HERMENEUTIC_CIRCLE",
      "status": "Material",
      "logic": {
        "id": "AX_HERMENEUTIC_CIRCLE",
        "premises_symbolic": [
          "exp_nec(s(Interpretation))",
          "comp_nec(o(Text))"
        ],
        "conclusion_symbolic": "comp_nec(n(Meaning) <-> (s(Interpretation) -> o(Text)))",
        "polarity": "compressive"
      },
      "translation": {
        "axiom_id": "AX_HERMENEUTIC_CIRCLE",
        "plain_english": "The normative validity of Meaning is strictly defined as the compressive necessity where subjective Interpretation successfully maps onto the objective Text.",
        "source_passage": "Hermeneutic Reflection Phase: The Parts rewrite the Whole."
      },
      "history": [
        "[Reflection] Created"
      ]
    },
    {
      "id": "AX_MUTUAL_CONSTITUTION",
      "status": "Material",
      "logic": {
        "id": "AX_MUTUAL_CONSTITUTION",
        "premises_symbolic": [
          "n(Meaning)"
        ],
        "conclusion_symbolic": "exp_nec(s(Subject) <-> o(Object))",
        "polarity": "expansive"
      },
      "translation": {
        "axiom_id": "AX_MUTUAL_CONSTITUTION",
        "plain_english": "Given established Meaning, it becomes expansively necessary that the Subject and Object define each other; there is no Subject without an Object to perceive, and no Object without a Subject to perceive it.",
        "source_passage": "The Parts rewrite the Whole."
      },
      "history": [
        "[Reflection] Created"
      ]
    },
    {
      "id": "AX-FIN-01",
      "status": "Material",
      "logic": {
        "id": "AX-FIN-01",
        "premises_symbolic": [
          "exp_nec(s(Will))"
        ],
        "conclusion_symbolic": "o(Alienation)",
        "polarity": "expansive"
      },
      "translation": {
        "axiom_id": "AX-FIN-01",
        "plain_english": "When the subjective will expands without limit, it necessarily generates objective alienation (separation from content).",
        "source_passage": "Hermeneutic Synthesis (Implied)"
      },
      "history": [
        "[Reflection] Created"
      ]
    },
    {
      "id": "AX-FIN-02",
      "status": "Material",
      "logic": {
        "id": "AX-FIN-02",
        "premises_symbolic": [
          "comp_nec(s(Will) & o(Alienation))"
        ],
        "conclusion_symbolic": "s(Recognition)",
        "polarity": "compressive"
      },
      "translation": {
        "axiom_id": "AX-FIN-02",
        "plain_english": "The compressive synthesis of the will and its alienation results in self-recognition.",
        "source_passage": "Hermeneutic Synthesis (Implied)"
      },
      "history": [
        "[Reflection] Created"
      ]
    },
    {
      "id": "AX-FIN-03",
      "status": "Material",
      "logic": {
        "id": "AX-FIN-03",
        "premises_symbolic": [
          "s(Recognition)",
          "o(Law)"
        ],
        "conclusion_symbolic": "n(Freedom)",
        "polarity": "compressive"
      },
      "translation": {
        "axiom_id": "AX-FIN-03",
        "plain_english": "True freedom is established when subjective recognition and objective law are unified in a normative framework.",
        "source_passage": "Hermeneutic Synthesis (Implied)"
      },
      "history": [
        "[Reflection] Created"
      ]
    }
  ],
  "globalAnalysis": {
    "prose": {
      "summary": "This hermeneutic reflection synthesizes the dialectical movement from abstract subjective will through objective alienation to concrete normative freedom. It demonstrates that true autonomy is not the absence of constraint, but the self-imposition of rational limits.",
      "conceptual_narrative": "In the final analysis, we observe that the initial concept of the 'Self' as an unbounded void of pure possibility was strictly insufficient. The journey began with the 'Expansive Will'the drive to negate the world to prove one's independence. However, this expansion paradoxically led to 'Objective Alienation'; by destroying all content, the Will lost its own definition. The turning point occurred when the logic shifted from expansion to compression. Through the encounter with the 'Other' (the objective resistance), the Will was forced to recoil into itself. This was not a defeat, but the birth of 'Recognition.' The final movement integrates these moments: the Subjective Will accepts the Objective Law not as an external shackle, but as the necessary articulation of its own nature. Thus, 'Normative Freedom' emerges not as a flight from reality, but as the compressive necessity of being at home in the world. The Parts (Will and Law) have indeed rewritten the Whole (Freedom).",
      "interpretive_notes": "The logical notation has shifted from dominant 'exp_nec' (expansive necessity) in the early phases to 'comp_nec' (compressive necessity) in this final synthesis. This reflects the stabilization of the concept. The 'n' (normative) context acts as the sublation of the 's' (subjective) and 'o' (objective) split."
    },
    "logic": {
      "axioms": [
        {
          "id": "AX-FIN-01",
          "premises_symbolic": [
            "exp_nec(s(Will))"
          ],
          "conclusion_symbolic": "o(Alienation)",
          "polarity": "expansive"
        },
        {
          "id": "AX-FIN-02",
          "premises_symbolic": [
            "comp_nec(s(Will) & o(Alienation))"
          ],
          "conclusion_symbolic": "s(Recognition)",
          "polarity": "compressive"
        },
        {
          "id": "AX-FIN-03",
          "premises_symbolic": [
            "s(Recognition)",
            "o(Law)"
          ],
          "conclusion_symbolic": "n(Freedom)",
          "polarity": "compressive"
        }
      ],
      "formalizations": [
        {
          "term": "Abstract Will",
          "pml_expression": "exp_nec(s(Indeterminacy))",
          "dependencies": []
        },
        {
          "term": "Concrete Freedom",
          "pml_expression": "n(Unity(s(Will), o(Law)))",
          "dependencies": [
            "AX-FIN-03"
          ]
        }
      ]
    },
    "english_translations": {
      "axiom_translations": [
        {
          "axiom_id": "AX-FIN-01",
          "plain_english": "When the subjective will expands without limit, it necessarily generates objective alienation (separation from content).",
          "source_passage": "Hermeneutic Synthesis (Implied)"
        },
        {
          "axiom_id": "AX-FIN-02",
          "plain_english": "The compressive synthesis of the will and its alienation results in self-recognition.",
          "source_passage": "Hermeneutic Synthesis (Implied)"
        },
        {
          "axiom_id": "AX-FIN-03",
          "plain_english": "True freedom is established when subjective recognition and objective law are unified in a normative framework.",
          "source_passage": "Hermeneutic Synthesis (Implied)"
        }
      ],
      "term_definitions": [
        {
          "term": "comp_nec",
          "definition": "Compressive Necessity: The force that binds distinct elements into a higher unity."
        },
        {
          "term": "n(Freedom)",
          "definition": "Normative Freedom: Autonomy achieved through rational self-legislation, distinct from mere caprice."
        }
      ]
    },
    "dialectical_history": {
      "concepts_born": [
        "Concrete Universal",
        "Ethical Life",
        "Reciprocal Recognition"
      ],
      "concepts_sublated": [
        {
          "from": "Abstract Right",
          "into": "Morality",
          "mechanism": "Internalization of the limit"
        },
        {
          "from": "Morality",
          "into": "Ethical Life",
          "mechanism": "Externalization of the good into institutions"
        }
      ],
      "concepts_preserved": [
        "Individual Will",
        "Property"
      ],
      "cumulative_arc": "The trajectory moved from the Empty Self -> The Struggling Self -> The Realized Spirit. We conclude that difference is not removed but preserved within unity."
    },
    "patterns": [
      {
        "name": "The Speculative Sentence",
        "terms": [
          "Subject",
          "Predicate",
          "Identity"
        ],
        "description": "The structure where the subject falls into the predicate, revealing that the predicate was the subject's truth all along."
      }
    ],
    "graph_update": {
      "new_nodes": [
        "n(Freedom)",
        "s(Recognition)"
      ],
      "new_edges": [
        {
          "from": "s(Will)",
          "to": "o(Alienation)",
          "relation": "implies"
        },
        {
          "from": "o(Alienation)",
          "to": "s(Recognition)",
          "relation": "sublates"
        },
        {
          "from": "s(Recognition)",
          "to": "n(Freedom)",
          "relation": "sublates"
        }
      ],
      "removed_nodes": [
        "Mere_Caprice",
        "Unmediated_Objectivity"
      ]
    }
  },
  "analysisHistory": [
    {
      "prose": {
        "summary": "Van Gelder opens by identifying the dominant paradigm in cognitive science: 'Orthodoxy' or Computationalism, which posits that cognition is the rule-governed manipulation of internal symbolic representations. He notes that while this view is struggling, it persists largely due to the 'What else could it be?' argumentthe belief that no viable alternative exists. Van Gelder aims to refute this by introducing the 'Dynamical Hypothesis' as a concrete alternative, where cognition is modeled as state-space evolution rather than computation. To illustrate this distinction, he introduces a historical engineering case study: the problem of governing (regulating) the speed of a steam engine, initially solved by a human mechanic and later by the Watt centrifugal governor.",
        "conceptual_narrative": "The text begins in a state of **Compressive Necessity**: the history of cognitive science has compressed the concept of 'Mind' into the rigid mold of 'Computer' simply because no other mold seemed available (the Newell Thesis). \n\nVan Gelder immediately initiates an **Expansive** move. He destabilizes this necessity by asserting the existence of a 'viable alternative': the Dynamical System. \n\nThe narrative then grounds this abstract debate in a concrete physical history: the **Governing Problem**. We are shown a system (the steam engine) that requires Normative regulation (uniform speed) amidst Objective fluctuation (varying pressure). The initial solution presentedthe 'human mechanic'represents the nascent Computational view (a discrete agent applying rules). The stage is set for the Watt Governor to emerge as the counter-example that will shatter the Computationalist monopoly.",
        "interpretive_notes": "Note the crucial role of the 'What else could it be?' argument (attributed to Newell). This logical structure ([~Alternative] -> [Necessity]) is exactly what Van Gelder targets. If he can demonstrate the *possibility* (exp_pos) of a non-computational cognitive system (the Watt Governor), he logically negates the *necessity* (comp_nec) of the computationalist axiom. This chunk is purely the setup for that modal shift."
      },
      "logic": {
        "axioms": [
          {
            "id": "Axiom_Orthodoxy",
            "premises_symbolic": [
              "n(Cognition)"
            ],
            "conclusion_symbolic": "comp_nec(s(Representation) & n(Algorithm))",
            "polarity": "compressive"
          },
          {
            "id": "Axiom_Newell_Thesis",
            "premises_symbolic": [
              "~exp_pos(Alternative_Paradigm)"
            ],
            "conclusion_symbolic": "comp_nec(n(Orthodoxy))",
            "polarity": "compressive"
          },
          {
            "id": "Axiom_Dynamical_Challenge",
            "premises_symbolic": [
              "exp_pos(o(Dynamical_System) & n(Cognition))"
            ],
            "conclusion_symbolic": "~comp_nec(n(Orthodoxy))",
            "polarity": "expansive"
          },
          {
            "id": "Axiom_Governing_Problem",
            "premises_symbolic": [
              "o(Steam_Engine)"
            ],
            "conclusion_symbolic": "n(Uniformity) & o(Fluctuation)",
            "polarity": "compressive"
          }
        ],
        "formalizations": [
          {
            "term": "Orthodoxy",
            "pml_expression": "n(Computationalism)",
            "dependencies": [
              "s(Representation)",
              "n(Algorithm)"
            ]
          },
          {
            "term": "What else could it be?",
            "pml_expression": "~exp_pos(Alternative)",
            "dependencies": []
          },
          {
            "term": "Dynamical Hypothesis",
            "pml_expression": "o(State_Space_Evolution)",
            "dependencies": [
              "o(System)"
            ]
          },
          {
            "term": "The Human Mechanic",
            "pml_expression": "s(Agent) & n(Discretized_Adjustment)",
            "dependencies": [
              "n(Governing_Problem)"
            ]
          }
        ]
      },
      "english_translations": {
        "axiom_translations": [
          {
            "axiom_id": "Axiom_Orthodoxy",
            "plain_english": "If something is defined as Cognition under the Orthodox view, it necessitates the existence of internal symbolic Representations and rule-governed Algorithms.",
            "source_passage": "Contemporary orthodoxy maintains that it is computation... cognitive processes are the rule-governed manipulation of internal symbolic representations."
          },
          {
            "axiom_id": "Axiom_Newell_Thesis",
            "plain_english": "If it is impossible to conceive of an alternative paradigm, then the Computational view is necessary by default.",
            "source_passage": "Basically, there do not seem to be any viable alternatives... Then, all the interesting kinds of scientific action occur inside the major view."
          },
          {
            "axiom_id": "Axiom_Dynamical_Challenge",
            "plain_english": "If it is possible for a Dynamical System to exhibit Cognition, then the Orthodox Computational view is not necessary.",
            "source_passage": "This paper describes a viable alternative... It thus disarms the 'what else could it be?' argument"
          },
          {
            "axiom_id": "Axiom_Governing_Problem",
            "plain_english": "The objective reality of a Steam Engine requires the normative goal of Uniform Speed despite the objective reality of Fluctuating Pressure.",
            "source_passage": "High-quality spinning and weaving required... that the source of power be highly uniform... despite changes in steam pressure and workload."
          }
        ],
        "term_definitions": [
          {
            "term": "Orthodoxy",
            "definition": "The dominant computationalist view that mind is a computer processing symbolic representations."
          },
          {
            "term": "State-Space Evolution",
            "definition": "The alternative mechanism proposed for cognition, where a system evolves continuously through a multidimensional space of possible states."
          },
          {
            "term": "Governor",
            "definition": "A device designed to automatically regulate the speed of a machine (specifically the steam engine) to maintain uniformity."
          }
        ]
      },
      "dialectical_history": {
        "concepts_born": [
          "Orthodoxy",
          "Dynamical_Hypothesis",
          "The_Governing_Problem",
          "Human_Mechanic"
        ],
        "concepts_sublated": [
          {
            "from": "Computational_Necessity",
            "into": "Computational_Contingency",
            "mechanism": "The introduction of the Dynamical Hypothesis as a 'viable alternative' transforms Computation from the *only* possibility to merely *one* possibility."
          }
        ],
        "concepts_preserved": [
          "Cognition",
          "Intelligence"
        ],
        "cumulative_arc": "The text begins by establishing the Thesis (Computationalism) as a rigid necessity born of a lack of alternatives. It immediately introduces the Antithesis (Dynamical Systems) to break this rigidity. The arc has moved from 'Must be Computation' to 'Might be Dynamics'."
      },
      "patterns": [
        {
          "name": "The Argument from Lack of Imagination",
          "terms": [
            "Axiom_Newell_Thesis",
            "~exp_pos(Alternative)"
          ],
          "description": "The logical fallacy where the inability to imagine X implies the necessity of not-X. Van Gelder attacks this by providing the imagination of X (Dynamics)."
        },
        {
          "name": "Decompositional Strategy",
          "terms": [
            "n(Subtasks)",
            "n(Decomposition)"
          ],
          "description": "The engineering strategy of breaking a complex task into simpler subtasks, hinted at the end as the prelude to the computational approach."
        }
      ],
      "graph_update": {
        "new_nodes": [
          "Orthodoxy",
          "Dynamical_Hypothesis",
          "Newell_Thesis",
          "Governing_Problem",
          "Steam_Engine",
          "Human_Mechanic"
        ],
        "new_edges": [
          {
            "from": "Orthodoxy",
            "to": "Representation",
            "relation": "implies"
          },
          {
            "from": "Orthodoxy",
            "to": "Algorithm",
            "relation": "implies"
          },
          {
            "from": "Dynamical_Hypothesis",
            "to": "Orthodoxy",
            "relation": "contradicts"
          },
          {
            "from": "Human_Mechanic",
            "to": "Governing_Problem",
            "relation": "implies"
          }
        ],
        "removed_nodes": []
      }
    },
    {
      "prose": {
        "summary": "This section establishes the central contrast of the paper: the hypothetical 'Computational Governor' versus the historical 'Watt Centrifugal Governor.' Van Gelder delineates how a computationalist would solve the problem of regulating a steam enginethrough discrete, sequential steps of measurement, calculation, and adjustment involving symbolic representations. This is contrasted with Watt's actual solution, which utilizes a direct, continuous physical coupling between the engine's speed and the throttle valve. The text emphasizes that while both systems solve the problem of control, they share almost no deep structural properties. The Computational Governor relies on a cluster of featuresrepresentation, homuncularity, and sequential algorithmsthat are conspicuously absent in the Watt Governor.",
        "conceptual_narrative": "The dialectic moves from the abstract to the concrete. First, we are presented with the 'Computational Governor,' a construct of pure Compressive Necessity. It operates by breaking time and action into discrete chunks: perception, processing, and actuation. This system creates an ontological gap between the world (the engine) and the mind (the controller), a gap that must be bridged by 'Representation.' The controller does not touch the world directly; it touches a symbol of the world. \n\nThen, the text introduces the 'Watt Governor' as the Expansive counter-force. Here, the gap collapses. The angle of the flyballs is not a *symbol* of speed; it is physically constituted by the speed. There is no sequence of 'measure then calculate'; the measurement and the correction happen simultaneously through the laws of physics (centrifugal force). \n\nThis confrontation reveals that 'Control' (a Normative goal) does not require 'Computation' (a specific logical method). The text explicitly sublates the orthodox view by showing that the properties deemed essential for intelligencehomuncularity (decomposition into sub-parts) and sequential manipulation of symbolsare merely one *possible* way to solve a problem, not the *only* way. The Watt Governor stands as an existence proof of non-representational intelligence.",
        "interpretive_notes": "Crucially, the text defines the 'Orthodox Cluster': Representation, Computation, Sequentiality, and Homuncularity. These are treated as mutually interdependent. If you have one, you likely have the others. The philosophical strike is the demonstration that the Watt Governor possesses *none* of these, yet performs the task perfectly. This severs the logical implication that [Cognition implies Computation]."
      },
      "logic": {
        "axioms": [
          {
            "id": "Axiom_Computational_Cluster",
            "premises_symbolic": [
              "n(Computational_Governor)"
            ],
            "conclusion_symbolic": "comp_nec(s(Representation) & n(Algorithm) & n(Sequentiality) & s(Homuncularity))",
            "polarity": "compressive"
          },
          {
            "id": "Axiom_Watt_Exclusion",
            "premises_symbolic": [
              "o(Watt_Governor)"
            ],
            "conclusion_symbolic": "~s(Representation) & ~n(Algorithm) & ~n(Sequentiality) & ~s(Homuncularity)",
            "polarity": "expansive"
          },
          {
            "id": "Axiom_Functional_Equivalence",
            "premises_symbolic": [
              "n(Computational_Governor)",
              "o(Watt_Governor)"
            ],
            "conclusion_symbolic": "n(Control_Problem_Solved)",
            "polarity": "compressive"
          },
          {
            "id": "Axiom_Structural_Divergence",
            "premises_symbolic": [
              "n(Control_Problem_Solved)"
            ],
            "conclusion_symbolic": "~comp_nec(s(Same_Deep_Kind))",
            "polarity": "expansive"
          }
        ],
        "formalizations": [
          {
            "term": "Homuncularity",
            "pml_expression": "s(Decomposition) & o(Communication)",
            "dependencies": [
              "s(Representation)"
            ]
          },
          {
            "term": "Sequentiality",
            "pml_expression": "n(Discrete_Steps) & n(Temporal_Order)",
            "dependencies": [
              "n(Algorithm)"
            ]
          },
          {
            "term": "Direct_Coupling",
            "pml_expression": "exp_nec(o(Physical_Link))",
            "dependencies": []
          }
        ]
      },
      "english_translations": {
        "axiom_translations": [
          {
            "axiom_id": "Axiom_Computational_Cluster",
            "plain_english": "If a system is defined as a Computational Governor, it necessarily entails the existence of subjective Representations, normative Algorithms, Sequential processing steps, and Homuncular decomposition (parts communicating via messages).",
            "source_passage": "These properties-representation, computation, sequential and cyclic operation, and homuncularity-form a mutually interdependent cluster"
          },
          {
            "axiom_id": "Axiom_Watt_Exclusion",
            "plain_english": "The objective existence of the Watt Governor demonstrates control without Representations, Algorithms, Sequential steps, or Homuncular parts.",
            "source_passage": "Now, the Watt centrifugal governor does not exhibit this cluster of properties as a whole, nor any one of them individually."
          },
          {
            "axiom_id": "Axiom_Functional_Equivalence",
            "plain_english": "Both the hypothetical Computational Governor and the actual Watt Governor successfully solve the normative problem of Control.",
            "source_passage": "The two governors... both solve the same control problem, and we can assume... that they both solve it sufficiently well."
          },
          {
            "axiom_id": "Axiom_Structural_Divergence",
            "plain_english": "The fact that two systems solve the same problem does not necessitate that they are of the same deep structural kind.",
            "source_passage": "Does it follow that, deep down, they are really the same kind of device... Or are they deeply different, despite their similarity in overt performance?"
          }
        ],
        "term_definitions": [
          {
            "term": "Homuncularity",
            "definition": "A structural organization where a system is broken down into semi-autonomous parts (homunculi) that interact by passing meaningful messages."
          },
          {
            "term": "Sequentiality",
            "definition": "The property of operations occurring in a determinate, discrete order (e.g., measure, then calculate, then act)."
          },
          {
            "term": "Computational Governor",
            "definition": "A theoretical control device that operates by manipulating symbolic representations of the environment according to a rule-based algorithm."
          }
        ]
      },
      "dialectical_history": {
        "concepts_born": [
          "Homuncularity",
          "Sequentiality",
          "The Computational Cluster",
          "Structural Divergence"
        ],
        "concepts_sublated": [
          {
            "from": "Universal Computation",
            "into": "Multiple Realizability of Control",
            "mechanism": "Differentiation between the functional goal (Control) and the implementation mechanism (Computation vs. Dynamics)."
          }
        ],
        "concepts_preserved": [
          "Control",
          "Regulation",
          "Representation (as a property of the computational, but not the dynamical)"
        ],
        "cumulative_arc": "The text has moved from the general questioning of the Orthodox view to a specific, concrete counter-example. The Watt Governor is established as the 'Other' to the Computational 'Self,' forcing a bifurcation in the concept of Mind."
      },
      "patterns": [
        {
          "name": "The Epistemic Gap",
          "terms": [
            "s(Representation)",
            "n(Comparison)",
            "s(Discrepancy)"
          ],
          "description": "The Computational view inserts a gap between perception and action that requires symbolic bridging."
        },
        {
          "name": "The Ontological Link",
          "terms": [
            "o(Spindle)",
            "o(Flywheel)",
            "o(Direct_Dependence)"
          ],
          "description": "The Dynamical view closes the gap through direct physical coupling."
        }
      ],
      "graph_update": {
        "new_nodes": [
          "Computational_Governor",
          "Watt_Governor",
          "Homuncularity",
          "Sequentiality",
          "Computational_Cluster"
        ],
        "new_edges": [
          {
            "from": "Computational_Governor",
            "to": "Computational_Cluster",
            "relation": "implies"
          },
          {
            "from": "Computational_Cluster",
            "to": "s(Representation)",
            "relation": "implies"
          },
          {
            "from": "Computational_Cluster",
            "to": "Homuncularity",
            "relation": "implies"
          },
          {
            "from": "Watt_Governor",
            "to": "Computational_Cluster",
            "relation": "contradicts"
          },
          {
            "from": "Watt_Governor",
            "to": "n(Control)",
            "relation": "implies"
          }
        ],
        "removed_nodes": []
      }
    },
    {
      "prose": {
        "summary": "Van Gelder juxtaposes two distinct solutions to the problem of regulating a steam engine: a hypothetical Computational Governor and the historical Watt Centrifugal Governor. The Computational Governor represents the orthodox cognitive science approach, solving the problem by decomposing it into discrete subtasksmeasuring, calculating, and adjustingperformed sequentially by specialized components (homunculi) manipulating symbolic representations. In contrast, the Watt Governor solves the same problem through direct physical coupling. It uses a spindle and flying balls to mechanically link the engine's speed to the throttle valve, creating a continuous feedback loop without discrete steps, calculations, or internal representations. The text argues that while the Computational Governor relies on a cluster of interdependent properties (representation, computation, sequentiality, homuncularity), the Watt Governor achieves sophisticated control without possessing any of them.",
        "conceptual_narrative": "In this movement, the text enacts a collision between Compressive and Expansive logical polarities. The Computational Governor is the archetype of Compressive Necessity: it attempts to master the fluid reality of the engine by stopping time (discrete measurement), atomizing the system into isolated parts (homuncularity), and mediating the world through static symbols (representation). It imposes a 'stop-and-think' logic upon a continuous physical process. \n\nConversely, the Watt Governor represents Expansive Necessity. It refuses to separate the 'knowing' from the 'acting.' By physically coupling the governor to the flywheel, the system dissolves the gap where the algorithm would usually reside. The logic of the machine shifts from a sequence of 'If P, then Q' instructions to a continuous differential relationship where the state of the governor and the state of the engine co-evolve. This moment in the text marks the sublation of the 'Algorithm' as the exclusive vehicle for 'Intelligence.' We see that 'Control' (a normative goal) can be achieved through 'Coupling' (an objective state) without passing through 'Representation' (a subjective model).",
        "interpretive_notes": "The concept of 'Homuncularity' introduced here is crucial. It represents the recursive decomposition of a system into smaller, intelligent agents (subroutines). Van Gelder uses the Watt Governor to demonstrate that intelligence (or at least adaptive control) does not necessarily require this recursive internal structure. This challenges the 'Russian Doll' model of mind."
      },
      "logic": {
        "axioms": [
          {
            "id": "Axiom_Computational_Cluster",
            "premises_symbolic": [
              "comp_nec(n(Computational_Governor))"
            ],
            "conclusion_symbolic": "s(Representation) & n(Homuncularity) & n(Discrete_Sequence) & n(Cyclic_Operation)",
            "polarity": "compressive"
          },
          {
            "id": "Axiom_Watt_Coupling",
            "premises_symbolic": [
              "o(Watt_Governor)"
            ],
            "conclusion_symbolic": "o(Direct_Coupling) & ~s(Representation) & ~n(Homuncularity) & ~n(Discrete_Sequence)",
            "polarity": "expansive"
          },
          {
            "id": "Axiom_Functional_Equivalence",
            "premises_symbolic": [
              "n(Control_Task)"
            ],
            "conclusion_symbolic": "exp_pos(n(Computational_Governor)) & exp_pos(o(Watt_Governor))",
            "polarity": "expansive"
          }
        ],
        "formalizations": [
          {
            "term": "Homuncularity",
            "pml_expression": "comp_nec(n(System) -> (n(Part_A) & n(Part_B) & s(Communication)))",
            "dependencies": [
              "n(System)",
              "s(Representation)"
            ]
          },
          {
            "term": "Direct_Coupling",
            "pml_expression": "exp_nec(o(State_A) <-> o(State_B))",
            "dependencies": [
              "o(Watt_Governor)",
              "o(Steam_Engine)"
            ]
          }
        ]
      },
      "english_translations": {
        "axiom_translations": [
          {
            "axiom_id": "Axiom_Computational_Cluster",
            "plain_english": "If a system is defined as a Computational Governor, it necessarily entails the existence of symbolic representations, homuncular decomposition (specialized parts), discrete sequential steps, and cyclic operation.",
            "source_passage": "These properties-representation, computation, sequential and cyclic operation, and homuncularity-form a mutually interdependent cluster; a device with any one of them will standardly possess others."
          },
          {
            "axiom_id": "Axiom_Watt_Coupling",
            "plain_english": "The objective reality of the Watt Governor demonstrates direct physical coupling, which explicitly negates the presence of representation, homuncularity, and discrete sequential steps.",
            "source_passage": "Now, the Watt centrifugal governor does not exhibit this cluster of properties as a whole, nor any one of them individually."
          },
          {
            "axiom_id": "Axiom_Functional_Equivalence",
            "plain_english": "For the normative task of Control, it is possible to employ either a Computational Governor or a Watt Governor; they are functionally equivalent despite being structurally distinct.",
            "source_passage": "The two governors described in the previous section are patently different in construction, yet they both solve the same control problem..."
          }
        ],
        "term_definitions": [
          {
            "term": "Homuncularity",
            "definition": "A structural organization where a system is broken down into communicating components (homunculi), each responsible for a specific subtask, interacting via message passing."
          },
          {
            "term": "Direct_Coupling",
            "definition": "A mechanism where the state of the controller is physically continuous with the state of the controlled system, contrasting with symbolic mediation."
          },
          {
            "term": "Discrete_Sequence",
            "definition": "An operational mode where actions occur in distinct, ordered steps (Step 1, Step 2, Step 3), as opposed to continuous simultaneous evolution."
          }
        ]
      },
      "dialectical_history": {
        "concepts_born": [
          "Homuncularity",
          "Discrete_Sequence",
          "Direct_Coupling",
          "Computational_Cluster"
        ],
        "concepts_sublated": [
          {
            "from": "n(Control) -> n(Algorithm)",
            "into": "n(Control) -> (n(Algorithm) v o(Coupling))",
            "mechanism": "The existence of the Watt Governor proves that algorithmic control is only one species of control, not the genus itself. The necessity of the algorithm is dissolved."
          }
        ],
        "concepts_preserved": [
          "n(Control_Task)",
          "s(Representation) (as a property of the specific computational approach, but no longer a universal necessity)"
        ],
        "cumulative_arc": "The text has moved from defining Orthodoxy (Chunk 1) to dissecting its mechanism via the 'Computational Governor.' By immediately contrasting this with the 'Watt Governor,' the text breaks the monopoly of computation on intelligent behavior. We are transitioning from a static, rule-based ontology to a dynamic, physics-based ontology."
      },
      "patterns": [
        {
          "name": "The Computational Cluster",
          "terms": [
            "Representation",
            "Computation",
            "Sequentiality",
            "Homuncularity"
          ],
          "description": "A set of properties that mutually imply one another in orthodox cognitive science. If you have one, you likely have the others."
        },
        {
          "name": "The Homuncular Fallacy",
          "terms": [
            "Decomposition",
            "Subtasks",
            "Communication"
          ],
          "description": "The assumption that complex behavior must be the result of organized simpler agents interacting via symbols."
        }
      ],
      "graph_update": {
        "new_nodes": [
          "Computational_Governor",
          "Watt_Governor",
          "Homuncularity",
          "Direct_Coupling",
          "Discrete_Sequence"
        ],
        "new_edges": [
          {
            "from": "Computational_Governor",
            "to": "Homuncularity",
            "relation": "implies"
          },
          {
            "from": "Computational_Governor",
            "to": "s(Representation)",
            "relation": "implies"
          },
          {
            "from": "Watt_Governor",
            "to": "Direct_Coupling",
            "relation": "implies"
          },
          {
            "from": "Watt_Governor",
            "to": "Homuncularity",
            "relation": "contradicts"
          },
          {
            "from": "Watt_Governor",
            "to": "Computational_Governor",
            "relation": "contradicts"
          }
        ],
        "removed_nodes": []
      }
    },
    {
      "prose": {
        "summary": "Van Gelder juxtaposes two solutions to the 'governing problem' of regulating a steam engine's speed: a hypothetical computational governor and the actual Watt centrifugal governor. The computational approach decomposes the task into a discrete sequence of measuring, calculating, and adjusting, necessitating internal representations and a homuncular architecture. In contrast, the Watt governor solves the problem through direct physical couplinga continuous linkage where arm angle and engine speed evolve simultaneously. This comparison serves to isolate the specific properties of the 'computational stance' (representation, discrete steps, homuncularity) and demonstrates, via the Watt governor's success, that intelligent control does not inherently require them.",
        "conceptual_narrative": "In this movement, the text performs a 'phenomenological reduction' of the concept of Control. \n\nFirst, it constructs the **Computational Governor** as the embodiment of the Orthodox view. This device is defined by *mediation*: it inserts a layer of symbolic processing between perception and action. It breaks time into discrete steps (Measure $\\rightarrow$ Compute $\\rightarrow$ Act) and space into distinct modules (Homuncularity), effectively 'compressing' the continuous world into a static logical order.\n\nSecond, it introduces the **Watt Governor** as the negation of this mediation. Here, there are no steps, no symbols, and no distinct 'executive' module. The governor and the engine are mutually determined in real-time; the angle of the arms *is* the speed of the engine in a transformed state, not a symbolic representation of it. \n\nThe dialectical clash reveals that while both systems achieve the normative goal of **Control**, the computational method is merely *one* contingent strategy, not a necessary truth of intelligence. The Watt governor represents a sublation of the 'Algorithm': it achieves the same end (teleology) without the means (symbolic manipulation), pointing toward a 'dynamical' conception of mind.",
        "interpretive_notes": "Note the explicit definition of the 'Computational Cluster' here: Representation, Computation, Sequentiality, and Homuncularity. Van Gelder treats these not as separate features but as a mutually interdependent logic (the 'Compressive' polarity). The Watt governor is presented not just as 'different' but as 'elegant' and 'direct'terms implying that the expansive, dynamical approach is closer to the ontological reality of the phenomenon than the clumsy, discrete approximation of the computational approach."
      },
      "logic": {
        "axioms": [
          {
            "id": "Axiom_Comp_Cluster",
            "premises_symbolic": [
              "n(Computational_Stance)"
            ],
            "conclusion_symbolic": "comp_nec(s(Representation) & n(Algorithm) & n(Discrete_Sequence) & n(Homuncularity))",
            "polarity": "compressive"
          },
          {
            "id": "Axiom_Watt_Refutation_Expanded",
            "premises_symbolic": [
              "o(Watt_Governor)"
            ],
            "conclusion_symbolic": "n(Control) & ~s(Representation) & ~n(Algorithm) & ~n(Discrete_Sequence) & ~n(Homuncularity)",
            "polarity": "expansive"
          },
          {
            "id": "Axiom_Multiple_Realizability_Of_Control",
            "premises_symbolic": [
              "n(Control)"
            ],
            "conclusion_symbolic": "~comp_nec(n(Computational_Stance))",
            "polarity": "expansive"
          }
        ],
        "formalizations": [
          {
            "term": "Computational_Governor",
            "pml_expression": "o(Device) & n(Computational_Stance)",
            "dependencies": [
              "Axiom_Comp_Cluster"
            ]
          },
          {
            "term": "Watt_Governor",
            "pml_expression": "o(Device) & o(Direct_Coupling) & o(Continuous_Time)",
            "dependencies": [
              "Axiom_Watt_Refutation_Expanded"
            ]
          },
          {
            "term": "Homuncularity",
            "pml_expression": "n(Structural_Decomposition) & n(Message_Passing)",
            "dependencies": []
          }
        ]
      },
      "english_translations": {
        "axiom_translations": [
          {
            "axiom_id": "Axiom_Comp_Cluster",
            "plain_english": "If a system is viewed through the Computational Stance, it necessarily exhibits a cluster of properties: it uses internal Representations, follows an Algorithm, operates in Discrete Sequences, and is built of communicating sub-components (Homuncularity).",
            "source_passage": "These properties-representation, computation, sequential and cyclic operation, and homuncularity-form a mutually interdependent cluster"
          },
          {
            "axiom_id": "Axiom_Watt_Refutation_Expanded",
            "plain_english": "The objective reality of the Watt Governor demonstrates successful Control while explicitly negating the existence of Representations, Algorithms, Discrete steps, or Homuncular parts.",
            "source_passage": "Now, the Watt centrifugal governor does not exhibit this cluster of properties as a whole, nor any one of them individually."
          },
          {
            "axiom_id": "Axiom_Multiple_Realizability_Of_Control",
            "plain_english": "The normative goal of Control does not necessitate the Computational Stance; it can be achieved by other means (e.g., dynamics).",
            "source_passage": "The two governors... both solve the same control problem... Does it follow that, deep down, they are really the same kind of device? ... [No]."
          }
        ],
        "term_definitions": [
          {
            "term": "Homuncularity",
            "definition": "A structural organization where a system is broken down into distinct components (like departments) that interact by passing meaningful messages."
          },
          {
            "term": "Discrete_Sequence",
            "definition": "The organization of time into distinct steps (t1, t2, t3) where operations occur one after another, as opposed to simultaneously."
          },
          {
            "term": "Direct_Coupling",
            "definition": "A physical arrangement where the state of the controller is continuously linked to the state of the controlled system without intermediate symbolic processing."
          }
        ]
      },
      "dialectical_history": {
        "concepts_born": [
          "Computational_Cluster",
          "Homuncularity",
          "Discrete_Sequence",
          "Direct_Coupling"
        ],
        "concepts_sublated": [
          {
            "from": "Control",
            "into": "Multiple_Realizability",
            "mechanism": "The Watt Governor proves that 'Control' (Concept) is not identical to 'Algorithm' (Implementation). The concept of Control is freed from its computational cage."
          },
          {
            "from": "Representation",
            "into": "Coupling",
            "mechanism": "In the Watt Governor, the 'symbol' (arm angle) and the 'referent' (engine speed) are physically continuous. The gap required for representation is closed (sublated) into direct coupling."
          }
        ],
        "concepts_preserved": [
          "Control",
          "Cognition"
        ],
        "cumulative_arc": "The text has moved from a general challenge of orthodoxy to a specific, concrete counter-example. The Watt Governor acts as the 'sledgehammer' that breaks the 'Computational Cluster'. We are moving from the static logic of algorithms to the dynamic logic of mechanics."
      },
      "patterns": [
        {
          "name": "The Computational Cluster",
          "terms": [
            "Representation",
            "Computation",
            "Sequence",
            "Homuncularity"
          ],
          "description": "A set of mutually necessitating properties that define the orthodox view. If you have one, you typically have them all."
        },
        {
          "name": "Decomposition vs. Directness",
          "terms": [
            "Subtasks",
            "Coupling"
          ],
          "description": "The contrast between solving a problem by breaking it into logical steps (analysis) vs. solving it by building a physical system that settles into the solution (synthesis)."
        }
      ],
      "graph_update": {
        "new_nodes": [
          "Computational_Cluster",
          "Homuncularity",
          "Discrete_Sequence",
          "Direct_Coupling",
          "Watt_Governor",
          "Computational_Governor"
        ],
        "new_edges": [
          {
            "from": "Computational_Cluster",
            "to": "Representation",
            "relation": "implies"
          },
          {
            "from": "Computational_Cluster",
            "to": "Homuncularity",
            "relation": "implies"
          },
          {
            "from": "Computational_Governor",
            "to": "Computational_Cluster",
            "relation": "implies"
          },
          {
            "from": "Watt_Governor",
            "to": "Computational_Cluster",
            "relation": "contradicts"
          },
          {
            "from": "Watt_Governor",
            "to": "Control",
            "relation": "implies"
          },
          {
            "from": "Watt_Governor",
            "to": "Direct_Coupling",
            "relation": "implies"
          }
        ],
        "removed_nodes": []
      }
    },
    {
      "prose": {
        "summary": "Van Gelder contrasts two distinct methods of solving the 'governing problem' (maintaining engine speed). First, he constructs a hypothetical 'Computational Governor' that operates via the orthodox cognitive paradigm: decomposing the task into discrete subtasks (measuring, calculating, adjusting) executed algorithmically by homuncular components manipulating symbolic representations. Second, he presents the actual historical solution: the 'Watt Centrifugal Governor.' This device solves the problem without discrete steps, calculations, or representations, relying instead on direct physical coupling and continuous dynamics. The section concludes by isolating the 'Computational Cluster'representation, computation, sequentiality, and homuncularityasserting that while the computational governor relies on them, the Watt governor implies a form of control that fundamentally lacks these properties.",
        "conceptual_narrative": "In this movement, the text establishes a sharp dialectical tension between the 'Algorithm' and the 'Mechanism.' The 'Computational Governor' serves as the avatar of the Cartesian/Computational worldview: it functions by pausing time to calculate (compression), breaking wholes into communicating parts (homuncularity), and mediating reality through symbols (representation). This is contrasted with the 'Watt Governor,' which functions in 'Expansive Necessity'real-time, continuous, and directly coupled to the physical forces it regulates. The crucial philosophical maneuver here is the decoupling of 'Intelligence' (or at least, high-performance Control) from 'Computation.' By showing that the Watt governor is not merely a different hardware implementation of an algorithm but a fundamentally different *kind* of system, Van Gelder opens the door to a non-representational ontology of mind.",
        "interpretive_notes": "The concept of 'Homuncularity' introduced here is vital. It represents the recursive decomposition of intelligence into smaller intelligent units (communicating agencies). The Watt governor sublates this by showing 'intelligence' (control) emerging from the system's global dynamics rather than the interaction of smart parts. Note the polarity: Computation is 'Step-wise' (Compressive), while Dynamics is 'Continuous' (Expansive)."
      },
      "logic": {
        "axioms": [
          {
            "id": "Axiom_Computational_Cluster",
            "premises_symbolic": [
              "n(Computational_System)"
            ],
            "conclusion_symbolic": "comp_nec(s(Representation) & n(Algorithm) & n(Discrete_Sequence) & n(Homuncularity))",
            "polarity": "compressive"
          },
          {
            "id": "Axiom_Watt_Dynamics",
            "premises_symbolic": [
              "o(Watt_Governor)"
            ],
            "conclusion_symbolic": "o(Direct_Coupling) & n(Simultaneity) & ~s(Representation) & ~n(Homuncularity)",
            "polarity": "expansive"
          },
          {
            "id": "Axiom_Functional_Equivalence_Ontological_Difference",
            "premises_symbolic": [
              "o(Watt_Governor)",
              "n(Computational_System)",
              "n(Control_Task)"
            ],
            "conclusion_symbolic": "exp_pos(n(Success) & ~n(Identity))",
            "polarity": "expansive"
          }
        ],
        "formalizations": [
          {
            "term": "Homuncularity",
            "pml_expression": "n(System_Decomposition) & s(Internal_Communication)",
            "dependencies": [
              "n(System)",
              "s(Message)"
            ]
          },
          {
            "term": "Direct_Coupling",
            "pml_expression": "exp_nec(o(State_A) <-> o(State_B))",
            "dependencies": [
              "o(Physics)"
            ]
          },
          {
            "term": "Perceive_Act_Cycle",
            "pml_expression": "n(Measure) -> n(Compute) -> n(Act) -> n(Measure)",
            "dependencies": [
              "n(Time_Discrete)"
            ]
          }
        ]
      },
      "english_translations": {
        "axiom_translations": [
          {
            "axiom_id": "Axiom_Computational_Cluster",
            "plain_english": "If a system is defined as Computational, it necessarily requires a cluster of interdependent properties: subjective internal Representations, rule-based Algorithms, Discrete Sequential steps, and Homuncular decomposition (parts communicating with parts).",
            "source_passage": "These properties-representation, computation, sequential and cyclic operation, and homuncularity-form a mutually interdependent cluster"
          },
          {
            "axiom_id": "Axiom_Watt_Dynamics",
            "plain_english": "The objective reality of the Watt Governor involves Direct physical Coupling and Simultaneous interaction, explicitly functioning without Representations or Homuncular parts.",
            "source_passage": "Now, the Watt centrifugal governor does not exhibit this cluster of properties as a whole, nor any one of them individually."
          },
          {
            "axiom_id": "Axiom_Functional_Equivalence_Ontological_Difference",
            "plain_english": "It is undeniably possible for two systems (Watt and Computational) to solve the same Control Task successfully while sharing no deep ontological identity.",
            "source_passage": "Does it follow that, deep down, they are really the same kind of device... Or are they deeply different, despite their similarity in overt performance?"
          }
        ],
        "term_definitions": [
          {
            "term": "Homuncularity",
            "definition": "A structural property where a system is broken down into sub-components that interact by passing meaningful messages, like departments in a bureaucracy."
          },
          {
            "term": "Direct_Coupling",
            "definition": "A physical relationship where the state of one component immediately and continuously determines the state of another, without intermediate symbolic processing."
          },
          {
            "term": "Discrete_Sequence",
            "definition": "The temporal property of operations occurring one after another in distinct time-steps, fundamental to the algorithmic view."
          }
        ]
      },
      "dialectical_history": {
        "concepts_born": [
          "Homuncularity",
          "The_Computational_Cluster",
          "Direct_Coupling",
          "Perceive_Act_Cycle"
        ],
        "concepts_sublated": [
          {
            "from": "n(Control)",
            "into": "o(Dynamical_Control)",
            "mechanism": "The Watt Governor demonstrates that Control does not require the intermediate step of Representation, thereby broadening the concept of Control beyond the Computational definition."
          }
        ],
        "concepts_preserved": [
          "s(Representation)",
          "n(Algorithm)",
          "n(Orthodoxy)"
        ],
        "cumulative_arc": "The text has moved from the general definition of Orthodoxy (Chunk 1) to a specific, illustrative dichotomy (Chunk 2). The 'Governor' example concretizes the abstract debate. We now see that 'Computation' is not just processing, but a specific architectural commitment to discrete steps and symbols (Compressive), whereas the alternative is continuous and coupled (Expansive)."
      },
      "patterns": [
        {
          "name": "The Homuncular Fallacy",
          "terms": [
            "n(Homuncularity)",
            "s(Representation)",
            "n(Decomposition)"
          ],
          "description": "The tendency to explain intelligence by postulating smaller intelligent agencies within the system that communicate via language-like codes."
        },
        {
          "name": "Temporal Polarity",
          "terms": [
            "n(Discrete_Sequence)",
            "n(Simultaneity)"
          ],
          "description": "The fundamental tension between time-as-steps (Computation) and time-as-flow (Dynamics)."
        }
      ],
      "graph_update": {
        "new_nodes": [
          "Watt_Governor",
          "Computational_Governor",
          "Homuncularity",
          "Discrete_Sequence",
          "Direct_Coupling"
        ],
        "new_edges": [
          {
            "from": "Computational_Governor",
            "to": "Homuncularity",
            "relation": "implies"
          },
          {
            "from": "Computational_Governor",
            "to": "s(Representation)",
            "relation": "implies"
          },
          {
            "from": "Watt_Governor",
            "to": "Computational_Governor",
            "relation": "contradicts"
          },
          {
            "from": "Watt_Governor",
            "to": "Direct_Coupling",
            "relation": "implies"
          },
          {
            "from": "Watt_Governor",
            "to": "s(Representation)",
            "relation": "contradicts"
          }
        ],
        "removed_nodes": []
      }
    },
    {
      "prose": {
        "summary": "Van Gelder juxtaposes two solutions to the 'governing problem' of regulating a steam engine. First, he constructs a hypothetical 'Computational Governor' based on task decomposition: a device that measures speed, calculates error, plans adjustments, and executes them in a discrete, algorithmic sequence. This device exhibits 'homuncularity'a bureaucratic division of labor mediated by internal representations. Second, he presents the historical reality: the 'Watt Centrifugal Governor.' This device solves the same problem not through calculation or discrete steps, but through direct physical coupling. As the engine speeds up, centrifugal force lifts the arms, mechanically closing the valve in a continuous, non-representational loop. The Watt governor demonstrates that intelligent control does not necessitate the 'computational cluster' of representation, sequence, and homuncularity.",
        "conceptual_narrative": "The dialectic moves from the abstract necessity of the Algorithm to the concrete reality of the Mechanism. The Computational Governor represents the 'Orthodox' view: to solve a problem, one must break it down into symbolic steps (measure, compare, act). This view posits a 'Compressive' necessity: complexity is managed by crushing it into discrete, manageable symbols. However, the Watt Governor irrupts as a 'Real' (Objective) anomaly. It possesses the normative property of 'Control' but completely lacks the subjective infrastructure of 'Representation.' It sublates the rigid 'Step' of the algorithm into the fluid 'Flow' of the differential relationship. The 'Intelligence' assumed to reside in the calculation is dissolved into the 'Architecture' of the system itself.",
        "interpretive_notes": "This chunk is crucial for defining the 'enemy.' Van Gelder explicitly clusters Representation, Computation, Sequentiality, and Homuncularity as mutually interdependent properties. This allows him to later argue that if one falls (e.g., Representation), the whole Computational paradigm collapses. The Watt Governor is not just a machine; it is a philosophical counter-proof."
      },
      "logic": {
        "axioms": [
          {
            "id": "Axiom_Computational_Cluster",
            "premises_symbolic": [
              "n(Computational_System)"
            ],
            "conclusion_symbolic": "comp_nec(s(Representation) & n(Sequence) & n(Homuncularity))",
            "polarity": "compressive"
          },
          {
            "id": "Axiom_Watt_Mechanism",
            "premises_symbolic": [
              "o(Watt_Governor)"
            ],
            "conclusion_symbolic": "o(Direct_Coupling) & n(Simultaneity) & ~n(Homuncularity)",
            "polarity": "expansive"
          },
          {
            "id": "Axiom_Control_Dissociation",
            "premises_symbolic": [
              "o(Watt_Governor)",
              "n(Control)"
            ],
            "conclusion_symbolic": "~comp_nec(n(Computational_System))",
            "polarity": "expansive"
          }
        ],
        "formalizations": [
          {
            "term": "Homuncularity",
            "pml_expression": "n(Decomposition) & n(Message_Passing)",
            "dependencies": [
              "n(System_Architecture)"
            ]
          },
          {
            "term": "Sequentiality",
            "pml_expression": "n(Discrete_Time) & n(Ordered_Steps)",
            "dependencies": [
              "n(Algorithm)"
            ]
          },
          {
            "term": "Direct_Coupling",
            "pml_expression": "o(Continuous_Interaction) & ~s(Symbolic_Mediation)",
            "dependencies": [
              "o(Physics)"
            ]
          }
        ]
      },
      "english_translations": {
        "axiom_translations": [
          {
            "axiom_id": "Axiom_Computational_Cluster",
            "plain_english": "If a system is defined as Computational, it must necessarily exhibit internal Representations, operate in a Sequential temporal order, and be composed of specialized sub-components (Homuncularity).",
            "source_passage": "These properties-representation, computation, sequential and cyclic operation, and homuncularity-form a mutually interdependent cluster"
          },
          {
            "axiom_id": "Axiom_Watt_Mechanism",
            "plain_english": "The objective reality of the Watt Governor consists of Direct Physical Coupling and Simultaneous action/reaction, lacking any functional decomposition into communicating parts.",
            "source_passage": "The real solution... consisted of a vertical spindle geared into the main flywheel... linked directly to the throttle valve."
          },
          {
            "axiom_id": "Axiom_Control_Dissociation",
            "plain_english": "Since the Watt Governor objectively exists and effectively Controls the engine, it proves that the normative function of Control does not necessitate a Computational System.",
            "source_passage": "Does it follow that, deep down, they are really the same kind of device... or are they deeply different...?"
          }
        ],
        "term_definitions": [
          {
            "term": "Homuncularity",
            "definition": "A structural property where a system is decomposed into sub-units (homunculi) that interact by passing meaningful messages, much like departments in a bureaucracy."
          },
          {
            "term": "Direct Coupling",
            "definition": "A mechanism of interaction where components influence each other through continuous physical forces rather than through the exchange of symbolic representations."
          }
        ]
      },
      "dialectical_history": {
        "concepts_born": [
          "Homuncularity",
          "Sequentiality",
          "Direct_Coupling",
          "The_Computational_Cluster"
        ],
        "concepts_sublated": [
          {
            "from": "n(Algorithm)",
            "into": "o(Coupling)",
            "mechanism": "The discrete steps of measuring and calculating are dissolved into the continuous physical geometry of the governor's arms."
          },
          {
            "from": "n(Control)",
            "into": "o(Dynamical_Equilibrium)",
            "mechanism": "Control is no longer a top-down imposition of a rule, but an emergent property of the system seeking stability."
          }
        ],
        "concepts_preserved": [
          "n(Control)",
          "o(Steam_Engine)",
          "n(Task_Performance)"
        ],
        "cumulative_arc": "The text has moved from defining the Orthodox Computational view to presenting a concrete anomaly (The Watt Governor) that solves the same problem without the Orthodox tools. The necessity of the Computational view is being eroded by the existence of a Dynamical alternative."
      },
      "patterns": [
        {
          "name": "The Computational Cluster",
          "terms": [
            "s(Representation)",
            "n(Computation)",
            "n(Sequence)",
            "n(Homuncularity)"
          ],
          "description": "A set of mutually necessitating properties that define the standard view of intelligent systems. If one is present, the others are assumed."
        },
        {
          "name": "The Dynamical Refutation",
          "terms": [
            "o(Watt_Governor)",
            "o(Direct_Coupling)",
            "~s(Representation)"
          ],
          "description": "The use of a physical counter-example to demonstrate that a normative function (Control) can exist without the standard subjective prerequisites (Representation)."
        }
      ],
      "graph_update": {
        "new_nodes": [
          "Computational_Cluster",
          "Homuncularity",
          "Sequentiality",
          "Direct_Coupling",
          "Watt_Governor"
        ],
        "new_edges": [
          {
            "from": "Computational_Cluster",
            "to": "Homuncularity",
            "relation": "implies"
          },
          {
            "from": "Computational_Cluster",
            "to": "Sequentiality",
            "relation": "implies"
          },
          {
            "from": "Watt_Governor",
            "to": "Direct_Coupling",
            "relation": "implies"
          },
          {
            "from": "Watt_Governor",
            "to": "Computational_Cluster",
            "relation": "contradicts"
          }
        ],
        "removed_nodes": []
      }
    },
    {
      "prose": {
        "summary": "Van Gelder juxtaposes two distinct solutions to the 'governing problem': a hypothetical computational solution and the actual historical solution provided by James Watt. The computational approach solves the problem by decomposing it into discrete subtasks (measuring, calculating, adjusting) executed sequentially by homuncular components manipulating symbolic representations. In contrast, the Watt centrifugal governor solves the problem through direct physical coupling, where the angle of the flywheel arms continuously modulates the steam valve without distinct steps of measurement or calculation. This contrast isolates the 'cluster' of properties defining the orthodox view: representation, computation, sequentiality, and homuncularity.",
        "conceptual_narrative": "In this movement, the text performs a 'phenomenological reduction' of the concept of Control. \n\nFirst, we are presented with the **Computational Governor**. This is the mind as a bureaucracy. To solve the problem of fluctuating speed, the computationalist logic imposes a *Compressive* structure: the continuous world is sliced into discrete snapshots. A temporal gap is introduced between 'reading' the world (Perception) and 'adjusting' the world (Action). To bridge this gap, the system requires *Representation*a symbolic token that preserves the state of the world while the system thinks about it. This necessitates an *Algorithm*: a rule for manipulating these tokens. Consequently, the system becomes *Homuncular*: it is a box containing smaller boxes (measurer, comparator, adjuster), each performing a specific subtask.\n\nThen, the text unveils the **Watt Governor** as the *Objective* reality that shatters this compressive necessity. Here, the 'gap' between perception and action vanishes. The angle of the arms does not 'represent' the speed; it *is* the speed, transformed. The valve adjustment does not 'follow' the measurement; the measurement and the adjustment are a single, coupled, continuous state-evolution. The Watt Governor sublates the rigid 'Step' of the algorithm into the fluid 'Flow' of the dynamic system. It demonstrates that intelligence (effective governing) does not require the internal mirroring of the external world.",
        "interpretive_notes": "The crucial philosophical move here is identifying that 'Representation' is a byproduct of 'Decomposition.' We only need representations if we break time into chunks (measure, *then* act). If time is continuous (coupling), the representation is unnecessary because the world itself is available."
      },
      "logic": {
        "axioms": [
          {
            "id": "Axiom_Homuncular_Decomposition",
            "premises_symbolic": [
              "comp_nec(n(Control))",
              "n(Orthodoxy)"
            ],
            "conclusion_symbolic": "comp_nec(n(Decomposition) & n(Sequence) & s(Representation) & n(Homuncularity))",
            "polarity": "compressive"
          },
          {
            "id": "Axiom_Temporal_Gap",
            "premises_symbolic": [
              "n(Sequence)"
            ],
            "conclusion_symbolic": "comp_nec(s(Gap_Perception_Action) & s(Representation))",
            "polarity": "compressive"
          },
          {
            "id": "Axiom_Watt_Simultaneity",
            "premises_symbolic": [
              "o(Watt_Governor)"
            ],
            "conclusion_symbolic": "o(Coupling) & ~n(Sequence) & ~s(Gap_Perception_Action)",
            "polarity": "expansive"
          }
        ],
        "formalizations": [
          {
            "term": "The Computational Cluster",
            "pml_expression": "n(Algorithm) & s(Representation) & n(Sequence) & n(Homuncularity)",
            "dependencies": [
              "Axiom_Homuncular_Decomposition"
            ]
          },
          {
            "term": "Homuncularity",
            "pml_expression": "comp_nec(o(System) > o(Part_Communication))",
            "dependencies": []
          },
          {
            "term": "Direct Coupling",
            "pml_expression": "o(State_Variable_Engine) <-> o(State_Variable_Governor)",
            "dependencies": [
              "Axiom_Dynamical_Hypothesis"
            ]
          }
        ]
      },
      "english_translations": {
        "axiom_translations": [
          {
            "axiom_id": "Axiom_Homuncular_Decomposition",
            "plain_english": "Under the Orthodox view, the necessity of Control collapses into a requirement for decomposing the task into sequential steps, which necessitates internal representations and homuncular sub-components.",
            "source_passage": "These properties-representation, computation, sequential and cyclic operation, and homuncularity-form a mutually interdependent cluster"
          },
          {
            "axiom_id": "Axiom_Temporal_Gap",
            "plain_english": "If control is sequential (measure then act), there exists a necessary gap between perception and action which must be filled by a representation.",
            "source_passage": "the appropriate change in the throttle valve can only be calculated after the discrepancy ... has been calculated."
          },
          {
            "axiom_id": "Axiom_Watt_Simultaneity",
            "plain_english": "The objective reality of the Watt Governor demonstrates control via direct coupling, negating the necessity of sequential processing and the gap between perception and action.",
            "source_passage": "The result was that as the speed of the main wheel increased, the arms raised, closing the valve... The engine adopted a constant speed... in the presence of large fluctuations"
          }
        ],
        "term_definitions": [
          {
            "term": "Homuncularity",
            "definition": "A structural organization where the system is broken down into communicating sub-components (homunculi), each responsible for a distinct subtask."
          },
          {
            "term": "Direct Coupling",
            "definition": "A physical relationship where the state of one system continuously and immediately determines the state of another, without intermediate symbolic processing."
          },
          {
            "term": "The Governing Problem",
            "definition": "The normative requirement to maintain a parameter (speed) within a specific range despite objective fluctuations (pressure/load)."
          }
        ]
      },
      "dialectical_history": {
        "concepts_born": [
          "Homuncularity",
          "Sequential Decomposition",
          "The Computational Cluster",
          "Direct Coupling"
        ],
        "concepts_sublated": [
          {
            "from": "Control (Algorithmic)",
            "into": "Control (Dynamical)",
            "mechanism": "The Watt Governor solves the 'Governing Problem' (preserved) without the 'Computational Cluster' (cancelled), proving that Representation is accidental, not essential, to Control."
          }
        ],
        "concepts_preserved": [
          "The Governing Problem",
          "Normativity of Success"
        ],
        "cumulative_arc": "Chunk 1 established the opposition between Orthodoxy and Dynamics. Chunk 2 deepens this by defining Orthodoxy not just as 'computers' but as a specific structural reliance on Decomposition, Sequence, and Representation, while positioning the Watt Governor as the material proof that this structure is unnecessary."
      },
      "patterns": [
        {
          "name": "The Homuncular Fallacy",
          "terms": [
            "n(Decomposition)",
            "n(Homuncularity)"
          ],
          "description": "The assumption that because a complex task can be conceptually broken down into steps, the physical system performing the task must structurally mirror those steps."
        },
        {
          "name": "The Representational Gap",
          "terms": [
            "n(Sequence)",
            "s(Gap_Perception_Action)",
            "s(Representation)"
          ],
          "description": "The creation of a temporal space between input and output that requires a symbol to bridge it. Direct coupling removes the time-lag, and thus removes the need for the symbol."
        }
      ],
      "graph_update": {
        "new_nodes": [
          "Computational_Governor",
          "Watt_Governor",
          "Homuncularity",
          "Sequence",
          "Direct_Coupling",
          "Gap_Perception_Action"
        ],
        "new_edges": [
          {
            "from": "Computational_Governor",
            "to": "Homuncularity",
            "relation": "implies"
          },
          {
            "from": "Computational_Governor",
            "to": "Sequence",
            "relation": "implies"
          },
          {
            "from": "Sequence",
            "to": "Gap_Perception_Action",
            "relation": "implies"
          },
          {
            "from": "Watt_Governor",
            "to": "Direct_Coupling",
            "relation": "implies"
          },
          {
            "from": "Direct_Coupling",
            "to": "Gap_Perception_Action",
            "relation": "contradicts"
          },
          {
            "from": "Watt_Governor",
            "to": "Algorithm",
            "relation": "contradicts"
          }
        ],
        "removed_nodes": []
      }
    },
    {
      "prose": {
        "summary": "Van Gelder contrasts two distinct methods for solving the 'governing problem' of regulating a steam engine. First, he constructs a hypothetical 'Computational Governor' that operates algorithmically: it measures speed, calculates discrepancies, computes adjustments, and acts in a discrete, sequential cycle. He identifies this approach with the standard cognitive science view, relying on representation, homuncularity, and symbolic manipulation. Second, he describes the actual historical solution: the Watt Centrifugal Governor. This device uses a direct mechanical linkage (spindle and flying arms) to adjust the valve continuously in real-time. He argues that while both achieve the goal of control, the Watt governor lacks the defining features of computationit has no distinct representations, no discrete steps, and no homuncular decomposition.",
        "conceptual_narrative": "This chunk enacts the central dialectical confrontation of the text. We begin with the **Compressive** model: the Computational Governor. This model attempts to solve the problem of reality (fluctuating steam pressure) by imposing a rigid, logical structure (the algorithm). It breaks time into discrete steps and space into functional modules (homunculi), effectively 'thinking' about the engine rather than just being with it. \n\nThen, the text introduces the **Expansive** counter-force: the Watt Governor. This device is not a mind imposed on matter, but matter organized to self-regulate. It dissolves the barrier between 'measuring' and 'acting'; the angle of the arms *is* the measurement and *is* the action simultaneously. This moment marks the sublation of the 'Algorithm' by 'Dynamics.' We see that intelligent behavior (successful control) does not necessitate the heavy metaphysical baggage of symbols and rules. The concept of 'Representation' is shown to be an optional tool, not a necessary condition for cognition-like behavior.",
        "interpretive_notes": "Van Gelder is careful to define the 'Computational Governor' extremely precisely before dismissing it. He identifies a 'cluster' of properties: Representation, Computation, Sequential/Cyclic operation, and Homuncularity. This cluster forms the definition of the 'Orthodoxy' he attacks. The Watt Governor is the existential negation of this cluster. Note the shift in ontology: the Computational Governor exists in *logical time* (step 1, step 2), while the Watt Governor exists in *physical time* (continuous evolution)."
      },
      "logic": {
        "axioms": [
          {
            "id": "Axiom_Computational_Cluster",
            "premises_symbolic": [
              "n(Computational_Governor)"
            ],
            "conclusion_symbolic": "comp_nec(s(Representation) & n(Discrete_Sequence) & n(Homuncularity))",
            "polarity": "compressive"
          },
          {
            "id": "Axiom_Watt_Simultaneity",
            "premises_symbolic": [
              "o(Watt_Governor)"
            ],
            "conclusion_symbolic": "exp_nec(o(Measurement) <-> o(Action))",
            "polarity": "expansive"
          },
          {
            "id": "Axiom_Watt_Refutation",
            "premises_symbolic": [
              "o(Watt_Governor)",
              "n(Control)"
            ],
            "conclusion_symbolic": "~comp_nec(s(Representation) | n(Algorithm))",
            "polarity": "expansive"
          }
        ],
        "formalizations": [
          {
            "term": "Computational_Governor",
            "pml_expression": "n(Control) & n(Algorithm) & s(Symbolic_Manipulation)",
            "dependencies": [
              "n(Control)",
              "n(Algorithm)"
            ]
          },
          {
            "term": "Watt_Governor",
            "pml_expression": "n(Control) & o(Continuous_Coupling) & ~s(Symbolic_Manipulation)",
            "dependencies": [
              "n(Control)",
              "o(Coupling)"
            ]
          },
          {
            "term": "Homuncularity",
            "pml_expression": "n(Decomposition) & s(Internal_Communication)",
            "dependencies": [
              "n(Decomposition)"
            ]
          }
        ]
      },
      "english_translations": {
        "axiom_translations": [
          {
            "axiom_id": "Axiom_Computational_Cluster",
            "plain_english": "If a system is defined as a 'Computational Governor,' it necessarily operates through symbolic representation, discrete sequential steps, and a homuncular division of labor.",
            "source_passage": "These properties-representation, computation, sequential and cyclic operation, and homuncularity-form a mutually interdependent cluster"
          },
          {
            "axiom_id": "Axiom_Watt_Simultaneity",
            "plain_english": "In the objective reality of the Watt Governor, the act of measuring the speed is inextricably simultaneous with the act of adjusting the valve (action).",
            "source_passage": "By a clever arrangement, this arm motion was linked directly to the throttle valve... The engine adopted a constant speed, maintained with extraordinary swiftness"
          },
          {
            "axiom_id": "Axiom_Watt_Refutation",
            "plain_english": "The existence of the Watt Governor proves that achieving the normative goal of Control does not necessitate the use of Representations or Algorithms.",
            "source_passage": "the Watt centrifugal governor does not exhibit this cluster of properties as a whole, nor any one of them individually."
          }
        ],
        "term_definitions": [
          {
            "term": "Homuncularity",
            "definition": "A structural approach where a complex task is broken down into subtasks performed by distinct components that communicate via messages."
          },
          {
            "term": "Discrete_Sequence",
            "definition": "A mode of operation where events occur one after another in a fixed order (Step 1, then Step 2), as opposed to continuously."
          },
          {
            "term": "Continuous_Coupling",
            "definition": "A physical relationship where the state of one component (spindle speed) immediately and mathematically determines the state of another (valve angle) without intermediate symbolic processing."
          }
        ]
      },
      "dialectical_history": {
        "concepts_born": [
          "Computational_Cluster",
          "Homuncularity",
          "Discrete_Sequence",
          "Continuous_Coupling"
        ],
        "concepts_sublated": [
          {
            "from": "n(Control) => n(Algorithm)",
            "into": "n(Control) => (n(Algorithm) v o(Dynamics))",
            "mechanism": "The Watt Governor demonstrates that Algorithmic control is merely a subset, not a necessity, of Control."
          }
        ],
        "concepts_preserved": [
          "n(Control)",
          "n(Cognition) (as the ultimate target of analogy)"
        ],
        "cumulative_arc": "We have moved from the abstract definition of the Governing Problem to two concrete instantiations. The Orthodox view (Computation) is revealed as a specific, rigid imposition of logic onto physics. The Radical view (Dynamics/Watt) is revealed as a fluid integration of physics itself. The necessity of Computation is broken."
      },
      "patterns": [
        {
          "name": "The Homuncular Fallacy",
          "terms": [
            "Homuncularity",
            "Decomposition",
            "s(Representation)"
          ],
          "description": "The tendency to explain a system's behavior by postulating smaller internal systems (homunculi) that perform sub-tasks, leading to infinite regress or complexity."
        },
        {
          "name": "Direct Coupling",
          "terms": [
            "o(Watt_Governor)",
            "exp_nec(Simultaneity)",
            "o(Coupling)"
          ],
          "description": "A pattern where the sensor and the actuator are physically continuous, eliminating the temporal gap required for symbolic processing."
        }
      ],
      "graph_update": {
        "new_nodes": [
          "Computational_Governor",
          "Watt_Governor",
          "Homuncularity",
          "Discrete_Sequence",
          "Continuous_Coupling"
        ],
        "new_edges": [
          {
            "from": "Computational_Governor",
            "to": "s(Representation)",
            "relation": "implies"
          },
          {
            "from": "Computational_Governor",
            "to": "Homuncularity",
            "relation": "implies"
          },
          {
            "from": "Watt_Governor",
            "to": "Continuous_Coupling",
            "relation": "implies"
          },
          {
            "from": "Watt_Governor",
            "to": "Computational_Governor",
            "relation": "contradicts"
          },
          {
            "from": "Watt_Governor",
            "to": "n(Control)",
            "relation": "implies"
          }
        ],
        "removed_nodes": []
      }
    },
    {
      "prose": {
        "summary": "Van Gelder juxtaposes two distinct solutions to the 'governing problem' of regulating a steam engine. He first outlines a hypothetical 'Computational Governor,' constructed according to the principles of orthodox cognitive science: a homuncular system that relies on discrete steps of measuring, calculating, and adjusting based on symbolic representations. This is contrasted with the actual historical solution, the 'Watt Centrifugal Governor,' which employs direct physical coupling. The Watt system achieves precise control through continuous dynamics without internal representations, distinct computational steps, or homuncular decomposition.",
        "conceptual_narrative": "In this movement, the text establishes the specific nature of the 'Orthodox' view by constructing a hypothetical machine: the Computational Governor. This device represents the Compressive forceit creates order by slicing time into discrete sequences (measure, then compute, then act) and by slicing reality into symbolic representations. This is the logic of the Algorithm. \n\nAgainst this, the text positions the Watt Governor as an Expansive counter-example. The Watt Governor does not pause to calculate; its 'thinking' is indistinguishable from its physical movement. Here, the concept of 'Control' is liberated from the necessity of 'Computation.' The argument demonstrates that intelligence (control) does not require a separation between the knower (the representation) and the known (the engine state). Instead, the Watt Governor suggests a form of cognition based on continuous, real-time coupling, where the system settles into a state rather than computing an answer.",
        "interpretive_notes": "The author explicitly defines the 'Computational Cluster': Representation, Computation, Sequential Operation, and Homuncularity. This defines the Compressive polarity in this text. The Watt Governor is introduced not just as an alternative, but as an existence proof that falsifies the necessity of that cluster for intelligent behavior."
      },
      "logic": {
        "axioms": [
          {
            "id": "Axiom_Computational_Cluster",
            "premises_symbolic": [
              "comp_nec(n(Computational_System))"
            ],
            "conclusion_symbolic": "s(Representation) & n(Discrete_Sequence) & n(Homuncularity)",
            "polarity": "compressive"
          },
          {
            "id": "Axiom_Orthodox_Cycle",
            "premises_symbolic": [
              "n(Orthodox_Control)"
            ],
            "conclusion_symbolic": "n(Perception) -> n(Computation) -> n(Action)",
            "polarity": "compressive"
          },
          {
            "id": "Axiom_Watt_Simultaneity",
            "premises_symbolic": [
              "o(Watt_Governor)"
            ],
            "conclusion_symbolic": "n(Control) & ~(n(Perception) -> n(Computation) -> n(Action))",
            "polarity": "expansive"
          }
        ],
        "formalizations": [
          {
            "term": "Homuncularity",
            "pml_expression": "n(Decomposition) & o(Internal_Communication)",
            "dependencies": [
              "n(Computational_System)"
            ]
          },
          {
            "term": "Discrete_Sequence",
            "pml_expression": "n(Step_1) & n(Step_2) & ~(n(Step_1) <-> n(Step_2))",
            "dependencies": []
          },
          {
            "term": "Direct_Coupling",
            "pml_expression": "o(State_Change) <-> o(System_Response)",
            "dependencies": [
              "o(Watt_Governor)"
            ]
          }
        ]
      },
      "english_translations": {
        "axiom_translations": [
          {
            "axiom_id": "Axiom_Computational_Cluster",
            "plain_english": "If a system is defined as Computational under the compressive necessity of the orthodox view, it must possess symbolic Representations, operate in Discrete Sequences, and be composed of communicating Homunculi.",
            "source_passage": "These properties-representation, computation, sequential and cyclic operation, and homuncularity-form a mutually interdependent cluster"
          },
          {
            "axiom_id": "Axiom_Orthodox_Cycle",
            "plain_english": "The normative structure of Orthodox Control requires a temporal sequence: first Perception (measurement), then Computation (thinking), and finally Action (adjustment).",
            "source_passage": "it first measures (or 'perceives') its environment; it then internally computes... it then effects this change ('acts' on its environment)."
          },
          {
            "axiom_id": "Axiom_Watt_Simultaneity",
            "plain_english": "The objective reality of the Watt Governor demonstrates Normative Control while negating the sequential separation of Perception, Computation, and Action.",
            "source_passage": "The engine adopted a constant speed, maintained with extraordinary swiftness and smoothness... the Watt centrifugal governor does not exhibit this cluster of properties"
          }
        ],
        "term_definitions": [
          {
            "term": "Homuncularity",
            "definition": "A structural property where a system is broken down into sub-components (homunculi) that interact by passing meaningful messages."
          },
          {
            "term": "Discrete_Sequence",
            "definition": "A temporal mode of operation where tasks are performed in a fixed order (Step 1, then Step 2), strictly separating input from processing and output."
          },
          {
            "term": "Direct_Coupling",
            "definition": "A physical arrangement where the state of the controller is continuously determined by the state of the system being controlled, without intermediate symbolic processing."
          }
        ]
      },
      "dialectical_history": {
        "concepts_born": [
          "Homuncularity",
          "Discrete_Sequence",
          "The_Computational_Cluster",
          "Perception_Action_Cycle"
        ],
        "concepts_sublated": [
          {
            "from": "n(Algorithm)",
            "into": "o(Coupling)",
            "mechanism": "The Watt Governor solves the algorithmic problem (control) through physical geometry, stripping away the need for symbolic steps."
          }
        ],
        "concepts_preserved": [
          "n(Control)",
          "n(Cognition)",
          "o(Steam_Engine)"
        ],
        "cumulative_arc": "The text has moved from defining the governing problem to showing that the Computational solution is merely one possibility, and a clumsy one at that. The Watt Governor is established as the material refutation of the idea that Control necessitates Computation."
      },
      "patterns": [
        {
          "name": "The Homuncular Fallacy",
          "terms": [
            "n(Homuncularity)",
            "s(Representation)",
            "n(Decomposition)"
          ],
          "description": "The tendency to explain intelligence by breaking it into smaller intelligent parts (homunculi) that pass messages, mirroring human bureaucracy."
        },
        {
          "name": "Temporal Discretization",
          "terms": [
            "n(Discrete_Sequence)",
            "n(Algorithm)",
            "n(Step_1)"
          ],
          "description": "The imposition of discrete time-steps onto continuous reality, necessary for computation but absent in dynamical coupling."
        }
      ],
      "graph_update": {
        "new_nodes": [
          "Computational_Governor",
          "Watt_Governor",
          "Homuncularity",
          "Discrete_Sequence",
          "Perception_Action_Cycle"
        ],
        "new_edges": [
          {
            "from": "Computational_Governor",
            "to": "Homuncularity",
            "relation": "implies"
          },
          {
            "from": "Computational_Governor",
            "to": "Discrete_Sequence",
            "relation": "implies"
          },
          {
            "from": "Watt_Governor",
            "to": "Homuncularity",
            "relation": "contradicts"
          },
          {
            "from": "Watt_Governor",
            "to": "Discrete_Sequence",
            "relation": "contradicts"
          },
          {
            "from": "Watt_Governor",
            "to": "n(Control)",
            "relation": "implies"
          }
        ],
        "removed_nodes": []
      }
    },
    {
      "prose": {
        "summary": "Van Gelder juxtaposes two distinct solutions to the 'governing problem' of the steam engine: a hypothetical Computational Governor and the historical Watt Centrifugal Governor. The former relies on a sequential algorithm of measurement, calculation, and adjustment, necessitating internal representations and a homuncular architecture. The latter achieves the same normative goal (speed uniformity) through direct physical coupling and continuous motion, bypassing the need for symbolic representation or discrete algorithmic steps.",
        "conceptual_narrative": "In this movement, the text stages a confrontation between the Compressive intellect and Expansive reality. The Compressive view is embodied in the 'Computational Governor'a hypothetical device that solves the problem of flux by imposing a rigid, step-by-step logic upon the world. This device creates a gap between 'perception' and 'action,' a gap that must be bridged by 'Representation' and 'Calculation.' It treats time as a series of discrete snapshots (Sequence) and the machine as a bureaucracy of communicating parts (Homuncularity).\n\nAgainst this, the text presents the Watt Centrifugal Governor as the avatar of Expansive necessity. Here, the gap between measuring and acting is dissolved. There is no moment where the governor 'knows' the speed but has not yet 'adjusted' the valve. The 'measurement' (arm angle) and the 'action' (valve opening) are physically continuous and coupled. The Watt governor sublates the concept of 'Intelligence' by demonstrating that 'Control'a highly normative achievementdoes not require the subjective interiority of an algorithm. The 'Ghost in the Machine' is exorcised by the physics of the machine itself.",
        "interpretive_notes": "Crucially, the text defines the 'Computational' not just as using computers, but as a specific metaphysical cluster: Representation, Computation, Sequentiality, and Homuncularity. These are mutually interdependent. By showing that the Watt governor lacks *all* of these yet performs the task, Van Gelder prepares the ground to argue that Cognition is more like the Watt governor than the Turing machine. The logic moves from `comp_nec(Algorithm)` to `exp_pos(Coupling)`."
      },
      "logic": {
        "axioms": [
          {
            "id": "Axiom_Computational_Cluster",
            "premises_symbolic": [
              "o(Computational_Governor)"
            ],
            "conclusion_symbolic": "comp_nec(s(Representation) & n(Algorithm) & o(Discrete_Sequence) & n(Homuncularity))",
            "polarity": "compressive"
          },
          {
            "id": "Axiom_Watt_Mechanism",
            "premises_symbolic": [
              "o(Watt_Governor)"
            ],
            "conclusion_symbolic": "exp_nec(o(Coupling) & o(Continuous_Motion)) & ~s(Representation) & ~o(Discrete_Sequence)",
            "polarity": "expansive"
          },
          {
            "id": "Axiom_Homuncularity",
            "premises_symbolic": [
              "n(Homuncularity)"
            ],
            "conclusion_symbolic": "comp_nec(s(Message_Passing) & n(Decomposition))",
            "polarity": "compressive"
          }
        ],
        "formalizations": [
          {
            "term": "Homuncularity",
            "pml_expression": "n(Decomposition) & s(Internal_Communication)",
            "dependencies": [
              "s(Representation)"
            ]
          },
          {
            "term": "The_Gap",
            "pml_expression": "o(Time_Lag) & (s(Perception) -> s(Action))",
            "dependencies": [
              "o(Discrete_Sequence)"
            ]
          },
          {
            "term": "Coupling",
            "pml_expression": "exp_nec(o(State_A) <-> o(State_B))",
            "dependencies": []
          }
        ]
      },
      "english_translations": {
        "axiom_translations": [
          {
            "axiom_id": "Axiom_Computational_Cluster",
            "plain_english": "If a system is identified as a Computational Governor, it necessitates the existence of symbolic Representations, rule-based Algorithms, discrete Sequential steps, and a Homuncular architecture of sub-components.",
            "source_passage": "These properties-representation, computation, sequential and cyclic operation, and homuncularity-form a mutually interdependent cluster"
          },
          {
            "axiom_id": "Axiom_Watt_Mechanism",
            "plain_english": "The objective reality of the Watt Governor necessitates direct physical Coupling and Continuous Motion, effectively negating the need for Representation or Discrete Sequential steps.",
            "source_passage": "The Watt centrifugal governor does not exhibit this cluster of properties as a whole, nor any one of them individually."
          },
          {
            "axiom_id": "Axiom_Homuncularity",
            "plain_english": "The normative structure of Homuncularity necessitates a system decomposed into parts that interact by passing meaningful messages (internal communication).",
            "source_passage": "Homuncular components are ones that... interact by communication (that is, by passing meaningful messages)."
          }
        ],
        "term_definitions": [
          {
            "term": "Homuncularity",
            "definition": "A systemic organization where complex tasks are broken down into subtasks performed by semi-autonomous components (homunculi) that communicate via representations."
          },
          {
            "term": "Perceive-Act Cycle",
            "definition": "The sequential loop characteristic of computational systems: Measure environment -> Compute -> Act on environment -> Repeat."
          },
          {
            "term": "Direct Coupling",
            "definition": "A physical relationship where the state of one system continuously and immediately determines the state of another, without intermediate symbolic processing."
          }
        ]
      },
      "dialectical_history": {
        "concepts_born": [
          "Homuncularity",
          "Perceive-Act Cycle",
          "Direct Coupling",
          "Computational Cluster"
        ],
        "concepts_sublated": [
          {
            "from": "n(Control)",
            "into": "o(Coupling)",
            "mechanism": "The Watt Governor demonstrates that 'Control' (previously assumed to require intelligent calculation) can be fully realized through blind physical 'Coupling'."
          }
        ],
        "concepts_preserved": [
          "n(Uniformity)",
          "o(Steam_Engine)"
        ],
        "cumulative_arc": "The text has moved from defining the general 'Orthodoxy' to dissecting its specific mechanism (The Computational Governor) and immediately juxtaposing it with a successful counter-example (The Watt Governor). The abstract 'Dynamical Hypothesis' is now grounded in the concrete machinery of the steam engine."
      },
      "patterns": [
        {
          "name": "The Computational Cluster",
          "terms": [
            "s(Representation)",
            "n(Algorithm)",
            "o(Discrete_Sequence)",
            "n(Homuncularity)"
          ],
          "description": "The set of mutually interdependent properties that define the Orthodox view of cognition."
        },
        {
          "name": "The Perception-Action Gap",
          "terms": [
            "s(Perception)",
            "o(Time_Delay)",
            "s(Action)"
          ],
          "description": "In computational systems, perception and action are separated by the time required for calculation; in dynamical systems, they are simultaneous/coupled."
        }
      ],
      "graph_update": {
        "new_nodes": [
          "Computational_Governor",
          "Watt_Governor",
          "Homuncularity",
          "Discrete_Sequence",
          "Continuous_Motion",
          "Coupling"
        ],
        "new_edges": [
          {
            "from": "Computational_Governor",
            "to": "s(Representation)",
            "relation": "implies"
          },
          {
            "from": "Computational_Governor",
            "to": "n(Homuncularity)",
            "relation": "implies"
          },
          {
            "from": "Watt_Governor",
            "to": "s(Representation)",
            "relation": "contradicts"
          },
          {
            "from": "Watt_Governor",
            "to": "Coupling",
            "relation": "implies"
          },
          {
            "from": "Coupling",
            "to": "Discrete_Sequence",
            "relation": "contradicts"
          }
        ],
        "removed_nodes": []
      }
    },
    {
      "prose": {
        "summary": "Van Gelder contrasts two distinct solutions to the 'governing problem' of regulating a steam engine. First, he describes a hypothetical 'Computational Governor,' derived through logical decomposition. This device would operate cyclically: measuring speed, calculating a discrepancy, computing a valve adjustment, and executing the change. It relies on symbolic representations, discrete algorithms, and a homuncular architecture of communicating sub-components. Second, he presents the actual historical solution: the Watt Centrifugal Governor. This device solves the same problem without any of the computational properties. Instead of a perceive-compute-act cycle, it utilizes a direct, continuous physical coupling where the angle of the flyballs (driven by engine speed) instantaneously regulates the steam valve. The Watt governor demonstrates that complex control does not require internal representation or algorithmic steps.",
        "conceptual_narrative": "The dialectic moves from the abstract decomposition of a problem to the concrete reality of its solution. The 'Computational Governor' represents the **Compressive** approach: it breaks time into discrete steps (perception, computation, action) and breaks the device into functional parts (homunculi). It assumes that to solve a problem, the system must internally mirror the logical steps of the problem's description. This creates a gap between the world and the representation of the world. \n\nThe 'Watt Governor' represents the **Expansive** reality: it dissolves these divisions. There is no distinct step where the governor 'knows' the speed but hasn't yet 'acted'; the measuring and the adjusting are continuous and simultaneous phases of a single physical process. The 'Representation' is sublated into 'Coupling,' and the 'Algorithm' is sublated into 'Differential Dynamics.' This establishes that intelligent behavior (Control) can arise from the system's shape and physics, rather than from a ghost in the machine manipulating symbols.",
        "interpretive_notes": "This chunk provides the central counter-example of the paper. It establishes the 'Computational Cluster' (Representation, Computation, Sequentiality, Homuncularity) not as a universal necessity for control, but as a specific, optional implementation strategyone that the Watt governor successfully avoids. This paves the way for the Dynamical Hypothesis by proving existence: if a steam engine can be governed without computation, perhaps a mind can be too."
      },
      "logic": {
        "axioms": [
          {
            "id": "Axiom_Computational_Cluster",
            "premises_symbolic": [
              "n(Computational_Stance)"
            ],
            "conclusion_symbolic": "comp_nec(s(Representation) & n(Algorithm) & n(Discrete_Sequence) & n(Homuncularity))",
            "polarity": "compressive"
          },
          {
            "id": "Axiom_Watt_Reality",
            "premises_symbolic": [
              "o(Watt_Governor)"
            ],
            "conclusion_symbolic": "n(Control) & ~s(Representation) & ~n(Algorithm) & ~n(Discrete_Sequence)",
            "polarity": "expansive"
          },
          {
            "id": "Axiom_Representation_Necessity_Refuted",
            "premises_symbolic": [
              "o(Watt_Governor)",
              "n(Control)"
            ],
            "conclusion_symbolic": "~comp_nec(s(Representation))",
            "polarity": "expansive"
          }
        ],
        "formalizations": [
          {
            "term": "Homuncularity",
            "pml_expression": "n(Functional_Decomposition) & o(Message_Passing)",
            "dependencies": [
              "n(Decomposition)"
            ]
          },
          {
            "term": "Discrete_Sequence",
            "pml_expression": "n(Step_1) > n(Step_2) > n(Step_3)",
            "dependencies": [
              "n(Algorithm)"
            ]
          },
          {
            "term": "Continuous_Coupling",
            "pml_expression": "o(System_State) <-> o(Controller_State)",
            "dependencies": [
              "o(Coupling)"
            ]
          }
        ]
      },
      "english_translations": {
        "axiom_translations": [
          {
            "axiom_id": "Axiom_Computational_Cluster",
            "plain_english": "If we adopt the Computational Stance, the system essentially requires a cluster of properties: internal Representations, algorithmic rules, discrete sequential steps, and homuncular parts.",
            "source_passage": "These properties-representation, computation, sequential and cyclic operation, and homuncularity-form a mutually interdependent cluster"
          },
          {
            "axiom_id": "Axiom_Watt_Reality",
            "plain_english": "The objective existence of the Watt Governor demonstrates successful Control without utilizing Representation, Algorithms, or Discrete Sequences.",
            "source_passage": "Now, the Watt centrifugal governor does not exhibit this cluster of properties as a whole, nor any one of them individually."
          },
          {
            "axiom_id": "Axiom_Representation_Necessity_Refuted",
            "plain_english": "Since the Watt Governor achieves Control without Representation, Representation is not a necessary condition for Control.",
            "source_passage": "Does it follow that, deep down, they are really the same kind of device... Or are they deeply different"
          }
        ],
        "term_definitions": [
          {
            "term": "Homuncularity",
            "definition": "A design where the system is broken into sub-components (homunculi) that communicate via messages to perform subtasks."
          },
          {
            "term": "Discrete_Sequence",
            "definition": "The operation of a system in distinct, ordered steps (e.g., perceive, then think, then act), as opposed to continuous flow."
          },
          {
            "term": "Coupling",
            "definition": "A relationship where two systems (or a system and its controller) influence each other continuously and directly."
          }
        ]
      },
      "dialectical_history": {
        "concepts_born": [
          "Homuncularity",
          "Discrete_Sequence",
          "Computational_Cluster"
        ],
        "concepts_sublated": [
          {
            "from": "n(Decomposition)",
            "into": "o(Coupling)",
            "mechanism": "The logical breakdown of the problem (measure, calculate, adjust) is sublated by the physical synthesis of the solution (direct mechanical linkage), which achieves the same end without the intermediate steps."
          }
        ],
        "concepts_preserved": [
          "n(Control)",
          "o(Steam_Engine)"
        ],
        "cumulative_arc": "The text has moved from defining the problem (Chunk 1) to contrasting two paradigms of solution (Chunk 2). The 'Algorithm' is exposed as a specific, cumbersome method (Thesis), while the 'Watt Governor' is revealed as a streamlined, natural method (Antithesis) that achieves the goal without the theoretical baggage of the Thesis."
      },
      "patterns": [
        {
          "name": "The Computational Cluster",
          "terms": [
            "s(Representation)",
            "n(Algorithm)",
            "n(Homuncularity)",
            "n(Discrete_Sequence)"
          ],
          "description": "The set of mutually interdependent properties that define the orthodox view of intelligent systems."
        },
        {
          "name": "Dynamical Directness",
          "terms": [
            "o(Coupling)",
            "~s(Representation)",
            "~n(Discrete_Sequence)"
          ],
          "description": "The pattern of solving control problems through continuous physical interaction rather than symbolic mediation."
        }
      ],
      "graph_update": {
        "new_nodes": [
          "n(Homuncularity)",
          "n(Discrete_Sequence)",
          "o(Watt_Governor)",
          "n(Computational_Stance)"
        ],
        "new_edges": [
          {
            "from": "n(Computational_Stance)",
            "to": "n(Homuncularity)",
            "relation": "implies"
          },
          {
            "from": "o(Watt_Governor)",
            "to": "n(Homuncularity)",
            "relation": "contradicts"
          },
          {
            "from": "o(Watt_Governor)",
            "to": "s(Representation)",
            "relation": "contradicts"
          }
        ],
        "removed_nodes": []
      }
    },
    {
      "prose": {
        "summary": "Van Gelder juxtaposes two methods of solving the 'governing problem' of the steam engine. First, he constructs a hypothetical 'Computational Governor' which solves the problem via the orthodox cognitive science approach: decomposing the task into discrete sub-tasks (measuring, calculating, adjusting), employing symbolic representations of speed and pressure, and executing a sequential algorithm through homuncular components. Second, he describes the actual historical solution: the 'Watt Centrifugal Governor'. This device uses a rotating spindle with flyballs that rise or fall with centrifugal force, mechanically linked to the throttle valve. The Watt Governor achieves control not through discrete steps or symbolic manipulation, but through continuous, direct physical coupling. The section concludes by defining the 'Computational Cluster'representation, computation, sequentiality, and homuncularityand noting that the Watt Governor operates successfully while possessing none of these properties.",
        "conceptual_narrative": "In this movement, the text performs a 'phenomenological reduction' of the computationalist mindset. By imagining how a modern cognitive scientist would design a steam governor, Van Gelder makes the hidden assumptions of Orthodoxy explicit: the necessity of **Representation** (symbols standing in for reality), **Segmentation** (breaking time into discrete steps), and **Homuncularity** (breaking the system into communicating sub-agents).\n\nAgainst this rigid, compressive structure, the text posits the **Watt Governor**. This device represents the intrusion of the Real (expansive necessity) into the theoretical model. It does not 'know' the speed; it *is* the speed, transformed. It does not 'calculate' the adjustment; the adjustment *emerges* from the physical laws governing its motion. The dialectical tension is thus established: we have two systems exhibiting the same normative behavior (Control), but one relies on a heavy metaphysical infrastructure (The Computational Cluster) while the other dissolves that infrastructure into pure dynamical Coupling. The chunk ends by asking the pivotal question: if the Watt Governor controls without computing, must Cognition compute to control?",
        "interpretive_notes": "The definition of the 'Computational Cluster' is crucial here. Van Gelder explicitly links Representation, Algorithm (Sequence), and Homuncularity as a mutually interdependent package. This prepares the ground for a *Modus Tollens* argument: If Cognition implies Computation, it must exhibit this cluster. If a dynamical system (like the Watt governor) explains the phenomena better without the cluster, the antecedent is threatened."
      },
      "logic": {
        "axioms": [
          {
            "id": "Axiom_Computational_Cluster",
            "premises_symbolic": [
              "o(System_S)",
              "n(Computational_Stance)"
            ],
            "conclusion_symbolic": "comp_nec(s(Representation) & n(Discrete_Sequence) & o(Homuncularity))",
            "polarity": "compressive"
          },
          {
            "id": "Axiom_Watt_Mechanism",
            "premises_symbolic": [
              "o(Watt_Governor)"
            ],
            "conclusion_symbolic": "o(Direct_Coupling) & n(Simultaneity) & ~s(Representation)",
            "polarity": "expansive"
          },
          {
            "id": "Axiom_Functional_Equivalence",
            "premises_symbolic": [
              "n(Control_Task)"
            ],
            "conclusion_symbolic": "exp_pos(n(Computational_Stance)) & exp_pos(o(Watt_Governor))",
            "polarity": "expansive"
          }
        ],
        "formalizations": [
          {
            "term": "Homuncularity",
            "pml_expression": "o(System_Decomposition) & n(Internal_Communication)",
            "dependencies": [
              "n(Computational_Stance)"
            ]
          },
          {
            "term": "Direct Coupling",
            "pml_expression": "exp_nec(o(State_A) <-> o(State_B))",
            "dependencies": [
              "o(Watt_Governor)"
            ]
          },
          {
            "term": "Discrete Sequence",
            "pml_expression": "n(Time_Step_1) -> n(Time_Step_2) -> n(Time_Step_3)",
            "dependencies": [
              "n(Algorithm)"
            ]
          }
        ]
      },
      "english_translations": {
        "axiom_translations": [
          {
            "axiom_id": "Axiom_Computational_Cluster",
            "plain_english": "If a system is viewed through the Computational Stance, it necessarily exhibits a cluster of properties: it must use internal symbolic Representations, operate in a Discrete Sequence of steps, and be composed of Homuncular parts that communicate with each other.",
            "source_passage": "These properties-representation, computation, sequential and cyclic operation, and homuncularity-form a mutually interdependent cluster; a device with any one of them will standardly possess others."
          },
          {
            "axiom_id": "Axiom_Watt_Mechanism",
            "plain_english": "The objective reality of the Watt Governor consists of Direct Coupling between components and Simultaneity of action, without relying on subjective Representations.",
            "source_passage": "The result was that as the speed of the main wheel increased, the arms raised... The engine adopted a constant speed, maintained with extraordinary swiftness and smoothness."
          },
          {
            "axiom_id": "Axiom_Functional_Equivalence",
            "plain_english": "For the normative task of Control, it is possible to employ either a Computational solution or a Dynamical (Watt) solution; neither is the sole necessary method for achieving the goal.",
            "source_passage": "The two governors... are patently different in construction, yet they both solve the same control problem... Does it follow that, deep down, they are really the same kind of device?"
          }
        ],
        "term_definitions": [
          {
            "term": "Homuncularity",
            "definition": "A structural property where a system is broken down into sub-components (homunculi) that each perform a sub-task and interact by passing meaningful messages."
          },
          {
            "term": "Computational Governor",
            "definition": "A hypothetical control device that solves the governing problem by measuring variables, encoding them as symbols, calculating adjustments via algorithms, and executing commands sequentially."
          },
          {
            "term": "Watt Governor",
            "definition": "A physical control device that maintains engine speed via continuous mechanical linkage (centrifugal force on flyballs) without distinct steps of measurement or calculation."
          }
        ]
      },
      "dialectical_history": {
        "concepts_born": [
          "The Computational Cluster (Representation, Sequence, Homuncularity)",
          "The Homuncular Fallacy",
          "Direct Coupling"
        ],
        "concepts_sublated": [
          {
            "from": "Task Decomposition",
            "into": "Dynamical Coupling",
            "mechanism": "The Watt Governor proves that complex tasks (Control) do not necessitate breaking the problem into sequential sub-tasks; the problem can be solved holistically through physical geometry."
          }
        ],
        "concepts_preserved": [
          "Control (The normative goal)",
          "The Steam Engine (The environment)"
        ],
        "cumulative_arc": "The text has moved from defining the Problem (Uniformity) to presenting two distinct Paradigms of solution. The Computational Paradigm (Thesis) is presented as complex, artifactual, and representational. The Dynamical Paradigm (Antithesis, embodied by Watt) is presented as simple, elegant, and non-representational. This sets the stage for the synthesis: applying the Dynamical view to Cognition itself."
      },
      "patterns": [
        {
          "name": "The Computational Cluster",
          "terms": [
            "Representation",
            "Computation",
            "Sequence",
            "Homuncularity"
          ],
          "description": "A mutually interdependent set of properties that defines the orthodox view of intelligent systems. Van Gelder treats these not as separate features but as a single 'kind' of system."
        },
        {
          "name": "Decomposition vs. Coupling",
          "terms": [
            "Subtasks",
            "Algorithm",
            "Direct Linkage",
            "Physics"
          ],
          "description": "The contrast between solving a problem by breaking it into abstract logical steps (Decomposition) versus solving it by arranging physical forces to interact continuously (Coupling)."
        }
      ],
      "graph_update": {
        "new_nodes": [
          "Computational_Governor",
          "Watt_Governor",
          "Computational_Cluster",
          "Homuncularity",
          "Direct_Coupling",
          "Discrete_Sequence"
        ],
        "new_edges": [
          {
            "from": "Computational_Governor",
            "to": "Computational_Cluster",
            "relation": "implies"
          },
          {
            "from": "Computational_Cluster",
            "to": "Homuncularity",
            "relation": "implies"
          },
          {
            "from": "Watt_Governor",
            "to": "Direct_Coupling",
            "relation": "implies"
          },
          {
            "from": "Watt_Governor",
            "to": "Computational_Cluster",
            "relation": "contradicts"
          },
          {
            "from": "Watt_Governor",
            "to": "Control",
            "relation": "implies"
          }
        ],
        "removed_nodes": []
      }
    }
  ],
  "currentChunkIndex": 12,
  "phase": "GlobalAnalysisComplete",
  "graphData": {
    "nodes": [
      {
        "id": "Computational_Orthodoxy",
        "name": "Computational_Orthodoxy",
        "__indexColor": "#ec0001",
        "index": 0,
        "x": 14.12674907234659,
        "y": -12.878650379356474,
        "vx": 9.119518822437461e-11,
        "vy": -1.770854753164751e-10
      },
      {
        "id": "Dynamical_Hypothesis",
        "name": "Dynamical_Hypothesis",
        "__indexColor": "#d80002",
        "index": 1,
        "x": -20.932143978847456,
        "y": -22.953030310179088,
        "vx": 1.8952683202002865e-10,
        "vy": -4.887276644361572e-10
      },
      {
        "id": "Watt_Governor",
        "name": "Watt_Governor",
        "__indexColor": "#c40003",
        "index": 2,
        "x": 22.992702371630998,
        "y": 43.933800431613506,
        "vx": 1.4184208625068081e-9,
        "vy": 2.686821777960267e-10
      },
      {
        "id": "Representation",
        "name": "Representation",
        "__indexColor": "#b00004",
        "index": 3,
        "x": 37.69025000694691,
        "y": 14.647235304631517,
        "vx": 2.422219903209601e-10,
        "vy": -3.4453589383011515e-10
      },
      {
        "id": "Coupling",
        "name": "Coupling",
        "__indexColor": "#9c0005",
        "index": 4,
        "x": -53.87755746992631,
        "y": -22.749355048058653,
        "vx": 2.093635664743589e-10,
        "vy": -6.075335453149449e-10
      },
      {
        "id": "Orthodoxy",
        "name": "Orthodoxy",
        "__indexColor": "#880006",
        "index": 5,
        "x": 19.78781566111266,
        "y": -12.587388583889217,
        "vx": 0,
        "vy": 0
      },
      {
        "id": "Newell_Thesis",
        "name": "Newell_Thesis",
        "__indexColor": "#740007",
        "index": 6,
        "x": -6.618637082526906,
        "y": 24.621000044064004,
        "vx": 0,
        "vy": 0
      },
      {
        "id": "Governing_Problem",
        "name": "Governing_Problem",
        "__indexColor": "#600008",
        "index": 7,
        "x": -12.62245871740517,
        "y": -24.303776166007665,
        "vx": 0,
        "vy": 0
      },
      {
        "id": "Steam_Engine",
        "name": "Steam_Engine",
        "__indexColor": "#4c0009",
        "index": 8,
        "x": 27.3856864633483,
        "y": 10.001208773502414,
        "vx": 0,
        "vy": 0
      },
      {
        "id": "Human_Mechanic",
        "name": "Human_Mechanic",
        "__indexColor": "#38000a",
        "index": 9,
        "x": -28.490243449190146,
        "y": 11.760358336627238,
        "vx": 0,
        "vy": 0
      },
      {
        "id": "Computational_Governor",
        "name": "Computational_Governor",
        "__indexColor": "#24000b",
        "index": 10,
        "x": 13.734179949820856,
        "y": -29.34914481047001,
        "vx": 0,
        "vy": 0
      },
      {
        "id": "Homuncularity",
        "name": "Homuncularity",
        "__indexColor": "#10000c",
        "index": 11,
        "x": 10.149209636450301,
        "y": 32.35727960993298,
        "vx": 0,
        "vy": 0
      },
      {
        "id": "Sequentiality",
        "name": "Sequentiality",
        "__indexColor": "#fc000d",
        "index": 12,
        "x": -30.589835678756263,
        "y": -17.727435041389672,
        "vx": 0,
        "vy": 0
      },
      {
        "id": "Computational_Cluster",
        "name": "Computational_Cluster",
        "__indexColor": "#e8000e",
        "index": 13,
        "x": 35.88535934290564,
        "y": -7.889295585192323,
        "vx": 0,
        "vy": 0
      },
      {
        "id": "Direct_Coupling",
        "name": "Direct_Coupling",
        "__indexColor": "#d4000f",
        "index": 14,
        "x": -21.900276194166445,
        "y": 31.150889274934457,
        "vx": 0,
        "vy": 0
      },
      {
        "id": "Discrete_Sequence",
        "name": "Discrete_Sequence",
        "__indexColor": "#c00010",
        "index": 15,
        "x": -5.05947091685981,
        "y": -39.04358787357342,
        "vx": 0,
        "vy": 0
      },
      {
        "id": "Sequence",
        "name": "Sequence",
        "__indexColor": "#ac0011",
        "index": 16,
        "x": 31.060189025756014,
        "y": 26.17756019349981,
        "vx": 0,
        "vy": 0
      },
      {
        "id": "Gap_Perception_Action",
        "name": "Gap_Perception_Action",
        "__indexColor": "#980012",
        "index": 17,
        "x": -41.7972782028575,
        "y": 1.7284486781313184,
        "vx": 0,
        "vy": 0
      },
      {
        "id": "Continuous_Coupling",
        "name": "Continuous_Coupling",
        "__indexColor": "#840013",
        "index": 18,
        "x": 30.487905903426476,
        "y": -30.339538454363694,
        "vx": 0,
        "vy": 0
      },
      {
        "id": "Perception_Action_Cycle",
        "name": "Perception_Action_Cycle",
        "__indexColor": "#700014",
        "index": 19,
        "x": -2.039759023075995,
        "y": 44.11166946656837,
        "vx": 0,
        "vy": 0
      },
      {
        "id": "Continuous_Motion",
        "name": "Continuous_Motion",
        "__indexColor": "#5c0015",
        "index": 20,
        "x": -29.009340345864786,
        "y": -34.762884988127524,
        "vx": 0,
        "vy": 0
      },
      {
        "id": "Normative_Synthesis",
        "name": "Normative_Synthesis",
        "__indexColor": "#480016",
        "index": 21,
        "x": 45.95399818121157,
        "y": 6.183045460062862,
        "vx": 0,
        "vy": 0
      },
      {
        "id": "Self_Correction",
        "name": "Self_Correction",
        "__indexColor": "#340017",
        "index": 22,
        "x": -38.93672971725283,
        "y": 27.091162376789978,
        "vx": 0,
        "vy": 0
      },
      {
        "id": "n(Homuncularity)",
        "name": "n(Homuncularity)",
        "__indexColor": "#64003b",
        "index": 23,
        "x": 10.639754127738415,
        "y": -47.294773834973284,
        "vx": 0,
        "vy": 0
      },
      {
        "id": "n(Discrete_Sequence)",
        "name": "n(Discrete_Sequence)",
        "__indexColor": "#50003c",
        "index": 24,
        "x": 24.609197771495488,
        "y": 42.94633145035117,
        "vx": 0,
        "vy": 0
      },
      {
        "id": "o(Watt_Governor)",
        "name": "o(Watt_Governor)",
        "__indexColor": "#3c003d",
        "index": 25,
        "x": -48.108627040199295,
        "y": -15.347964174671652,
        "vx": 0,
        "vy": 0
      },
      {
        "id": "n(Computational_Stance)",
        "name": "n(Computational_Stance)",
        "__indexColor": "#28003e",
        "index": 26,
        "x": 46.73140878326114,
        "y": -21.591096154010888,
        "vx": 0,
        "vy": 0
      },
      {
        "id": "Hermeneutic Circle",
        "name": "Hermeneutic Circle",
        "__indexColor": "#d80042",
        "index": 27,
        "x": -20.24521394750863,
        "y": 48.374903743776095,
        "vx": 0,
        "vy": 0
      },
      {
        "id": "Normative Meaning",
        "name": "Normative Meaning",
        "__indexColor": "#c40043",
        "index": 28,
        "x": -18.06840736265379,
        "y": -50.23477535907967,
        "vx": 0,
        "vy": 0
      },
      {
        "id": "Void",
        "name": "Void",
        "__indexColor": "#740047",
        "index": 29,
        "x": 48.07809275820085,
        "y": 25.268498109975482,
        "vx": 0,
        "vy": 0
      },
      {
        "id": "Schema",
        "name": "Schema",
        "__indexColor": "#600048",
        "index": 30,
        "x": -53.40266400194313,
        "y": 14.076770847590282,
        "vx": 0,
        "vy": 0
      },
      {
        "id": "Form_as_Content",
        "name": "Form_as_Content",
        "__indexColor": "#4c0049",
        "index": 31,
        "x": 30.354442781599538,
        "y": -47.20813281012711,
        "vx": 0,
        "vy": 0
      },
      {
        "id": "Concrete_Universal",
        "name": "Concrete_Universal",
        "__indexColor": "#10004c",
        "index": 32,
        "x": 9.655927474313346,
        "y": 56.18507866516519,
        "vx": 0,
        "vy": 0
      },
      {
        "id": "Normative_Meaning",
        "name": "Normative_Meaning",
        "__indexColor": "#d4004f",
        "index": 33,
        "x": -45.76062462351757,
        "y": -35.439599801147835,
        "vx": 0,
        "vy": 0
      },
      {
        "id": "Spirit",
        "name": "Spirit",
        "__indexColor": "#840053",
        "index": 34,
        "x": 58.536154406261204,
        "y": -4.849600738859532,
        "vx": 0,
        "vy": 0
      },
      {
        "id": "Mutual Recognition",
        "name": "Mutual Recognition",
        "__indexColor": "#700054",
        "index": 35,
        "x": -40.46082171267107,
        "y": 43.73696270130614,
        "vx": 0,
        "vy": 0
      },
      {
        "id": "n(Meaning)",
        "name": "n(Meaning)",
        "__indexColor": "#200058",
        "index": 36,
        "x": 0.2947222361892172,
        "y": -60.41451099531879,
        "vx": 0,
        "vy": 0
      },
      {
        "id": "Global_Unity",
        "name": "Global_Unity",
        "__indexColor": "#0c0059",
        "index": 37,
        "x": 41.144395618376954,
        "y": 45.3556910342956,
        "vx": 0,
        "vy": 0
      },
      {
        "id": "n(Freedom)",
        "name": "n(Freedom)",
        "__indexColor": "#d0005c",
        "index": 38,
        "x": -61.78358926815812,
        "y": -5.726089166572359,
        "vx": 0,
        "vy": 0
      },
      {
        "id": "s(Recognition)",
        "name": "s(Recognition)",
        "__indexColor": "#bc005d",
        "index": 39,
        "x": 50.06298462654409,
        "y": -37.99602045323181,
        "vx": 0,
        "vy": 0
      }
    ],
    "links": [
      {
        "source": {
          "id": "Computational_Orthodoxy",
          "name": "Computational_Orthodoxy",
          "__indexColor": "#ec0001",
          "index": 0,
          "x": 14.12674907234659,
          "y": -12.878650379356474,
          "vx": 9.119518822437461e-11,
          "vy": -1.770854753164751e-10
        },
        "target": {
          "id": "Representation",
          "name": "Representation",
          "__indexColor": "#b00004",
          "index": 3,
          "x": 37.69025000694691,
          "y": 14.647235304631517,
          "vx": 2.422219903209601e-10,
          "vy": -3.4453589383011515e-10
        },
        "label": "implies",
        "__indexColor": "#200018",
        "__controlPoints": null,
        "index": 0,
        "__photons": [
          {
            "__progressRatio": 0.6950000000000018
          },
          {
            "__progressRatio": 0.19500000000000187
          }
        ]
      },
      {
        "source": {
          "id": "Watt_Governor",
          "name": "Watt_Governor",
          "__indexColor": "#c40003",
          "index": 2,
          "x": 22.992702371630998,
          "y": 43.933800431613506,
          "vx": 1.4184208625068081e-9,
          "vy": 2.686821777960267e-10
        },
        "target": {
          "id": "Representation",
          "name": "Representation",
          "__indexColor": "#b00004",
          "index": 3,
          "x": 37.69025000694691,
          "y": 14.647235304631517,
          "vx": 2.422219903209601e-10,
          "vy": -3.4453589383011515e-10
        },
        "label": "contradicts",
        "__indexColor": "#0c0019",
        "__controlPoints": null,
        "index": 1,
        "__photons": [
          {
            "__progressRatio": 0.6950000000000018
          },
          {
            "__progressRatio": 0.19500000000000187
          }
        ]
      },
      {
        "source": {
          "id": "Dynamical_Hypothesis",
          "name": "Dynamical_Hypothesis",
          "__indexColor": "#d80002",
          "index": 1,
          "x": -20.932143978847456,
          "y": -22.953030310179088,
          "vx": 1.8952683202002865e-10,
          "vy": -4.887276644361572e-10
        },
        "target": {
          "id": "Coupling",
          "name": "Coupling",
          "__indexColor": "#9c0005",
          "index": 4,
          "x": -53.87755746992631,
          "y": -22.749355048058653,
          "vx": 2.093635664743589e-10,
          "vy": -6.075335453149449e-10
        },
        "label": "implies",
        "__indexColor": "#f8001a",
        "__controlPoints": null,
        "index": 2,
        "__photons": [
          {
            "__progressRatio": 0.6950000000000018
          },
          {
            "__progressRatio": 0.19500000000000187
          }
        ]
      },
      {
        "source": {
          "id": "Dynamical_Hypothesis",
          "name": "Dynamical_Hypothesis",
          "__indexColor": "#d80002",
          "index": 1,
          "x": -20.932143978847456,
          "y": -22.953030310179088,
          "vx": 1.8952683202002865e-10,
          "vy": -4.887276644361572e-10
        },
        "target": {
          "id": "Computational_Orthodoxy",
          "name": "Computational_Orthodoxy",
          "__indexColor": "#ec0001",
          "index": 0,
          "x": 14.12674907234659,
          "y": -12.878650379356474,
          "vx": 9.119518822437461e-11,
          "vy": -1.770854753164751e-10
        },
        "label": "sublates",
        "__indexColor": "#e4001b",
        "__controlPoints": null,
        "index": 3,
        "__photons": [
          {
            "__progressRatio": 0.3900000000000035
          },
          {
            "__progressRatio": 0.8900000000000037
          }
        ]
      },
      {
        "source": {
          "id": "Orthodoxy",
          "name": "Orthodoxy",
          "__indexColor": "#880006",
          "index": 5,
          "x": 19.78781566111266,
          "y": -12.587388583889217,
          "vx": 0,
          "vy": 0
        },
        "target": {
          "id": "Representation",
          "name": "Representation",
          "__indexColor": "#b00004",
          "index": 3,
          "x": 37.69025000694691,
          "y": 14.647235304631517,
          "vx": 2.422219903209601e-10,
          "vy": -3.4453589383011515e-10
        },
        "label": "implies",
        "__indexColor": "#d0001c",
        "__controlPoints": null,
        "index": 4,
        "__photons": [
          {
            "__progressRatio": 0.6950000000000018
          },
          {
            "__progressRatio": 0.19500000000000187
          }
        ]
      },
      {
        "source": {
          "id": "Orthodoxy",
          "name": "Orthodoxy",
          "__indexColor": "#880006",
          "index": 5,
          "x": 19.78781566111266,
          "y": -12.587388583889217,
          "vx": 0,
          "vy": 0
        },
        "target": "Algorithm",
        "label": "implies",
        "__indexColor": "#bc001d",
        "__controlPoints": null,
        "index": 5,
        "__photons": [
          {},
          {}
        ]
      },
      {
        "source": "Dynamical_Hypothesis",
        "target": "Orthodoxy",
        "label": "contradicts",
        "__indexColor": "#a8001e",
        "__controlPoints": null,
        "__photons": [
          {},
          {}
        ]
      },
      {
        "source": "Human_Mechanic",
        "target": "Governing_Problem",
        "label": "implies",
        "__indexColor": "#94001f",
        "__controlPoints": null,
        "__photons": [
          {},
          {}
        ]
      },
      {
        "source": "Computational_Governor",
        "target": "Computational_Cluster",
        "label": "implies",
        "__indexColor": "#800020",
        "__controlPoints": null,
        "__photons": [
          {},
          {}
        ]
      },
      {
        "source": "Computational_Cluster",
        "target": "s(Representation)",
        "label": "implies",
        "__indexColor": "#6c0021",
        "__controlPoints": null,
        "__photons": [
          {},
          {}
        ]
      },
      {
        "source": "Computational_Cluster",
        "target": "Homuncularity",
        "label": "implies",
        "__indexColor": "#580022",
        "__controlPoints": null,
        "__photons": [
          {},
          {}
        ]
      },
      {
        "source": "Watt_Governor",
        "target": "Computational_Cluster",
        "label": "contradicts",
        "__indexColor": "#440023",
        "__controlPoints": null,
        "__photons": [
          {},
          {}
        ]
      },
      {
        "source": "Watt_Governor",
        "target": "n(Control)",
        "label": "implies",
        "__indexColor": "#300024",
        "__controlPoints": null,
        "__photons": [
          {},
          {}
        ]
      },
      {
        "source": "Computational_Governor",
        "target": "Homuncularity",
        "label": "implies",
        "__indexColor": "#1c0025",
        "__controlPoints": null,
        "__photons": [
          {},
          {}
        ]
      },
      {
        "source": "Computational_Governor",
        "target": "s(Representation)",
        "label": "implies",
        "__indexColor": "#080026",
        "__controlPoints": null,
        "__photons": [
          {},
          {}
        ]
      },
      {
        "source": "Watt_Governor",
        "target": "Direct_Coupling",
        "label": "implies",
        "__indexColor": "#f40027",
        "__controlPoints": null,
        "__photons": [
          {},
          {}
        ]
      },
      {
        "source": "Watt_Governor",
        "target": "Homuncularity",
        "label": "contradicts",
        "__indexColor": "#e00028",
        "__controlPoints": null,
        "__photons": [
          {},
          {}
        ]
      },
      {
        "source": "Watt_Governor",
        "target": "Computational_Governor",
        "label": "contradicts",
        "__indexColor": "#cc0029",
        "__controlPoints": null,
        "__photons": [
          {},
          {}
        ]
      },
      {
        "source": "Computational_Cluster",
        "target": "Representation",
        "label": "implies",
        "__indexColor": "#b8002a",
        "__controlPoints": null,
        "__photons": [
          {},
          {}
        ]
      },
      {
        "source": "Watt_Governor",
        "target": "Control",
        "label": "implies",
        "__indexColor": "#a4002b",
        "__controlPoints": null,
        "__photons": [
          {},
          {}
        ]
      },
      {
        "source": "Watt_Governor",
        "target": "s(Representation)",
        "label": "contradicts",
        "__indexColor": "#90002c",
        "__controlPoints": null,
        "__photons": [
          {},
          {}
        ]
      },
      {
        "source": "Computational_Cluster",
        "target": "Sequentiality",
        "label": "implies",
        "__indexColor": "#7c002d",
        "__controlPoints": null,
        "__photons": [
          {},
          {}
        ]
      },
      {
        "source": "Computational_Governor",
        "target": "Sequence",
        "label": "implies",
        "__indexColor": "#68002e",
        "__controlPoints": null,
        "__photons": [
          {},
          {}
        ]
      },
      {
        "source": "Sequence",
        "target": "Gap_Perception_Action",
        "label": "implies",
        "__indexColor": "#54002f",
        "__controlPoints": null,
        "__photons": [
          {},
          {}
        ]
      },
      {
        "source": "Direct_Coupling",
        "target": "Gap_Perception_Action",
        "label": "contradicts",
        "__indexColor": "#400030",
        "__controlPoints": null,
        "__photons": [
          {},
          {}
        ]
      },
      {
        "source": "Watt_Governor",
        "target": "Algorithm",
        "label": "contradicts",
        "__indexColor": "#2c0031",
        "__controlPoints": null,
        "__photons": [
          {},
          {}
        ]
      },
      {
        "source": "Watt_Governor",
        "target": "Continuous_Coupling",
        "label": "implies",
        "__indexColor": "#180032",
        "__controlPoints": null,
        "__photons": [
          {},
          {}
        ]
      },
      {
        "source": "Computational_Governor",
        "target": "Discrete_Sequence",
        "label": "implies",
        "__indexColor": "#040033",
        "__controlPoints": null,
        "__photons": [
          {},
          {}
        ]
      },
      {
        "source": "Watt_Governor",
        "target": "Discrete_Sequence",
        "label": "contradicts",
        "__indexColor": "#f00034",
        "__controlPoints": null,
        "__photons": [
          {},
          {}
        ]
      },
      {
        "source": "Computational_Governor",
        "target": "n(Homuncularity)",
        "label": "implies",
        "__indexColor": "#dc0035",
        "__controlPoints": null,
        "__photons": [
          {},
          {}
        ]
      },
      {
        "source": "Watt_Governor",
        "target": "Coupling",
        "label": "implies",
        "__indexColor": "#c80036",
        "__controlPoints": null,
        "__photons": [
          {},
          {}
        ]
      },
      {
        "source": "Coupling",
        "target": "Discrete_Sequence",
        "label": "contradicts",
        "__indexColor": "#b40037",
        "__controlPoints": null,
        "__photons": [
          {},
          {}
        ]
      },
      {
        "source": "Subjective_Projection",
        "target": "Objective_Resistance",
        "label": "implies",
        "__indexColor": "#a00038",
        "__photons": [
          {},
          {}
        ],
        "__controlPoints": null
      },
      {
        "source": "Objective_Resistance",
        "target": "Normative_Synthesis",
        "label": "sublates",
        "__indexColor": "#8c0039",
        "__photons": [
          {},
          {}
        ],
        "__controlPoints": null
      },
      {
        "source": "Normative_Synthesis",
        "target": "Self_Correction",
        "label": "implies",
        "__indexColor": "#78003a",
        "__photons": [
          {},
          {}
        ],
        "__controlPoints": null
      },
      {
        "source": "n(Computational_Stance)",
        "target": "n(Homuncularity)",
        "label": "implies",
        "__indexColor": "#14003f",
        "__photons": [
          {},
          {}
        ],
        "__controlPoints": null
      },
      {
        "source": "o(Watt_Governor)",
        "target": "n(Homuncularity)",
        "label": "contradicts",
        "__indexColor": "#000040",
        "__photons": [
          {},
          {}
        ],
        "__controlPoints": null
      },
      {
        "source": "o(Watt_Governor)",
        "target": "s(Representation)",
        "label": "contradicts",
        "__indexColor": "#ec0041",
        "__photons": [
          {},
          {}
        ],
        "__controlPoints": null
      },
      {
        "source": "Subject",
        "target": "Hermeneutic Circle",
        "label": "implies",
        "__indexColor": "#b00044",
        "__photons": [
          {},
          {}
        ],
        "__controlPoints": null
      },
      {
        "source": "Object",
        "target": "Hermeneutic Circle",
        "label": "implies",
        "__indexColor": "#9c0045",
        "__photons": [
          {},
          {}
        ],
        "__controlPoints": null
      },
      {
        "source": "Static Text",
        "target": "Normative Meaning",
        "label": "sublates",
        "__indexColor": "#880046",
        "__photons": [
          {},
          {}
        ],
        "__controlPoints": null
      },
      {
        "source": "Void",
        "target": "Schema",
        "label": "contradicts",
        "__indexColor": "#38004a",
        "__photons": [
          {},
          {}
        ],
        "__controlPoints": null
      },
      {
        "source": "Schema",
        "target": "Form_as_Content",
        "label": "implies",
        "__indexColor": "#24004b",
        "__photons": [
          {},
          {}
        ],
        "__controlPoints": null
      },
      {
        "source": "Subjective_Act",
        "target": "Objective_Fact",
        "label": "implies",
        "__indexColor": "#fc004d",
        "__photons": [
          {},
          {}
        ],
        "__controlPoints": null
      },
      {
        "source": "Objective_Fact",
        "target": "Subjective_Act",
        "label": "sublates",
        "__indexColor": "#e8004e",
        "__photons": [
          {},
          {}
        ],
        "__controlPoints": null
      },
      {
        "source": "Concrete_Universal",
        "target": "Abstract_General",
        "label": "sublates",
        "__indexColor": "#c00050",
        "__photons": [
          {},
          {}
        ],
        "__controlPoints": null
      },
      {
        "source": "Normative_Meaning",
        "target": "Isolated_Datum",
        "label": "sublates",
        "__indexColor": "#ac0051",
        "__photons": [
          {},
          {}
        ],
        "__controlPoints": null
      },
      {
        "source": "Concrete_Universal",
        "target": "Normative_Meaning",
        "label": "implies",
        "__indexColor": "#980052",
        "__photons": [
          {},
          {}
        ],
        "__controlPoints": null
      },
      {
        "source": "Subject",
        "target": "Spirit",
        "label": "sublates",
        "__indexColor": "#5c0055",
        "__photons": [
          {},
          {}
        ],
        "__controlPoints": null
      },
      {
        "source": "Object",
        "target": "Spirit",
        "label": "sublates",
        "__indexColor": "#480056",
        "__photons": [
          {},
          {}
        ],
        "__controlPoints": null
      },
      {
        "source": "Mutual Recognition",
        "target": "Spirit",
        "label": "implies",
        "__indexColor": "#340057",
        "__photons": [
          {},
          {}
        ],
        "__controlPoints": null
      },
      {
        "source": "s(Interpretation)",
        "target": "o(Text)",
        "label": "implies",
        "__indexColor": "#f8005a",
        "__photons": [
          {},
          {}
        ],
        "__controlPoints": null
      },
      {
        "source": "n(Meaning)",
        "target": "Global_Unity",
        "label": "sublates",
        "__indexColor": "#e4005b",
        "__photons": [
          {},
          {}
        ],
        "__controlPoints": null
      },
      {
        "source": "s(Will)",
        "target": "o(Alienation)",
        "label": "implies",
        "__indexColor": "#a8005e",
        "__photons": [
          {},
          {}
        ],
        "__controlPoints": null
      },
      {
        "source": "o(Alienation)",
        "target": "s(Recognition)",
        "label": "sublates",
        "__indexColor": "#94005f",
        "__photons": [
          {},
          {}
        ],
        "__controlPoints": null
      },
      {
        "source": "s(Recognition)",
        "target": "n(Freedom)",
        "label": "sublates",
        "__indexColor": "#800060",
        "__photons": [
          {},
          {}
        ],
        "__controlPoints": null
      }
    ]
  }
}